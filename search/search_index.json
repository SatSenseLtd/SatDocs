{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SatSense Documentation Introduction This page collects the documentation of the various parts of SatSense technical development areas. The documentation is organised in various sections, described below. Processing Here you'll find documentation regarding basic InSAR processing, ranging from downloading data all the way to postprocessing data. Daemon Here you'll find documentation regarding the automatic processing daemon and the graphical user interface, covering starting and stopping the daemon, defining processing frames, setting up new processing databases and using the interface. Client-Facing Applications Overview Here you'll find documentation regarding the client-facing application ecosystem. These applications are responsible for taking processed InSAR data and making it accessible to an end user.","title":"SatSense Documentation"},{"location":"#satsense-documentation","text":"","title":"SatSense Documentation"},{"location":"#introduction","text":"This page collects the documentation of the various parts of SatSense technical development areas. The documentation is organised in various sections, described below.","title":"Introduction"},{"location":"#processing","text":"Here you'll find documentation regarding basic InSAR processing, ranging from downloading data all the way to postprocessing data.","title":"Processing"},{"location":"#daemon","text":"Here you'll find documentation regarding the automatic processing daemon and the graphical user interface, covering starting and stopping the daemon, defining processing frames, setting up new processing databases and using the interface.","title":"Daemon"},{"location":"#client-facing-applications-overview","text":"Here you'll find documentation regarding the client-facing application ecosystem. These applications are responsible for taking processed InSAR data and making it accessible to an end user.","title":"Client-Facing Applications Overview"},{"location":"AWS/","text":"Setting up AWS for processing Starting EC2 instance EC2 instances can be started from the AWS EC2 console. If just a single instance is required, simply select the stopped instance in the Instance screen, and select Actions -> Instance Settings -> Modify Instance Type to select the instance type required. Note that not all instance types are available, t3 (general purpose) and r5 (higher memory) instances work. A t3.medium instance works well for SatSAR, r5.xlarge works well for RapidSAR and beyond. Note that starting an instance like this does not come with additional storage attached, see the section on Setting up EBS volumes below. All software should be installed and environments set up for basic processing, except for the database, see the section on RDS database processing below. It's probably a good idea to run and apt upgrade and pull changes in from gitlab on the various bits of software. If multiple instances are required, we can create an image of the basic stopped instance. If necessary, start the instance and ensure the latest updates have been applied (apt and gitlab). Then from the console, go to Actions -> Image and templates -> Create image. Give the image a name and click \"Create image\". From the main console window, the image is now available from the AMI screen. This image can now be used to launch images. Ensure that the vpc is (vpc-770a581f) and that the subnet mask is the default for eu-west-2a. On the next screen, storage can be defined, or this can be added at a later time, see section on Setting up EBS volumes. One the instance is running (this can take a minute or more), you can ssh into the EC2 instance using the IP address or URL of the instance, which you can find on the Instances screen. The username is ubuntu. From the instances screen, you can also stop the instance, or run the shutdown command from the ssh session terminal. Note that storage continues to be billed, even if the instance is stopped. Any unused instance (besides the basic instance), including their EBS volumes, should be deleted. RDS database setup As our processing database is currently not accessible from outside Unipart network, we'll have to set up a specific database for AWS processing. Luckily this is a fairly streamlined process consisting of two parts, commissioning the database from the AWS RDS console, and setting up the specific requirements for the SatSense processing database. RDS console From the console, we can determine the type of database we want, and set up security and connectivity settings. The steps listed below will set up a database suitable for SatSense processing: From the main dashboard, click the Create Database button, and select \"standard create\" and \"PostgreSQL\". For the version, go with the latest subversion of version 12, at the time of writing version 12.8-R1. Give the database and identifier. Leave the username, and choose a password (and remember it!). Select burstable classes, type db.t3.micro Change storage type to \"General Purpose SSD (gp2)\" and leave allocated storage to the minimum 20 GB. Untick \"Enable storage autoscaling\" and select \"Do not create a standby instance\" Select the default VPC and subnet groups (vpc-770a581f), set availability zone to \"eu-west-2a\" and enable public access After this, create database and wait for it to come online. This might take 15-30 minutes. Additional database setup Now we switch to a Linux terminal on our local system or an EC2 instance. EC2 instance is probably a better option, but not mandatory. If using a local terminal, ensure a postgresql client version 12 is installed. If using EC2, ensure it is a t2/t3.medium or above, as some memory will be required for the ingestion of bursts. Set the $DBIP environment variable to the correct enpoint url. After the database has initialised, you can find the url in the Databases screen, under \"Connectivity and Security\". Here you can also find the port number, and ensure that the VPC and security groups match the EC2 instance you'll use. Log into database from EC2 instance or local system: psql --host=$DBIP --port=5432 --username=postgres --password From psql, create satsense_live database CREATE DATABASE satsense_live OWNER=postgres; Switch to database \\c satsense_live Activate Postgis, see https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.PostGIS.html Log out of database Ensure $DBIP points to the RDS DB, and make sure the password, port and user are correct in satdaemon.cfg. From the satdaemon directory, run init_database.py init_database.py -d satdaemon.cfg -f database/UK_frame_coords_ASF.txt -b database/UK_frame_burst_ids.txt -l database/burst_corners_llh.dat This will take a while (30 mins or so?) After this, you should be good to go. You can test the database by going into the satdaemon/database directory and running python make_frames_shapefile_db.py . If it completes at least one frame, the database is working as it should and you can stop the script with CTRL+c. That's it. Setting up EBS volumes Disk space for EC2 instances is provided by Elastic Block Storage (EBS) volumes. EBS storage is charged by storage volume provided (not used!), and costs the same whether it is attached to a running instance, attached to a stopped instance or not attached. Except when processing, the only EBS volume should be the one that has the installation files of the stopped instance on it. EBS volumes can be created and deleted at will. This can be done in the EC2 console, under Elastic Block Store -> Volumes. Click the \"Create Volume\" button and select volume type, which normally should be general provisioned SSD. Set the size and ensure Availability zone is the same as the EC2 instance (normally eu-west-2a) and click \"Create Volume\". The volume should be showing as \"Available\" momentarily. To use a volume inside an EC2 instance, it needs to be attached. Under normal conditions, EC2 volumes can only be attached to a single EC2 instance! Select the volume you wish to attach, and select Actions -> Attach volume. Select the EC2 instance you wish to attach the volume to. To be able to use the volume, it has to be formated (if it is newly created) and mounted to a mount point. Volumes have to be remounted every time the instance gets restarted, unless there is an entry in fstab to automatically mount them. This is not receommended, as we likely want to switch volumes in and out. To first need to know where the volume is attached to: sudo lsblk This will show you a list of all attached devices. The EBS volume name will likely be nvme*n1, where * is 1,2,3,etc. We can see whether the volume needs formating using: sudo file -s /dev/nvme*n1 Replacing * with the corresponding number. If the volume is already formated, the output will look similar to: /dev/nvme1n1: SGI XFS filesystem data (blksz 4096, inosz 512, v2 dirs) If not, it will look like this: /dev/nvme2n1: data To format the volume, use: sudo mkfs -t xfs /dev/nvme*n1 To mount the disk, create a suitable mount point (e.g. /data, /workspace) and use: sudo mount /dev/nvme1n1 /mountdir Ensure you have write permission in the directory the volume is mounted to, and you're good to go. Volumes can be modified on the fly. This is useful when e.g. you need additional space. Not that volumes can only be increased, not decreased! To increase a volume, modify the volume through the Elastic Block Store screen in the EC2 console. Select the volume and go to Actions -> Modify volume. Up the size to the desired value and click \"Modify\". Wait for the volume to reach Optimizing stage. The volume should now be ready to be expanded from inside the instance. If the volume was mounted, you can use the following command to attach the expanded storage to the same mount point, without disruption: sudo xfs_growfs -d /mountdir More information on growing an EBS volume can be found in the AWS docs (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html)","title":"Setting up AWS for processing"},{"location":"AWS/#setting-up-aws-for-processing","text":"","title":"Setting up AWS for processing"},{"location":"AWS/#starting-ec2-instance","text":"EC2 instances can be started from the AWS EC2 console. If just a single instance is required, simply select the stopped instance in the Instance screen, and select Actions -> Instance Settings -> Modify Instance Type to select the instance type required. Note that not all instance types are available, t3 (general purpose) and r5 (higher memory) instances work. A t3.medium instance works well for SatSAR, r5.xlarge works well for RapidSAR and beyond. Note that starting an instance like this does not come with additional storage attached, see the section on Setting up EBS volumes below. All software should be installed and environments set up for basic processing, except for the database, see the section on RDS database processing below. It's probably a good idea to run and apt upgrade and pull changes in from gitlab on the various bits of software. If multiple instances are required, we can create an image of the basic stopped instance. If necessary, start the instance and ensure the latest updates have been applied (apt and gitlab). Then from the console, go to Actions -> Image and templates -> Create image. Give the image a name and click \"Create image\". From the main console window, the image is now available from the AMI screen. This image can now be used to launch images. Ensure that the vpc is (vpc-770a581f) and that the subnet mask is the default for eu-west-2a. On the next screen, storage can be defined, or this can be added at a later time, see section on Setting up EBS volumes. One the instance is running (this can take a minute or more), you can ssh into the EC2 instance using the IP address or URL of the instance, which you can find on the Instances screen. The username is ubuntu. From the instances screen, you can also stop the instance, or run the shutdown command from the ssh session terminal. Note that storage continues to be billed, even if the instance is stopped. Any unused instance (besides the basic instance), including their EBS volumes, should be deleted.","title":"Starting EC2 instance"},{"location":"AWS/#rds-database-setup","text":"As our processing database is currently not accessible from outside Unipart network, we'll have to set up a specific database for AWS processing. Luckily this is a fairly streamlined process consisting of two parts, commissioning the database from the AWS RDS console, and setting up the specific requirements for the SatSense processing database.","title":"RDS database setup"},{"location":"AWS/#rds-console","text":"From the console, we can determine the type of database we want, and set up security and connectivity settings. The steps listed below will set up a database suitable for SatSense processing: From the main dashboard, click the Create Database button, and select \"standard create\" and \"PostgreSQL\". For the version, go with the latest subversion of version 12, at the time of writing version 12.8-R1. Give the database and identifier. Leave the username, and choose a password (and remember it!). Select burstable classes, type db.t3.micro Change storage type to \"General Purpose SSD (gp2)\" and leave allocated storage to the minimum 20 GB. Untick \"Enable storage autoscaling\" and select \"Do not create a standby instance\" Select the default VPC and subnet groups (vpc-770a581f), set availability zone to \"eu-west-2a\" and enable public access After this, create database and wait for it to come online. This might take 15-30 minutes.","title":"RDS console"},{"location":"AWS/#additional-database-setup","text":"Now we switch to a Linux terminal on our local system or an EC2 instance. EC2 instance is probably a better option, but not mandatory. If using a local terminal, ensure a postgresql client version 12 is installed. If using EC2, ensure it is a t2/t3.medium or above, as some memory will be required for the ingestion of bursts. Set the $DBIP environment variable to the correct enpoint url. After the database has initialised, you can find the url in the Databases screen, under \"Connectivity and Security\". Here you can also find the port number, and ensure that the VPC and security groups match the EC2 instance you'll use. Log into database from EC2 instance or local system: psql --host=$DBIP --port=5432 --username=postgres --password From psql, create satsense_live database CREATE DATABASE satsense_live OWNER=postgres; Switch to database \\c satsense_live Activate Postgis, see https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.PostGIS.html Log out of database Ensure $DBIP points to the RDS DB, and make sure the password, port and user are correct in satdaemon.cfg. From the satdaemon directory, run init_database.py init_database.py -d satdaemon.cfg -f database/UK_frame_coords_ASF.txt -b database/UK_frame_burst_ids.txt -l database/burst_corners_llh.dat This will take a while (30 mins or so?) After this, you should be good to go. You can test the database by going into the satdaemon/database directory and running python make_frames_shapefile_db.py . If it completes at least one frame, the database is working as it should and you can stop the script with CTRL+c. That's it.","title":"Additional database setup"},{"location":"AWS/#setting-up-ebs-volumes","text":"Disk space for EC2 instances is provided by Elastic Block Storage (EBS) volumes. EBS storage is charged by storage volume provided (not used!), and costs the same whether it is attached to a running instance, attached to a stopped instance or not attached. Except when processing, the only EBS volume should be the one that has the installation files of the stopped instance on it. EBS volumes can be created and deleted at will. This can be done in the EC2 console, under Elastic Block Store -> Volumes. Click the \"Create Volume\" button and select volume type, which normally should be general provisioned SSD. Set the size and ensure Availability zone is the same as the EC2 instance (normally eu-west-2a) and click \"Create Volume\". The volume should be showing as \"Available\" momentarily. To use a volume inside an EC2 instance, it needs to be attached. Under normal conditions, EC2 volumes can only be attached to a single EC2 instance! Select the volume you wish to attach, and select Actions -> Attach volume. Select the EC2 instance you wish to attach the volume to. To be able to use the volume, it has to be formated (if it is newly created) and mounted to a mount point. Volumes have to be remounted every time the instance gets restarted, unless there is an entry in fstab to automatically mount them. This is not receommended, as we likely want to switch volumes in and out. To first need to know where the volume is attached to: sudo lsblk This will show you a list of all attached devices. The EBS volume name will likely be nvme*n1, where * is 1,2,3,etc. We can see whether the volume needs formating using: sudo file -s /dev/nvme*n1 Replacing * with the corresponding number. If the volume is already formated, the output will look similar to: /dev/nvme1n1: SGI XFS filesystem data (blksz 4096, inosz 512, v2 dirs) If not, it will look like this: /dev/nvme2n1: data To format the volume, use: sudo mkfs -t xfs /dev/nvme*n1 To mount the disk, create a suitable mount point (e.g. /data, /workspace) and use: sudo mount /dev/nvme1n1 /mountdir Ensure you have write permission in the directory the volume is mounted to, and you're good to go. Volumes can be modified on the fly. This is useful when e.g. you need additional space. Not that volumes can only be increased, not decreased! To increase a volume, modify the volume through the Elastic Block Store screen in the EC2 console. Select the volume and go to Actions -> Modify volume. Up the size to the desired value and click \"Modify\". Wait for the volume to reach Optimizing stage. The volume should now be ready to be expanded from inside the instance. If the volume was mounted, you can use the following command to attach the expanded storage to the same mount point, without disruption: sudo xfs_growfs -d /mountdir More information on growing an EBS volume can be found in the AWS docs (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html)","title":"Setting up EBS volumes"},{"location":"daemon/","text":"SatDaemon (SQLAlchemy Version) Introduction SatDaemon is the project responsible for automated processing of SatSense data, from the creation of SLC images to the ingestion of post-processed time series in to the points database. The daemon uses a processing database to determine which jobs can be run. Configuration The daemon and processing database are partly controlled through the config file. The config file determines which database the entire satdaemon project uses. Database initialisation, querying and updating are all performed on the database specified in the config file, unless manual override is given. The default config file is 'satdaemon.cfg ' within the main directory of the satdaemon repository. This default config file must be used for all routine processing since other SatSense projects (e.g. SatSAR, RapidSAR etc) which need to communicate with the processing database assume this config file provides the information they need. Within the config file, there are a number of sections. The 'PARAMETERS' section contains information about which database should be used, as well as paths for where data should be processed and software found. The 'PROC_MACHINES' section lists various parameters for the different processing machines available to the daemon , including names, resources, ports etc. Beneath these sections are sections which give estimated resource usage for each kind of processing job. CPU resources are the number of CPU cores used in the process, memory is the maximum memory used by each kind of job in gigabytes and disk resources are an estimate of how much disk I/O the job uses (arbitrary units out of 100). Processing Database The processing database is an SQL database such as SQLite or PostgreSQL (Postgres). SQLite was used for earlier versions of SatDaemon, and is currently used for testing. Postgres is used for the operational processing database. Communication with these databases is achieved through the Python package SQLAlchemy, which handles the different SQL dialects used by different SQL database versions. Unless you know what you are doing, do not interact directly with the database - use functions provided within SatDaemon instead. Schema and Structure The database has the following tables: Table Contents files Each row is a zipfile with information about track, orbit, date etc bursts Each row is a burst with information about track, orbit, swath and geometry files2bursts Secondary table for many-to-many relationship between files and bursts frames Each row is a frame and contains links to files and bursts as well as information about various processing parameters for the daemon frames2bursts Secondary table for many-to-many relationship between frames and bursts frames2files Secondary table for many-to-many relationship between frames and files master Each row is a master image for a specific frame with processing information (one per frame) ifg Each row is a secondary image for a specific frame with processing information (many per frame) rsar_ifg Each row is a RapidSAR interferogram between two dates: used for coherence and unwrap jobs master_proc_stages Each row is a different processing stage for all master images (reference table) ifg_proc_stages Each row is a different processing stage for all secondary images (reference table) rsar_ifg_proc_stages Each row is a different processing stage for all RapidSAR interferograms (reference table) daemon_tools One row which the daemon checks for any new input from users pending_jobs Each row is a pending job the daemon has produced with information about frame, job type etc running_jobs Each row is a running job the daemon has launched with information about frame, job type etc as well as progress information failed_jobs Each row is a failed job the daemon has encountered with information about frame, job type etc The table schema are all stored in the models.py file within the 'database' folder of the satdaemon repository . Each of the (non-secondary) tables is defined using the SQLAlchemy object relational mapper (ORM) syntax. Links between the various tables are established through these models. Initialisation Prior to initialisation, PostgreSQL and PostGIS need to be installed. Beware of potential issues with conflicting versions of PostgreSQL, the psql client and PostGIS on the system itself and within a conda environment. Once postgres is installed and running, a database needs to be created, connected to and the PostGIS extension enabled in it, all of which can be done using the psql client: CREATE DATABASE database_name; \\c database_name CREATE EXTENSION postgis; The processing database is initialised using the python script init_database.py , which can be found within the 'database' folder in the satdaemon repository. The database is initialised using the default config file 'satdaemon .cfg', but an alternative config file can be provided using the -d <config-file> flag. SQLite databases can be initialised entirely using the script init_database.py . This creates the database file , creates the various tables and relationships and then inserts bursts, frames and processing stage information. Postgres databases require a Postgres instance to be running before the database can be initialised. Once the Postgres instance has been set up, init_database.py can be used in the same way. Zip files can be inserted in to the database using the script ingest_files.py , found within the 'database ' folder of the satdaemon repository. By default, this will insert all zip files found in subdirectories of the /data directory, provided these subdirectories start with 'T' (e.g. 'T132'). Ingestion of a file automatically links the file to the appropriate frames and bursts in the database. A SQL dump file (produced using pg_dump ) can be used to restore a back-up file or fill a new database with data from an other. This can be done once the database has been initialised as above by using the pg_restore command. Bringing a database up to date with the state of the file system A new (or current) database may be out of sync with the state of the file system. In order for the daemon to know which jobs should be launched, the database must be checked for consistency against the file system. This should only need to be done very infrequently since the daemon will keep the processing database up to date as it processes data. You can use check_db_consistency.py in the main directory of the satdaemon repository. You must provide the config file which contains information about the database and file system you want to check. This script then checks every data and processing folder on the file system, and looks for the most advanced job for each possible date. The database is then updated with the information for each processing date, depending on which jobs have been run for that date. Note: This is not perfect - it assumes the file system is representative of the current state, that files are not corrupt or half processed and that the file system is the ultimate source of truth - use with caution! If you need to create a new database, and have a current database which is up-to-date, it may be better to copy over the data from the current database to the new one. This can be done using appropriate SQL commands such as dump . Querying and updating the database The safest way to query or update the database is by using the functions defined in the dbquery.py module . The current way to do this is to open a python command prompt and establish a connection to the database: from dbquery import Database # get ability to connect to database from models import * # get the database table models dbq = Database() # this is the database connection With the database connection established, we can query, insert, delete or update the database. Queries # to issue a simple query to the database file_id = 'AN_EXAMPLE_FILE_ID' result = dbq.query(File, id=file_id) # note that 'result' is a list, even when only one object is retrieved file = result[0] # the 'file' object has all the attributes of the files table, which can be retrieved path_to_file = file.abspath date = file.date Manual inserts, updates and deletes If satdaemon is running correctly then you should not need to issue these commands. However, it may be necessary to occasionally perform some manual work on the processing database. Insert from datetime import date # to insert a new object in to the database, we make a new instance of it new_file = File(id='EXAMPLE_ID', abspath='PATH/TO/FILE', track=100, orbit_direction='A', date=date(2019,10,1 ), proc_date=date(2019,10,1)) # other fields (last_updated and links to bursts and frames) are automatically filled in by SQLAlchemy dbq.insert(new_file) Update # to update a pre-existing entry in the database, we issue an update command # the update dictionary tells the database how fields should be updated update_dict = {'track': 101} # the update command is similar to the query command, where keywords are used to specify which rows should be updated dbq.update(File, update_dict, id='EXAMPLE_ID') Delete # to delete an existing row, use the delete command with similar syntax to the query command dbq.delete(File, id=file_id) More complex queries, updates and deletes The query, update and delete commands above work well where equality conditions are used to identify rows of interest . However, if you wish to query using other kinds of operators (e.g. greater than, less than, like, contains etc ) then you need to use a more complex query. See the SQLAlchemy Query API page for more information. To begin one of these more complex queries, it is necessary to start a session . The simpler query, insert, delete and update commands above all begin a session inside them and execute the required commands. To start our own session we use the session_scope context manager to ensure everything runs cleanly: ```python with dbq.session_scope() as session: result = session.query(File).filter(File.date < date(2019, 1, 20)).all() ### Creating a new frame and inserting it into the database The best way to create a new frame and insert it in to the database is to use a list of bursts to define the frame . You can use QGIS to look at the global bursts shapefile, or you can use the bursts section of the processing controller part of the admin website (https://admin.satsense.com/processing_controller/bursts) and note down the bursts you want to use in your new frame . Once you have a list of bursts, open up a connection to the database and use `make_new_frame_using_burstlist`: ```python from dbquery import Database dbq = Database() burstlist = ['132_8603_IW1','132_8612_IW2','132_8594_IW3','132_8575_IW1','132_8584_IW2','132_8566_IW3'] frame_id = '132A_CUSTOM_FRAME' dbq.make_new_frame_using_burstlist(burst_list, frame_id) Burst IDs should be in the format {TRACK}_{ANXID}_{SUBSWATH} , e.g. 132_8603_IW1 . The defined frame name should be in the format {TRACK}{A/D}_{TEXT}_{TEXT} e.g. 132A_CUSTOM_FRAME or 081D_CUSTOM_FRAME . You can check whether the new frame looks correct by plotting all the frames in the database using the python script make_frames_shapefile_db.py . The frame should also appear on the admin website. Setting a frame master date Creating a new frame does not automatically give a list of all dates available for that frame. A list of dates for the frame can be obtained by using the commands below: from dbquery import Database dbq = Database() dbq.fill_files_table(frame_id) # Running the command below will result in a master for the frame being automatically chosen if no master is present dbq.update_procdates(frame_id) # Alternatively, give a master date explicitly dbq.update_procdates(frame_id, user_master_date=master_date) # If there is already a master defined and you wish to change it, use the following command. # This will warn you if changing the master would mean reprocessing data dbq.set_master_for_frame(frame_id, master_date) Daemon Overview The daemon refers to the automated processor used by SatSense. The daemon uses a config file to determine certain parameters, but once launched, is largely left alone. The daemon consists of three main objects: ProcDaemon , ProcMachine and ProcJob objects. In simple terms, a ProcDaemon object is the daemon itself - it knows what is going on and communicates with the database. A ProcDaemon object knows how many ProcMachine objects it has at its disposal. ProcMachine objects are the processing machines themselves and know what is running on them, as well as their available resources. A ProcDaemon also knows what ProcJobs it can run. ProcJobs run on ProcMachines and these objects know all the relevant information for the job they are associated with. Launching the daemon The daemon can be launched from the command line using the command satdaemon.py . Before launching the daemon, it is very important that you check the config file satdaemon.cfg is set up as you want, and that it is pointing to the right database! You should always launch the daemon in a Linux 'screen' so that it can continue running when you log out of the remote machines. You can run screen -S daemon to establish a daemon screen if one does not already exist. Once the daemon is launched, it will use the specified database to check for new jobs which can be run and launch them in an appropriate order. Jobs will only be run for frames which are set to be processed. Frames can be set to process to different stages depending on need/resource availability. Frames can also be given different priorities, where higher priority frames will be processed before lower priority frames. Note that if a higher priority job cannot be launched because necessary pre-requisites have not been met, or resources are not available, a lower priority job which can be run will be launched. Controlling the daemon Before launching the daemon, you may want to change the processing parameters for a frame. This can be achieved using the SatDaemonController object and associated methods. Various common operations can be performed using the SatDaemonController, ensuring an easy, safe and clean change to the database. from satdaemon_control import SatDaemonController from datetime import date sdc = SatDaemonController() frame_id = 'EXAMPLE_FRAME' # Turn on full processing for a frame sdc.set_frame_full_proc(frame_id, True) # turn frame off for all processing stages sdc.set_frame_full_proc(frame_id, False) # turn frame off for all processing stages sdc.set_frame_full_proc(frame_id, False) # turn frame on, but only til download (all other stages turned off) sdc.set_frame_download(frame_id, True) # turn frame on, but only til end of SatSAR processing (all other stages turned off) sdc.set_frame_satsar(frame_id, True) # turn frame on, but only til unwrap (all other stages turned off) sdc.set_frame_process_til_timeseries(frame_id, True) # turn frame on, but only initial processing (all updating turned off) sdc.set_frame_noupdate(frame_id, True) # set the processing range for the frame sdc.set_frame_proc_range(frame_id, date(2019, 1, 1), date(2020, 1, 1)) # Set frame priority relative to other frames sdc.set_frame_priority(frame_id, 10) The daemon can also be controlled whilst the daemon is running using these commands. Each of these commands also issues a trigger to the daemon that it should recreate the job list, which it will do in light of any changes made to frame processing parameters. Turning off the daemon The daemon should be turned off using the SatDaemonController. from satdaemon_control import SatDaemonController sdc = SatDaemonController() sdc.power_down_daemon() This will cancel all pending jobs, but the daemon will keep running until currently running jobs are complete. The daemon will then stop running. If you cannot use the method above, you can issue a 'KeyboardInterrupt' if the daemon is running in a terminal, or kill it using the PID. However, these may result in the database and/or files ending up in a confused state. This should be avoided where possible. Before relaunching the daemon, it is important to check the database is not in an incorrect state. Prior to relaunching the daemon, there should be no jobs in the 'running_jobs' table, and there should be no rows in the ifg/master/rsar_ifg tables with a 'proc_status' of 1 (running). A daemon crash may not cause previously launched jobs to crash, and the best way of checking whether there are still jobs running is to check for running python processes on each of the processing machines, which can be done by running the command below in the shell: ps aux | grep python Jobs can take hours to finish. Before relaunching the daemon, let all jobs which had been launched by the daemon finish. Error reporting Errors may occur in the daemon itself (i.e. within satdaemon.py ) or in one of the jobs launched by the daemon . Errors in the daemon itself will cause the daemon to crash. These errors will be reported to the terminal and to a dedicated Microsoft Teams channel. Any jobs which are marked as running in the processing database will be reset so they can be rerun when the daemon is restarted. Errors within launched jobs are handled by the JobLogger object, created by the launched job itself. Each launched job communicates with the database and Micorsoft Teams using the JobLogger, reporting the processing status of the job, any errors or warnings and, in some cases, the progress of the job. Sometimes, errors within launched jobs are not caught by the JobLogger, and the job stops unexpectedly. In these cases, the return code of the job should be caught by the daemon and the daemon reports to the database and Micorsoft Teams that an error has occurred. Handling Crashes Jobs can sometimes crash unexpectedly, and this can mean the database does not get correctly updated. Possible problems which may occur are: 1. The master/ifg/rsar_ifg row in the corresponding table is not correctly updated. The 'proc_status' column may be stuck on a value of 1 (running), or it may correctly be changed to 4 (failure). 2. The 'running_jobs' table may not have the job removed. This means the job will never be launched again as the database states it is already running. This row needs to be deleted in order to relaunch the job. 3. An error can occur in the actual satdaemon.py script, which causes the daemon itself to crash. A daemon crash means the daemon stops running and no more jobs are launched. Previously launched jobs may still be running - make sure these jobs finish before relaunching the daemon. The best way of checking whether there are still jobs running is to check for running python processes on each of the processing machines, which can be done by running the command below in the shell: ps aux | grep python Jobs can take hours to finish. Before relaunching the daemon, let all jobs which had been launched by the daemon finish. Graphical Process Monitoring We are moving towards a web-based, graphical user interface for monitoring and controlling the automated processing. At the moment, we have a web-based monitoring tool, which allows users to see which jobs are running, monitor resource usage and visualise information from the database. This can all be accessed at the admin site: https://admin.satsense.com/processing_controller The processing controller area has pages for each frame and image as well as summaries of currently running jobs, maps of procesing progress and job failures. There is also a separate area with a map showing all global bursts, allowing for easier determination of which bursts to include in a new frame. There is currently no ability to change the daemon or database from the processing controller pages. The processing controller is currently only set up in 'read only' mode.","title":"SatDaemon (SQLAlchemy Version)"},{"location":"daemon/#satdaemon-sqlalchemy-version","text":"","title":"SatDaemon (SQLAlchemy Version)"},{"location":"daemon/#introduction","text":"SatDaemon is the project responsible for automated processing of SatSense data, from the creation of SLC images to the ingestion of post-processed time series in to the points database. The daemon uses a processing database to determine which jobs can be run.","title":"Introduction"},{"location":"daemon/#configuration","text":"The daemon and processing database are partly controlled through the config file. The config file determines which database the entire satdaemon project uses. Database initialisation, querying and updating are all performed on the database specified in the config file, unless manual override is given. The default config file is 'satdaemon.cfg ' within the main directory of the satdaemon repository. This default config file must be used for all routine processing since other SatSense projects (e.g. SatSAR, RapidSAR etc) which need to communicate with the processing database assume this config file provides the information they need. Within the config file, there are a number of sections. The 'PARAMETERS' section contains information about which database should be used, as well as paths for where data should be processed and software found. The 'PROC_MACHINES' section lists various parameters for the different processing machines available to the daemon , including names, resources, ports etc. Beneath these sections are sections which give estimated resource usage for each kind of processing job. CPU resources are the number of CPU cores used in the process, memory is the maximum memory used by each kind of job in gigabytes and disk resources are an estimate of how much disk I/O the job uses (arbitrary units out of 100).","title":"Configuration"},{"location":"daemon/#processing-database","text":"The processing database is an SQL database such as SQLite or PostgreSQL (Postgres). SQLite was used for earlier versions of SatDaemon, and is currently used for testing. Postgres is used for the operational processing database. Communication with these databases is achieved through the Python package SQLAlchemy, which handles the different SQL dialects used by different SQL database versions. Unless you know what you are doing, do not interact directly with the database - use functions provided within SatDaemon instead.","title":"Processing Database"},{"location":"daemon/#schema-and-structure","text":"The database has the following tables: Table Contents files Each row is a zipfile with information about track, orbit, date etc bursts Each row is a burst with information about track, orbit, swath and geometry files2bursts Secondary table for many-to-many relationship between files and bursts frames Each row is a frame and contains links to files and bursts as well as information about various processing parameters for the daemon frames2bursts Secondary table for many-to-many relationship between frames and bursts frames2files Secondary table for many-to-many relationship between frames and files master Each row is a master image for a specific frame with processing information (one per frame) ifg Each row is a secondary image for a specific frame with processing information (many per frame) rsar_ifg Each row is a RapidSAR interferogram between two dates: used for coherence and unwrap jobs master_proc_stages Each row is a different processing stage for all master images (reference table) ifg_proc_stages Each row is a different processing stage for all secondary images (reference table) rsar_ifg_proc_stages Each row is a different processing stage for all RapidSAR interferograms (reference table) daemon_tools One row which the daemon checks for any new input from users pending_jobs Each row is a pending job the daemon has produced with information about frame, job type etc running_jobs Each row is a running job the daemon has launched with information about frame, job type etc as well as progress information failed_jobs Each row is a failed job the daemon has encountered with information about frame, job type etc The table schema are all stored in the models.py file within the 'database' folder of the satdaemon repository . Each of the (non-secondary) tables is defined using the SQLAlchemy object relational mapper (ORM) syntax. Links between the various tables are established through these models.","title":"Schema and Structure"},{"location":"daemon/#initialisation","text":"Prior to initialisation, PostgreSQL and PostGIS need to be installed. Beware of potential issues with conflicting versions of PostgreSQL, the psql client and PostGIS on the system itself and within a conda environment. Once postgres is installed and running, a database needs to be created, connected to and the PostGIS extension enabled in it, all of which can be done using the psql client: CREATE DATABASE database_name; \\c database_name CREATE EXTENSION postgis; The processing database is initialised using the python script init_database.py , which can be found within the 'database' folder in the satdaemon repository. The database is initialised using the default config file 'satdaemon .cfg', but an alternative config file can be provided using the -d <config-file> flag. SQLite databases can be initialised entirely using the script init_database.py . This creates the database file , creates the various tables and relationships and then inserts bursts, frames and processing stage information. Postgres databases require a Postgres instance to be running before the database can be initialised. Once the Postgres instance has been set up, init_database.py can be used in the same way. Zip files can be inserted in to the database using the script ingest_files.py , found within the 'database ' folder of the satdaemon repository. By default, this will insert all zip files found in subdirectories of the /data directory, provided these subdirectories start with 'T' (e.g. 'T132'). Ingestion of a file automatically links the file to the appropriate frames and bursts in the database. A SQL dump file (produced using pg_dump ) can be used to restore a back-up file or fill a new database with data from an other. This can be done once the database has been initialised as above by using the pg_restore command.","title":"Initialisation"},{"location":"daemon/#bringing-a-database-up-to-date-with-the-state-of-the-file-system","text":"A new (or current) database may be out of sync with the state of the file system. In order for the daemon to know which jobs should be launched, the database must be checked for consistency against the file system. This should only need to be done very infrequently since the daemon will keep the processing database up to date as it processes data. You can use check_db_consistency.py in the main directory of the satdaemon repository. You must provide the config file which contains information about the database and file system you want to check. This script then checks every data and processing folder on the file system, and looks for the most advanced job for each possible date. The database is then updated with the information for each processing date, depending on which jobs have been run for that date. Note: This is not perfect - it assumes the file system is representative of the current state, that files are not corrupt or half processed and that the file system is the ultimate source of truth - use with caution! If you need to create a new database, and have a current database which is up-to-date, it may be better to copy over the data from the current database to the new one. This can be done using appropriate SQL commands such as dump .","title":"Bringing a database up to date with the state of the file system"},{"location":"daemon/#querying-and-updating-the-database","text":"The safest way to query or update the database is by using the functions defined in the dbquery.py module . The current way to do this is to open a python command prompt and establish a connection to the database: from dbquery import Database # get ability to connect to database from models import * # get the database table models dbq = Database() # this is the database connection With the database connection established, we can query, insert, delete or update the database.","title":"Querying and updating the database"},{"location":"daemon/#queries","text":"# to issue a simple query to the database file_id = 'AN_EXAMPLE_FILE_ID' result = dbq.query(File, id=file_id) # note that 'result' is a list, even when only one object is retrieved file = result[0] # the 'file' object has all the attributes of the files table, which can be retrieved path_to_file = file.abspath date = file.date","title":"Queries"},{"location":"daemon/#manual-inserts-updates-and-deletes","text":"If satdaemon is running correctly then you should not need to issue these commands. However, it may be necessary to occasionally perform some manual work on the processing database.","title":"Manual inserts, updates and deletes"},{"location":"daemon/#insert","text":"from datetime import date # to insert a new object in to the database, we make a new instance of it new_file = File(id='EXAMPLE_ID', abspath='PATH/TO/FILE', track=100, orbit_direction='A', date=date(2019,10,1 ), proc_date=date(2019,10,1)) # other fields (last_updated and links to bursts and frames) are automatically filled in by SQLAlchemy dbq.insert(new_file)","title":"Insert"},{"location":"daemon/#update","text":"# to update a pre-existing entry in the database, we issue an update command # the update dictionary tells the database how fields should be updated update_dict = {'track': 101} # the update command is similar to the query command, where keywords are used to specify which rows should be updated dbq.update(File, update_dict, id='EXAMPLE_ID')","title":"Update"},{"location":"daemon/#delete","text":"# to delete an existing row, use the delete command with similar syntax to the query command dbq.delete(File, id=file_id)","title":"Delete"},{"location":"daemon/#more-complex-queries-updates-and-deletes","text":"The query, update and delete commands above work well where equality conditions are used to identify rows of interest . However, if you wish to query using other kinds of operators (e.g. greater than, less than, like, contains etc ) then you need to use a more complex query. See the SQLAlchemy Query API page for more information. To begin one of these more complex queries, it is necessary to start a session . The simpler query, insert, delete and update commands above all begin a session inside them and execute the required commands. To start our own session we use the session_scope context manager to ensure everything runs cleanly: ```python with dbq.session_scope() as session: result = session.query(File).filter(File.date < date(2019, 1, 20)).all() ### Creating a new frame and inserting it into the database The best way to create a new frame and insert it in to the database is to use a list of bursts to define the frame . You can use QGIS to look at the global bursts shapefile, or you can use the bursts section of the processing controller part of the admin website (https://admin.satsense.com/processing_controller/bursts) and note down the bursts you want to use in your new frame . Once you have a list of bursts, open up a connection to the database and use `make_new_frame_using_burstlist`: ```python from dbquery import Database dbq = Database() burstlist = ['132_8603_IW1','132_8612_IW2','132_8594_IW3','132_8575_IW1','132_8584_IW2','132_8566_IW3'] frame_id = '132A_CUSTOM_FRAME' dbq.make_new_frame_using_burstlist(burst_list, frame_id) Burst IDs should be in the format {TRACK}_{ANXID}_{SUBSWATH} , e.g. 132_8603_IW1 . The defined frame name should be in the format {TRACK}{A/D}_{TEXT}_{TEXT} e.g. 132A_CUSTOM_FRAME or 081D_CUSTOM_FRAME . You can check whether the new frame looks correct by plotting all the frames in the database using the python script make_frames_shapefile_db.py . The frame should also appear on the admin website.","title":"More complex queries, updates and deletes"},{"location":"daemon/#setting-a-frame-master-date","text":"Creating a new frame does not automatically give a list of all dates available for that frame. A list of dates for the frame can be obtained by using the commands below: from dbquery import Database dbq = Database() dbq.fill_files_table(frame_id) # Running the command below will result in a master for the frame being automatically chosen if no master is present dbq.update_procdates(frame_id) # Alternatively, give a master date explicitly dbq.update_procdates(frame_id, user_master_date=master_date) # If there is already a master defined and you wish to change it, use the following command. # This will warn you if changing the master would mean reprocessing data dbq.set_master_for_frame(frame_id, master_date)","title":"Setting a frame master date"},{"location":"daemon/#daemon","text":"","title":"Daemon"},{"location":"daemon/#overview","text":"The daemon refers to the automated processor used by SatSense. The daemon uses a config file to determine certain parameters, but once launched, is largely left alone. The daemon consists of three main objects: ProcDaemon , ProcMachine and ProcJob objects. In simple terms, a ProcDaemon object is the daemon itself - it knows what is going on and communicates with the database. A ProcDaemon object knows how many ProcMachine objects it has at its disposal. ProcMachine objects are the processing machines themselves and know what is running on them, as well as their available resources. A ProcDaemon also knows what ProcJobs it can run. ProcJobs run on ProcMachines and these objects know all the relevant information for the job they are associated with.","title":"Overview"},{"location":"daemon/#launching-the-daemon","text":"The daemon can be launched from the command line using the command satdaemon.py . Before launching the daemon, it is very important that you check the config file satdaemon.cfg is set up as you want, and that it is pointing to the right database! You should always launch the daemon in a Linux 'screen' so that it can continue running when you log out of the remote machines. You can run screen -S daemon to establish a daemon screen if one does not already exist. Once the daemon is launched, it will use the specified database to check for new jobs which can be run and launch them in an appropriate order. Jobs will only be run for frames which are set to be processed. Frames can be set to process to different stages depending on need/resource availability. Frames can also be given different priorities, where higher priority frames will be processed before lower priority frames. Note that if a higher priority job cannot be launched because necessary pre-requisites have not been met, or resources are not available, a lower priority job which can be run will be launched.","title":"Launching the daemon"},{"location":"daemon/#controlling-the-daemon","text":"Before launching the daemon, you may want to change the processing parameters for a frame. This can be achieved using the SatDaemonController object and associated methods. Various common operations can be performed using the SatDaemonController, ensuring an easy, safe and clean change to the database. from satdaemon_control import SatDaemonController from datetime import date sdc = SatDaemonController() frame_id = 'EXAMPLE_FRAME' # Turn on full processing for a frame sdc.set_frame_full_proc(frame_id, True) # turn frame off for all processing stages sdc.set_frame_full_proc(frame_id, False) # turn frame off for all processing stages sdc.set_frame_full_proc(frame_id, False) # turn frame on, but only til download (all other stages turned off) sdc.set_frame_download(frame_id, True) # turn frame on, but only til end of SatSAR processing (all other stages turned off) sdc.set_frame_satsar(frame_id, True) # turn frame on, but only til unwrap (all other stages turned off) sdc.set_frame_process_til_timeseries(frame_id, True) # turn frame on, but only initial processing (all updating turned off) sdc.set_frame_noupdate(frame_id, True) # set the processing range for the frame sdc.set_frame_proc_range(frame_id, date(2019, 1, 1), date(2020, 1, 1)) # Set frame priority relative to other frames sdc.set_frame_priority(frame_id, 10) The daemon can also be controlled whilst the daemon is running using these commands. Each of these commands also issues a trigger to the daemon that it should recreate the job list, which it will do in light of any changes made to frame processing parameters.","title":"Controlling the daemon"},{"location":"daemon/#turning-off-the-daemon","text":"The daemon should be turned off using the SatDaemonController. from satdaemon_control import SatDaemonController sdc = SatDaemonController() sdc.power_down_daemon() This will cancel all pending jobs, but the daemon will keep running until currently running jobs are complete. The daemon will then stop running. If you cannot use the method above, you can issue a 'KeyboardInterrupt' if the daemon is running in a terminal, or kill it using the PID. However, these may result in the database and/or files ending up in a confused state. This should be avoided where possible. Before relaunching the daemon, it is important to check the database is not in an incorrect state. Prior to relaunching the daemon, there should be no jobs in the 'running_jobs' table, and there should be no rows in the ifg/master/rsar_ifg tables with a 'proc_status' of 1 (running). A daemon crash may not cause previously launched jobs to crash, and the best way of checking whether there are still jobs running is to check for running python processes on each of the processing machines, which can be done by running the command below in the shell: ps aux | grep python Jobs can take hours to finish. Before relaunching the daemon, let all jobs which had been launched by the daemon finish.","title":"Turning off the daemon"},{"location":"daemon/#error-reporting","text":"Errors may occur in the daemon itself (i.e. within satdaemon.py ) or in one of the jobs launched by the daemon . Errors in the daemon itself will cause the daemon to crash. These errors will be reported to the terminal and to a dedicated Microsoft Teams channel. Any jobs which are marked as running in the processing database will be reset so they can be rerun when the daemon is restarted. Errors within launched jobs are handled by the JobLogger object, created by the launched job itself. Each launched job communicates with the database and Micorsoft Teams using the JobLogger, reporting the processing status of the job, any errors or warnings and, in some cases, the progress of the job. Sometimes, errors within launched jobs are not caught by the JobLogger, and the job stops unexpectedly. In these cases, the return code of the job should be caught by the daemon and the daemon reports to the database and Micorsoft Teams that an error has occurred.","title":"Error reporting"},{"location":"daemon/#handling-crashes","text":"Jobs can sometimes crash unexpectedly, and this can mean the database does not get correctly updated. Possible problems which may occur are: 1. The master/ifg/rsar_ifg row in the corresponding table is not correctly updated. The 'proc_status' column may be stuck on a value of 1 (running), or it may correctly be changed to 4 (failure). 2. The 'running_jobs' table may not have the job removed. This means the job will never be launched again as the database states it is already running. This row needs to be deleted in order to relaunch the job. 3. An error can occur in the actual satdaemon.py script, which causes the daemon itself to crash. A daemon crash means the daemon stops running and no more jobs are launched. Previously launched jobs may still be running - make sure these jobs finish before relaunching the daemon. The best way of checking whether there are still jobs running is to check for running python processes on each of the processing machines, which can be done by running the command below in the shell: ps aux | grep python Jobs can take hours to finish. Before relaunching the daemon, let all jobs which had been launched by the daemon finish.","title":"Handling Crashes"},{"location":"daemon/#graphical-process-monitoring","text":"We are moving towards a web-based, graphical user interface for monitoring and controlling the automated processing. At the moment, we have a web-based monitoring tool, which allows users to see which jobs are running, monitor resource usage and visualise information from the database. This can all be accessed at the admin site: https://admin.satsense.com/processing_controller The processing controller area has pages for each frame and image as well as summaries of currently running jobs, maps of procesing progress and job failures. There is also a separate area with a map showing all global bursts, allowing for easier determination of which bursts to include in a new frame. There is currently no ability to change the daemon or database from the processing controller pages. The processing controller is currently only set up in 'read only' mode.","title":"Graphical Process Monitoring"},{"location":"dataprocessing/","text":"Overview The SatSense InSAR processing chain consists of four main steps: 1. SatSAR: Ingest SAR data from archive and generate single-master interferograms. 2. RapidSAR: Coherence estimation and unwrapping of interferograms. 3. Time-series inversion: Cumulative displacement time-series and velocity. 4. Post-processing: Multiple filtering steps to reduce noise and mitigate signals from tropospheric delays. SatSAR SatSAR is an interferometric software package developed by SatSense, originally derived from LiCSAR . SatSAR uses the Gamma SAR processor as a backend to ingest SAR data from archive, and is developed predominntly in Python. The package is currently undergoing a re-organisation, so this page is subject to change. Package organisation The batch processing to form interferograms consists of three main steps: 1. make_images.py 2. coreg.py 3. make_interferograms.py Gamma functions The four-step scripts described above act as the front end to the processor. Under the hood, they use the Gamma SAR processor: gamma_functions module. The function names in this module correspond one-to-one to Gamma functions, and more documentation on them can be found in the Gamma manual. Database integration The Sentinel-1 satellite acquires data in bursts and swaths. To keep track of these, SatSAR can be run using input files (polygon and ziplist), or using the database. The queries into the database are contained in the satdaemon dbquery module. Processing directory structure A typical SatSAR working directory will contain a number of directories. Below is a description of the main directories: DEM The DEM directory contains the Digital Elevation Model necessary for processing. This can be created using the mk_srtm2insar script. You can use whatever DEM you want, but the files must be named as listed in the table! Below is a table of files that should be in the DEM directory. | File | Description | |--------------|-------------| | dem_crop.dem | Binary file containing the DEM heights | | dem_crop.dem_par | Parameter file associated with the DEM | | dem_crop.dem.ras | Sunraster preview of the DEM | geo The geo directory contains files related to the sensing geometry, like height of every point, latitude, longitude and look angles. Below is a list of important files in this directory. File Description [Masterdate].hgt Binary file containing the height of every point in the master MLI/IFG [Masterdate].lat Binary file containing the latitude of every point in the master MLI/IFG [Masterdate].lon Binary file containing the longitude of every point in the master MLI/IFG [Masterdate].lt Complex binary file containing Lookup table between the master MLI and EQA.dem EQA.dem Binary file containing a crop of the DEM fitted to the processed scene Most of these files have associated preview and/or parameter files. There are quite a few other files in the directory, but you're less likely to need to know about them. All of the above files are created during coregistration , except for the lat and lon files, which are created during post-processing using a separate script . IFG The IFG directory contains files related to interferograms. Within this directory, there are two options for the directory structure, depending on the chosen method during processing. Usually, inside the IFG directory, there will be a singlemaster directory. Inside here, there is a directory for every combinations formed, which will be one combination for each slave image. The other option is that you find combinations directly in the IFG directory. This means that the short temporal baseline combination was chosen, and the number of combinations per image depends on the maximum combination parameter that was used. Whichever method is used, the files inside each combination directory looks the same. | File | Description | |------|-------------| |[combination].diff | Wrapped, unfiltered interferogram | |[combination].sim_unw | Estimated topographic phase | SLC Single Look Complex data. This will only contain the master directory, apart from during the SLC generation. RSLC Registered Single Look Comple data, contains dtaa for each image/acquisition. Note that there are several additional auxillary directories also created. Tutorial At the end of this tutorial you will have: 1. Setup software modules including the SatSAR module 2. Learned basic SatSAR workflow 3. Used SatSAR to process a test frame Some acronyms/terms used throughout this tutorial: | Item | Description | | ----------- | ----------- | SatSAR | The version of LiCSAR used by SatSense LTD. | | Gamma | Commercial software used for various stages of InSAR processing. Throughout the tutorial, wherever you see text between arrows: <LIKE_THIS> This refers to somewhere you are required to provide an input in a bash terminal, or ( python ) terminal (if speficied). Obtaining your own local version of SatSAR First, obtain an ssh key for GitLab by following the instructions here: https://docs.gitlab.com/ee/gitlab-basics/create-your-ssh-keys.html Instructions to generate your ssh key can be found here: https://docs.gitlab.com/ee/ssh/README.html Following this, go to the area you wish to set up your local version of SatSAR, for example: cd <PATH_TO_YOUR_CLONE_LOCATION> e.g. cd /home/karsten/ Activate your ssh key (create with ssh-keygen if necessary): ssh-agent $SHELL ssh-add ~/.ssh/<keyname> Note that you have to do this every time you want to interact with the remote repository. Now, go to the SatSAR GitLab page (https://gitlab.com/SatSenseLtd/SatSAR) and copy the SSH URL found at the top of the page (you may need to swap to SSH from HTTPS using the drop down box). Clone the remote GitLab repository to your local system: git clone <GITLAB_URL> The following should work with the current SatSAR URL: git clone git@gitlab.com:SatSenseLtd/SatSAR.git We will also need the satdaemon repository, which is also on gitlab. Navigate here, and clone it from the same location as you did for SatSAR. Setting up SatSAR SatSAR uses Gamma, implemented within the SatSense software written in python. In order to begin processing, you need to set up the appropriate software. At SatSense, we have Gamma and python installed as modules or applications. Begin by setting these up using: module load canopy python-libs gamma/20180704 This will import various python modules and set up Gamma as required for processing. Next, source the LiCSAR software. There is already a LiCSAR_source.sh file in your local SatSAR folder, which should be copied to a different location and updated as follows: LiCSARpath=<PATH_TO_YOUR_SATSAR_FOLDER> e.g. LiCSARpath=/home/karsten/SatSAR Source your updated LiCSAR_source.sh file: source <PATH_TO_YOUR_CONFIG_FILE>/LiCSAR_source.sh e.g. source /home/karsten/LiCSAR_source.sh You could put these commands in your bashrc/cshrc file such that they run when you load a new terminal Finally, make an empty folder entitled \"temp\" and then make a new environmental variable ,$LiCSAR_temp, in your bashrc/cshrc file, by adding the following command: export LiCSAR_temp=\"<PATH_TO_YOUR_TEMP>\" ``` e.g. ```shell export LiCSAR_temp=/home/karsten/temp Using SatSAR on the SatSense Virtual Machines This will take you through getting started processing on the Virtual Machines (VM). There are currently two virtual machines (VM3 and VM4) at SatSense for processing. This also requires a .bashrc file with correct paths and loading the satsense_live conda environment. To access the virtual machines from your local Ubuntu terminal: ssh -X -p 2223 user@93.93.133.78 ssh -X -p 2222 user@93.93.133.78 Now you are on the virtual machine, check the data storage availability on the rust disks (rust0 to 3, 115 TB each) prior to starting processing: df -h Set the emptiest of these to store the downloaded files through the intial processing stages: RUSTDIR=rust0 echo $RUSTDIR Downloaded SAR data is stored in: /data/ Any subsequent frame products are stored in: /workspace/frames/ When processing, login to centos (root privelidges account): sudo su centos If using the database for frame processing ( python ): from dbquery import Database from dbquery import Frame dbq = Database() Several of the following steps take a while to run so do this in a screen : screen -S proc_guide Directory set-up and data download Prior to dowloading data, check if a track data directory already exists (e.g. T000, from pre-existing defined frames). TRACK=000 ORB=D ls /data/T${TRACK} If not, create this in the data directory of the rust disk which has the most remaining space. cd /${RUSTDIR}/data/ mkdir T${TRACK} The data directory must now be linked to rust2. cd /rust2/data/ ln -s /${RUSTDIR}/data/${TRACK} . Similarly we need to create a frame processing directory for processing. Framenames are self defined but must contain the track name and orbit, and then two additional strings separated by underscores (e.g. 000A_UK_131313). The second string can be used to direct the user to the location (either name or colatitude), whilst the third string is typically used to inform a user of the number of bursts in each subswath within the frame (see ASF/SciHub/QGIS). If you want make typing things in easier, set a bash environment variable for the framename: FRAMENAME=${TRACK}${ORB}_UK_131313 echo $FRAMENAME cd /${RUSTDIR}/workspace/frames/ mkdir $FRAMENAME The frame directory must now be linked to the rust2 workspace directory. cd /rust2/workspace/frames/ ln -s /${RUSTDIR}/workspace/frames/${FRAMENAME} . To set up a frame in the database ( python ): fid = '000A_UK_131313' bl = ['000_12345_IW1', '000_12345_IW2', '000_12345_IW3'] dbq.make_new_frame_using_burstlist(bl, fid) To check the set-up is succesful, try ( python ): frame = dbq.query(Frame, id=fid)[0] print(frame.id, frame.track) If using the frame database for processing, it is good practice to update the database with the data download location ( python ). dbq.update(Frame, {'downloaddir':'/data/T000'}, id=fid) Now download some data (replace input flags). Once the data has been unzipped, remember to delete the zip files to save memory on the virtual machines. master_download_script.py -f $FRAMENAME -d /data/T${TRACK}/ The MASTERDATE is now defined if using the database ( python ): frame = dbq.query(Frame, id=fid)[0] frame.master[0].date.strftime('%Y%m%d') MASTERDATE=YYYYMMDD echo $MASTERDATE The final remaining step prior to processing is to create a DEM. Within the frame directory: cd /workspace/frames/$FRAMENAME make_frame_dem.py -d /data/SRTM -f $FRAMENAME -o DEM Check the .bmp file in the output directory to confirm the DEM is correct ( eog DEM/*.bmp ). Processing overview Now that SatSAR has been set up, you can start using it. The commands for each stage of the processing are summarised below: make_images.py -d `pwd` -f $FRAMENAME -m $MASTERDATE coreg.py -d `pwd` -f $FRAMENAME -m $MASTERDATE make_interferograms.py -d `pwd` -f $FRAMENAME -s A summary of the input argument placeholders: | Placeholder | Description | | ----------- | ----------- | | WORKDIR | Working directory for the frame processing ( pwd ) | | FRAMENAME | The name of the frame you want to process | MASTERDATE | The master date | RapidSAR time-series processing Following the initial single-master processing with SatSAR, we now run the rest of the time-series processing with RapidSAR. Within the processing directory, create a RapidSAR working directory. It is also worth running these commands in a screen as they can take a while. mkdir RapidSAR Prior to running the ingest step of RapidSAR, we need to generate some files in the geo directory: get_lonlat.py -d `pwd` -f $FRAMENAME get_look_angles.py -d `pwd` -f $FRAMENAME If cropping the data down prior to running the time-series analysis, at this stage run (and use the output during the RapidSAR ingestion, also recommend saving to text file for future reference): get_lonlatbounds_shp.py -s .shp get_crop_area.py -d `pwd` -p top,bottom,left,right To ingest the processed data into RapidSAR, run: RapidSAR_ingest.py RSLC IFG data.h5 -f $FRAMENAME [-c top,bottom,left,right] There will now be a single data.h5 file in the directory (to list its contents: h5ls data.h5 ). Coherence estimation The next step is to use the sibling coherence method to accurately estimate the coherence on a pixel. Previous measures use a window surrounding the pixel to estimate the coherence. However this estimation breaks down if pixels are adjacent to non-similar pixels (e.g. the edge of buildings). Instead the sibling method identifies similar points within the image (up to 100 siblings per pixel) and uses these to estimate the coherence. RapidSAR_find_siblings.py RSLC IFG data.h5 Coherence -f $FRAMENAME This creates a .shp file (statistically homegenous pixels, i.e. siblings, not a QGIS format...) and a coh.h5 file. For more details on the sibling coherence method, see: Spaans K, Hooper A. InSAR processing for volcano monitoring and other near\u2010real time applications (2016). JGR Solid Earth . Unwrapping For the unwrapping, we use the algorithm/program SNAPHU (Chen and Zebker, Stanford). This converts wrapped phase (-\u03c0 to \u03c0) to continuous unwrapped phase (also in radians). The [-c] flag is the phase variance threshold (any pixels above this are considered noise). RapidSAR_unwrap.py IFG Coherence data.h5 RSLC -f $FRAMENAME This process creates a file uw.h5 within the RapidSAR directory. The uw.h5 file contains two unwrapped datasets. The first is the \"high resolution\" (full) unwrapped interferograms. The second is the lower resolution \"rural\" dataset. The rural dataset is multi-looked (downsampled) with 3 looks in range and 12 looks in azimuth (Sentinel-1 data is acquired in non-square pixels, this ratio converts to approximately square). The rural data has a more coarse resolution which makes it easier to handle (look at the differences in file size of the output velocity maps in the next step). The pixel size is approximately 50 m \u00d7 50 m. There is currently an issue with rural datasets in that they are affected by fading phase-bias (see: Ansari, H., De Zan, F. and Parizzi, A. Study of Systematic Bias in Measuring Surface Deformation with SAR Interferometry (2020) IEEE ). The source of the bias remains unknown, however it results in the apparent subsidence of rural pixels and is more pronounced in short temporal baseline interferograms. Time-series inversion The time-series inversion is run on both the rural and high-resolution datasets. An overly simplified description of the time-series inversion is that it is solving a least-squares inversion for the displacement of each image relative to the first date in the time-series, from the network phase displacements in each interferogram in the interferometric network. This generates a displacement time-series which can then be used to derive the average velocity of each pixel in the line-of-sight (LOS). In practice this is more complex, including referencing the time-series in space and time, running the inversion multiple times to detect unwrapping errors, and mapping out islands in the track extent using the DEM. We run this in two stages (rural resolution, then full resolution): multicore_ts.py Coherence data.h5 ${FRAMENAME}-rural-vel.h5 -f $FRAMENAME -l multicore_ts.py Coherence data.h5 ${FRAMENAME}-vel.h5 -f $FRAMENAME -z ${FRAMENAME}-rural-vel.h5 Post-processing multicore_postproc.py -d ${FRAMENAME}-rural-vel.h5 -i ${FRAMENAME}-vel.h5 -p data.h5 -f $FRAMENAME SatSense 'standard' post-processing applies several steps to the \"Cumulative_Displacement\" dataset to create new datasets in the *-vel.h5 files. * Remove long-wavelength signals with a 30 km Gaussian filter (\"Cumulative_Displacement_Filt\"). * APS filter: using the assumption that atmosphere should be random in time (high-pass) but correlated in space (low-pass)(\"Cumulative_Displacement_APS\"). * Smooth displacement time-series in time using a triangular weighted smoothing (\"Cumulative_Displacement_TSmooth\"). This also calculates the RMS error for the time-series. It is possible to skip options with flags (use input \"SKIP\"), however then watch out for default inputs in subsequent steps. An additional required post-processing step is the reliable pixels estimation. This recognises pixels affected by rural bias and removes them. To run this: get_reliable_pixels.py -d ${FRAMENAME}-rural-vel.h5 -i ${FRAMENAME}-vel.h5 -p data.h5 -f 0 Data export to QGIS After this, it is possible to generate shapefiles for export to QGIS: rsar_extract.py -d ${FRAMENAME}-vel.h5 -e data.h5 -o $FRAMENAME -r REF.shp -p linear,seasonal rsar_extract.py -d ${FRAMENAME}-rural-vel.h5 -e data.h5 -o ${FRAMENAME}_RURAL -r REF.shp -p linear,seasonal","title":"Overview"},{"location":"dataprocessing/#overview","text":"The SatSense InSAR processing chain consists of four main steps: 1. SatSAR: Ingest SAR data from archive and generate single-master interferograms. 2. RapidSAR: Coherence estimation and unwrapping of interferograms. 3. Time-series inversion: Cumulative displacement time-series and velocity. 4. Post-processing: Multiple filtering steps to reduce noise and mitigate signals from tropospheric delays.","title":"Overview"},{"location":"dataprocessing/#satsar","text":"SatSAR is an interferometric software package developed by SatSense, originally derived from LiCSAR . SatSAR uses the Gamma SAR processor as a backend to ingest SAR data from archive, and is developed predominntly in Python. The package is currently undergoing a re-organisation, so this page is subject to change.","title":"SatSAR"},{"location":"dataprocessing/#package-organisation","text":"The batch processing to form interferograms consists of three main steps: 1. make_images.py 2. coreg.py 3. make_interferograms.py","title":"Package organisation"},{"location":"dataprocessing/#gamma-functions","text":"The four-step scripts described above act as the front end to the processor. Under the hood, they use the Gamma SAR processor: gamma_functions module. The function names in this module correspond one-to-one to Gamma functions, and more documentation on them can be found in the Gamma manual.","title":"Gamma functions"},{"location":"dataprocessing/#database-integration","text":"The Sentinel-1 satellite acquires data in bursts and swaths. To keep track of these, SatSAR can be run using input files (polygon and ziplist), or using the database. The queries into the database are contained in the satdaemon dbquery module.","title":"Database integration"},{"location":"dataprocessing/#processing-directory-structure","text":"A typical SatSAR working directory will contain a number of directories. Below is a description of the main directories:","title":"Processing directory structure"},{"location":"dataprocessing/#dem","text":"The DEM directory contains the Digital Elevation Model necessary for processing. This can be created using the mk_srtm2insar script. You can use whatever DEM you want, but the files must be named as listed in the table! Below is a table of files that should be in the DEM directory. | File | Description | |--------------|-------------| | dem_crop.dem | Binary file containing the DEM heights | | dem_crop.dem_par | Parameter file associated with the DEM | | dem_crop.dem.ras | Sunraster preview of the DEM |","title":"DEM"},{"location":"dataprocessing/#geo","text":"The geo directory contains files related to the sensing geometry, like height of every point, latitude, longitude and look angles. Below is a list of important files in this directory. File Description [Masterdate].hgt Binary file containing the height of every point in the master MLI/IFG [Masterdate].lat Binary file containing the latitude of every point in the master MLI/IFG [Masterdate].lon Binary file containing the longitude of every point in the master MLI/IFG [Masterdate].lt Complex binary file containing Lookup table between the master MLI and EQA.dem EQA.dem Binary file containing a crop of the DEM fitted to the processed scene Most of these files have associated preview and/or parameter files. There are quite a few other files in the directory, but you're less likely to need to know about them. All of the above files are created during coregistration , except for the lat and lon files, which are created during post-processing using a separate script .","title":"geo"},{"location":"dataprocessing/#ifg","text":"The IFG directory contains files related to interferograms. Within this directory, there are two options for the directory structure, depending on the chosen method during processing. Usually, inside the IFG directory, there will be a singlemaster directory. Inside here, there is a directory for every combinations formed, which will be one combination for each slave image. The other option is that you find combinations directly in the IFG directory. This means that the short temporal baseline combination was chosen, and the number of combinations per image depends on the maximum combination parameter that was used. Whichever method is used, the files inside each combination directory looks the same. | File | Description | |------|-------------| |[combination].diff | Wrapped, unfiltered interferogram | |[combination].sim_unw | Estimated topographic phase |","title":"IFG"},{"location":"dataprocessing/#slc","text":"Single Look Complex data. This will only contain the master directory, apart from during the SLC generation.","title":"SLC"},{"location":"dataprocessing/#rslc","text":"Registered Single Look Comple data, contains dtaa for each image/acquisition. Note that there are several additional auxillary directories also created.","title":"RSLC"},{"location":"dataprocessing/#tutorial","text":"At the end of this tutorial you will have: 1. Setup software modules including the SatSAR module 2. Learned basic SatSAR workflow 3. Used SatSAR to process a test frame Some acronyms/terms used throughout this tutorial: | Item | Description | | ----------- | ----------- | SatSAR | The version of LiCSAR used by SatSense LTD. | | Gamma | Commercial software used for various stages of InSAR processing. Throughout the tutorial, wherever you see text between arrows: <LIKE_THIS> This refers to somewhere you are required to provide an input in a bash terminal, or ( python ) terminal (if speficied).","title":"Tutorial"},{"location":"dataprocessing/#obtaining-your-own-local-version-of-satsar","text":"First, obtain an ssh key for GitLab by following the instructions here: https://docs.gitlab.com/ee/gitlab-basics/create-your-ssh-keys.html Instructions to generate your ssh key can be found here: https://docs.gitlab.com/ee/ssh/README.html Following this, go to the area you wish to set up your local version of SatSAR, for example: cd <PATH_TO_YOUR_CLONE_LOCATION> e.g. cd /home/karsten/ Activate your ssh key (create with ssh-keygen if necessary): ssh-agent $SHELL ssh-add ~/.ssh/<keyname> Note that you have to do this every time you want to interact with the remote repository. Now, go to the SatSAR GitLab page (https://gitlab.com/SatSenseLtd/SatSAR) and copy the SSH URL found at the top of the page (you may need to swap to SSH from HTTPS using the drop down box). Clone the remote GitLab repository to your local system: git clone <GITLAB_URL> The following should work with the current SatSAR URL: git clone git@gitlab.com:SatSenseLtd/SatSAR.git We will also need the satdaemon repository, which is also on gitlab. Navigate here, and clone it from the same location as you did for SatSAR.","title":"Obtaining your own local version of SatSAR"},{"location":"dataprocessing/#setting-up-satsar","text":"SatSAR uses Gamma, implemented within the SatSense software written in python. In order to begin processing, you need to set up the appropriate software. At SatSense, we have Gamma and python installed as modules or applications. Begin by setting these up using: module load canopy python-libs gamma/20180704 This will import various python modules and set up Gamma as required for processing. Next, source the LiCSAR software. There is already a LiCSAR_source.sh file in your local SatSAR folder, which should be copied to a different location and updated as follows: LiCSARpath=<PATH_TO_YOUR_SATSAR_FOLDER> e.g. LiCSARpath=/home/karsten/SatSAR Source your updated LiCSAR_source.sh file: source <PATH_TO_YOUR_CONFIG_FILE>/LiCSAR_source.sh e.g. source /home/karsten/LiCSAR_source.sh You could put these commands in your bashrc/cshrc file such that they run when you load a new terminal Finally, make an empty folder entitled \"temp\" and then make a new environmental variable ,$LiCSAR_temp, in your bashrc/cshrc file, by adding the following command: export LiCSAR_temp=\"<PATH_TO_YOUR_TEMP>\" ``` e.g. ```shell export LiCSAR_temp=/home/karsten/temp","title":"Setting up SatSAR"},{"location":"dataprocessing/#using-satsar-on-the-satsense-virtual-machines","text":"This will take you through getting started processing on the Virtual Machines (VM). There are currently two virtual machines (VM3 and VM4) at SatSense for processing. This also requires a .bashrc file with correct paths and loading the satsense_live conda environment. To access the virtual machines from your local Ubuntu terminal: ssh -X -p 2223 user@93.93.133.78 ssh -X -p 2222 user@93.93.133.78 Now you are on the virtual machine, check the data storage availability on the rust disks (rust0 to 3, 115 TB each) prior to starting processing: df -h Set the emptiest of these to store the downloaded files through the intial processing stages: RUSTDIR=rust0 echo $RUSTDIR Downloaded SAR data is stored in: /data/ Any subsequent frame products are stored in: /workspace/frames/ When processing, login to centos (root privelidges account): sudo su centos If using the database for frame processing ( python ): from dbquery import Database from dbquery import Frame dbq = Database() Several of the following steps take a while to run so do this in a screen : screen -S proc_guide","title":"Using SatSAR on the SatSense Virtual Machines"},{"location":"dataprocessing/#directory-set-up-and-data-download","text":"Prior to dowloading data, check if a track data directory already exists (e.g. T000, from pre-existing defined frames). TRACK=000 ORB=D ls /data/T${TRACK} If not, create this in the data directory of the rust disk which has the most remaining space. cd /${RUSTDIR}/data/ mkdir T${TRACK} The data directory must now be linked to rust2. cd /rust2/data/ ln -s /${RUSTDIR}/data/${TRACK} . Similarly we need to create a frame processing directory for processing. Framenames are self defined but must contain the track name and orbit, and then two additional strings separated by underscores (e.g. 000A_UK_131313). The second string can be used to direct the user to the location (either name or colatitude), whilst the third string is typically used to inform a user of the number of bursts in each subswath within the frame (see ASF/SciHub/QGIS). If you want make typing things in easier, set a bash environment variable for the framename: FRAMENAME=${TRACK}${ORB}_UK_131313 echo $FRAMENAME cd /${RUSTDIR}/workspace/frames/ mkdir $FRAMENAME The frame directory must now be linked to the rust2 workspace directory. cd /rust2/workspace/frames/ ln -s /${RUSTDIR}/workspace/frames/${FRAMENAME} . To set up a frame in the database ( python ): fid = '000A_UK_131313' bl = ['000_12345_IW1', '000_12345_IW2', '000_12345_IW3'] dbq.make_new_frame_using_burstlist(bl, fid) To check the set-up is succesful, try ( python ): frame = dbq.query(Frame, id=fid)[0] print(frame.id, frame.track) If using the frame database for processing, it is good practice to update the database with the data download location ( python ). dbq.update(Frame, {'downloaddir':'/data/T000'}, id=fid) Now download some data (replace input flags). Once the data has been unzipped, remember to delete the zip files to save memory on the virtual machines. master_download_script.py -f $FRAMENAME -d /data/T${TRACK}/ The MASTERDATE is now defined if using the database ( python ): frame = dbq.query(Frame, id=fid)[0] frame.master[0].date.strftime('%Y%m%d') MASTERDATE=YYYYMMDD echo $MASTERDATE The final remaining step prior to processing is to create a DEM. Within the frame directory: cd /workspace/frames/$FRAMENAME make_frame_dem.py -d /data/SRTM -f $FRAMENAME -o DEM Check the .bmp file in the output directory to confirm the DEM is correct ( eog DEM/*.bmp ).","title":"Directory set-up and data download"},{"location":"dataprocessing/#processing-overview","text":"Now that SatSAR has been set up, you can start using it. The commands for each stage of the processing are summarised below: make_images.py -d `pwd` -f $FRAMENAME -m $MASTERDATE coreg.py -d `pwd` -f $FRAMENAME -m $MASTERDATE make_interferograms.py -d `pwd` -f $FRAMENAME -s A summary of the input argument placeholders: | Placeholder | Description | | ----------- | ----------- | | WORKDIR | Working directory for the frame processing ( pwd ) | | FRAMENAME | The name of the frame you want to process | MASTERDATE | The master date |","title":"Processing overview"},{"location":"dataprocessing/#rapidsar-time-series-processing","text":"Following the initial single-master processing with SatSAR, we now run the rest of the time-series processing with RapidSAR. Within the processing directory, create a RapidSAR working directory. It is also worth running these commands in a screen as they can take a while. mkdir RapidSAR Prior to running the ingest step of RapidSAR, we need to generate some files in the geo directory: get_lonlat.py -d `pwd` -f $FRAMENAME get_look_angles.py -d `pwd` -f $FRAMENAME If cropping the data down prior to running the time-series analysis, at this stage run (and use the output during the RapidSAR ingestion, also recommend saving to text file for future reference): get_lonlatbounds_shp.py -s .shp get_crop_area.py -d `pwd` -p top,bottom,left,right To ingest the processed data into RapidSAR, run: RapidSAR_ingest.py RSLC IFG data.h5 -f $FRAMENAME [-c top,bottom,left,right] There will now be a single data.h5 file in the directory (to list its contents: h5ls data.h5 ).","title":"RapidSAR time-series processing"},{"location":"dataprocessing/#coherence-estimation","text":"The next step is to use the sibling coherence method to accurately estimate the coherence on a pixel. Previous measures use a window surrounding the pixel to estimate the coherence. However this estimation breaks down if pixels are adjacent to non-similar pixels (e.g. the edge of buildings). Instead the sibling method identifies similar points within the image (up to 100 siblings per pixel) and uses these to estimate the coherence. RapidSAR_find_siblings.py RSLC IFG data.h5 Coherence -f $FRAMENAME This creates a .shp file (statistically homegenous pixels, i.e. siblings, not a QGIS format...) and a coh.h5 file. For more details on the sibling coherence method, see: Spaans K, Hooper A. InSAR processing for volcano monitoring and other near\u2010real time applications (2016). JGR Solid Earth .","title":"Coherence estimation"},{"location":"dataprocessing/#unwrapping","text":"For the unwrapping, we use the algorithm/program SNAPHU (Chen and Zebker, Stanford). This converts wrapped phase (-\u03c0 to \u03c0) to continuous unwrapped phase (also in radians). The [-c] flag is the phase variance threshold (any pixels above this are considered noise). RapidSAR_unwrap.py IFG Coherence data.h5 RSLC -f $FRAMENAME This process creates a file uw.h5 within the RapidSAR directory. The uw.h5 file contains two unwrapped datasets. The first is the \"high resolution\" (full) unwrapped interferograms. The second is the lower resolution \"rural\" dataset. The rural dataset is multi-looked (downsampled) with 3 looks in range and 12 looks in azimuth (Sentinel-1 data is acquired in non-square pixels, this ratio converts to approximately square). The rural data has a more coarse resolution which makes it easier to handle (look at the differences in file size of the output velocity maps in the next step). The pixel size is approximately 50 m \u00d7 50 m. There is currently an issue with rural datasets in that they are affected by fading phase-bias (see: Ansari, H., De Zan, F. and Parizzi, A. Study of Systematic Bias in Measuring Surface Deformation with SAR Interferometry (2020) IEEE ). The source of the bias remains unknown, however it results in the apparent subsidence of rural pixels and is more pronounced in short temporal baseline interferograms.","title":"Unwrapping"},{"location":"dataprocessing/#time-series-inversion","text":"The time-series inversion is run on both the rural and high-resolution datasets. An overly simplified description of the time-series inversion is that it is solving a least-squares inversion for the displacement of each image relative to the first date in the time-series, from the network phase displacements in each interferogram in the interferometric network. This generates a displacement time-series which can then be used to derive the average velocity of each pixel in the line-of-sight (LOS). In practice this is more complex, including referencing the time-series in space and time, running the inversion multiple times to detect unwrapping errors, and mapping out islands in the track extent using the DEM. We run this in two stages (rural resolution, then full resolution): multicore_ts.py Coherence data.h5 ${FRAMENAME}-rural-vel.h5 -f $FRAMENAME -l multicore_ts.py Coherence data.h5 ${FRAMENAME}-vel.h5 -f $FRAMENAME -z ${FRAMENAME}-rural-vel.h5","title":"Time-series inversion"},{"location":"dataprocessing/#post-processing","text":"multicore_postproc.py -d ${FRAMENAME}-rural-vel.h5 -i ${FRAMENAME}-vel.h5 -p data.h5 -f $FRAMENAME SatSense 'standard' post-processing applies several steps to the \"Cumulative_Displacement\" dataset to create new datasets in the *-vel.h5 files. * Remove long-wavelength signals with a 30 km Gaussian filter (\"Cumulative_Displacement_Filt\"). * APS filter: using the assumption that atmosphere should be random in time (high-pass) but correlated in space (low-pass)(\"Cumulative_Displacement_APS\"). * Smooth displacement time-series in time using a triangular weighted smoothing (\"Cumulative_Displacement_TSmooth\"). This also calculates the RMS error for the time-series. It is possible to skip options with flags (use input \"SKIP\"), however then watch out for default inputs in subsequent steps. An additional required post-processing step is the reliable pixels estimation. This recognises pixels affected by rural bias and removes them. To run this: get_reliable_pixels.py -d ${FRAMENAME}-rural-vel.h5 -i ${FRAMENAME}-vel.h5 -p data.h5 -f 0","title":"Post-processing"},{"location":"dataprocessing/#data-export-to-qgis","text":"After this, it is possible to generate shapefiles for export to QGIS: rsar_extract.py -d ${FRAMENAME}-vel.h5 -e data.h5 -o $FRAMENAME -r REF.shp -p linear,seasonal rsar_extract.py -d ${FRAMENAME}-rural-vel.h5 -e data.h5 -o ${FRAMENAME}_RURAL -r REF.shp -p linear,seasonal","title":"Data export to QGIS"},{"location":"jira/","text":"Jira The current SatSense Jira board is set up here . This board is actually the board for a project called \"SatSense Devs\", but it pulls in the issues for the other projects. The following details on how this board was set up, linking it to multiple projects, and integrating with Gitlab. We assume that the user has set up an account . Projects Create Project (all except the \"SatSense Devs\" board) To create a normal project, i.e. not one whose board that needs to be able to pull in issues from other projects: In the upper nav bar, click \"Projects\" and then \"Create project\". Click \"Scrum\" and then \"Use Template\", this will add the ability to add a backlog and sprints. Select \"Team Managed\" - whilst this has fewer features than \"Company Managed\", it is must easier to get going. Enter name and key and click \"Create\". Amend workflow Go to project board (click \"Projects\" and then select your project, the default view goes to the project board) Click three dots in top right, then \"Manage workflow\". Manage workflow - for example to add an \"In Review\" column, click \"In-progress status\" at the top and type to create. Save and close. SatSense Devs Project In this section we'll create a project that can pull in issues from other projects. To create a board for multiple projects you first need to create a filter. In the upper nav bar, click \"Projects\" and then \"Create project\". Click \"Scrum\" and then \"Use Template\", this will add the ability to add a backlog and sprints. Select \"Company Managed\" (compare with the above), this type of board will allow issues to be imported into this project. Enter name and key and click \"Create\". Create Filter Once the project board is created, we need to amend the filter to allow access to other project issues. From top nav bar, click \"Filters\" and then \"View all Filters\". Click \"Filter for board\" in top right. Click \"Switch to JQL\". Enter a statement, for example project = POR OR project = API or project = AD ORDER BY Rank ASC will pull in all the issues from the POR , API and AD projects. Click \"Save\" Map statuses You might find that issues you expected to appear do not appear on your project board. This is likely to be a problem with unmapped statuses. Go to the board column settings: When viewing board, click three dots in top right and click \"Board settings\". Click \"Columns\" under \"Settings\" menu You can add columns if needed (for instance, if you created a \"In Review\" column for your project, you might want to do it here also). Click and drag statuses from the \"Unmapped Statuses\" column to the required column. You should now be able to see the issues as expected. Gitlab Integration Add gitlab to jira In nav bar, click \"Apps\" and then \"Find new apps\". Search for \"gitlab.com for Jira Cloud\" and follow the instructions. Create api token on jira Go to https://id.atlassian.com/manage-profile/security/api-tokens page. Rest is self explanatory. Enable authorisation on gitlab We currently have only done this on a per project basis (projects include satsense-portal, satsense-admin, satsense-domain, satsense-api, postgresingester, sat-tileserver) Go to project or group integrations - Whilst viewing project or group, click \"Settings\" then \"Integrations\". Click on \"Jira\" in the list. Fill in form, hints for settings: \"Web URL\": https://satsense.atlassian.net \"Username or Email\": bob.ross@satsense.com \"Password or API token\": <value created in previous section>","title":"Jira"},{"location":"jira/#jira","text":"The current SatSense Jira board is set up here . This board is actually the board for a project called \"SatSense Devs\", but it pulls in the issues for the other projects. The following details on how this board was set up, linking it to multiple projects, and integrating with Gitlab. We assume that the user has set up an account .","title":"Jira"},{"location":"jira/#projects","text":"","title":"Projects"},{"location":"jira/#create-project-all-except-the-satsense-devs-board","text":"To create a normal project, i.e. not one whose board that needs to be able to pull in issues from other projects: In the upper nav bar, click \"Projects\" and then \"Create project\". Click \"Scrum\" and then \"Use Template\", this will add the ability to add a backlog and sprints. Select \"Team Managed\" - whilst this has fewer features than \"Company Managed\", it is must easier to get going. Enter name and key and click \"Create\".","title":"Create Project (all except the \"SatSense Devs\" board)"},{"location":"jira/#amend-workflow","text":"Go to project board (click \"Projects\" and then select your project, the default view goes to the project board) Click three dots in top right, then \"Manage workflow\". Manage workflow - for example to add an \"In Review\" column, click \"In-progress status\" at the top and type to create. Save and close.","title":"Amend workflow"},{"location":"jira/#satsense-devs-project","text":"In this section we'll create a project that can pull in issues from other projects. To create a board for multiple projects you first need to create a filter. In the upper nav bar, click \"Projects\" and then \"Create project\". Click \"Scrum\" and then \"Use Template\", this will add the ability to add a backlog and sprints. Select \"Company Managed\" (compare with the above), this type of board will allow issues to be imported into this project. Enter name and key and click \"Create\".","title":"SatSense Devs Project"},{"location":"jira/#create-filter","text":"Once the project board is created, we need to amend the filter to allow access to other project issues. From top nav bar, click \"Filters\" and then \"View all Filters\". Click \"Filter for board\" in top right. Click \"Switch to JQL\". Enter a statement, for example project = POR OR project = API or project = AD ORDER BY Rank ASC will pull in all the issues from the POR , API and AD projects. Click \"Save\"","title":"Create Filter"},{"location":"jira/#map-statuses","text":"You might find that issues you expected to appear do not appear on your project board. This is likely to be a problem with unmapped statuses. Go to the board column settings: When viewing board, click three dots in top right and click \"Board settings\". Click \"Columns\" under \"Settings\" menu You can add columns if needed (for instance, if you created a \"In Review\" column for your project, you might want to do it here also). Click and drag statuses from the \"Unmapped Statuses\" column to the required column. You should now be able to see the issues as expected.","title":"Map statuses"},{"location":"jira/#gitlab-integration","text":"","title":"Gitlab Integration"},{"location":"jira/#add-gitlab-to-jira","text":"In nav bar, click \"Apps\" and then \"Find new apps\". Search for \"gitlab.com for Jira Cloud\" and follow the instructions.","title":"Add gitlab to jira"},{"location":"jira/#create-api-token-on-jira","text":"Go to https://id.atlassian.com/manage-profile/security/api-tokens page. Rest is self explanatory.","title":"Create api token on jira"},{"location":"jira/#enable-authorisation-on-gitlab","text":"We currently have only done this on a per project basis (projects include satsense-portal, satsense-admin, satsense-domain, satsense-api, postgresingester, sat-tileserver) Go to project or group integrations - Whilst viewing project or group, click \"Settings\" then \"Integrations\". Click on \"Jira\" in the list. Fill in form, hints for settings: \"Web URL\": https://satsense.atlassian.net \"Username or Email\": bob.ross@satsense.com \"Password or API token\": <value created in previous section>","title":"Enable authorisation on gitlab"},{"location":"sftp_user_setup/","text":"All of the below should be done on the API machine, not the standard virtual machines ssh -p 2222 centos@satsense-api.mb1.unipart.io Also most of the commands require prefixing with sudo . Create User Add user to sftpusers group and set password useradd -M -g sftpusers -d /files -s /sbin/nologin -e `date -d \"14 days\" +\"%Y-%m-%d\"` <user_name> passwd <user_name> Here: * -M ensures that home directory is not created for this user; * -g sets the group of the user; * -d sets the home directory of the user. Note that we've told the command not to create this directory - we will deal with the creation of the home momentarily; * -s sets the shell that is to be used by the user. The value /sbin/nologin means that the user cannot open a shell on the server. This isn't necessary but good practice for sftp-only users. * -e sets the expiry date for the user, in the above the user expires after 14 days. Note that if you need to extend the expiry date for a user, you can query what the expiry settings with: chage -l <username> To set the expiry to 14 days from now: chage -E $(date -d +14days +%Y-%m-%d) <username> Create User Home Directory The following assumes that sftp ChrootDirectory has been set to /rust2/sftp/<user_name> . At the time of writing, this is correct and continuing with the below commands is most likely to work. However, if you are a cautious individual, you can check the file /etc/ssh/sshd_config to make sure this is the case. To create the home directory: 1. mkdir -p /rust2/sftp/<user_name>/files/ 2. chown root:sftpusers /rust2/sftp/<user_name> 3. chown <user_name>:sftpusers /rust2/sftp/<user_name>/files Note that line 2 will give the user read access to everything inside their Chroot, whereas line 3 will give them read and write access to the /files folder. Also note that every directory in the path of /rust2/sftp/ needs to be owned by root and to not be writable by anyone else. Ensure that any files copied (likely also requires sudo; also files cannot be linked) into the /files folder have the correct permissions. The external user can now download with (in bash ): wget *.zip","title":"Sftp user setup"},{"location":"client-facing-applications/admin/","text":"Admin Suite (satadmin) This is a web application with two main responsibilies: allow the management of users on the portal/satshop and api. monitor/control the processing of SatSense data. Instructions for how to install an instance of the admin suite into a virtual environment are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with how to set up apache to forward on requests. Contents Live Server Locations - where files related to the admin suite are kept on the live server. First Release - how to release a brand new admin suite. Release Update - how to release an update to an admin suite that's already been released. Troubleshooting - something not working? No problem. Live Server Locations On the live server, we run several portals and in turn we therefore run several admin suites (which deal with the separate user databases). This is a list of the admin suites that are running, along with locations of related important files: Admin instance name Domain end point Associated portal name Project directory Httpd config file Systemd file satshop admin admin.satsense.com satshop /var/www/admin-live /etc/httpd/sites-available/admin-live.conf /etc/systemd/system/adminlive.service staging admin admin.staging.satsense.com staging /var/www/admin-staging /etc/httpd/sites-available/admin-staging.conf /etc/systemd/system/adminstaging.service portal2 admin portal2.satsense.com/admin portal2 /var/www/admin2 shared with portal2 i.e. /etc/httpd/sites-available/flask-portal2.conf /etc/systemd/system/admin2.service portal3 admin portal3.satsense.com/admin portal3 /var/www/admin3 shared with portal3 i.e. /etc/httpd/sites-available/portal3.conf /etc/systemd/system/admin3.service Notice that \"portal2 admin\" and \"portal3 admin\" share a domain with portal2 and portal3 respectively - we realised that it was easier to share this domain rather than set up two domains every single time we want a new portal. \"satshop admin\" and \"staging admin\" only use their dedicated domains for historical purposes. Project directory structure The structure of each \"Project directory\" is as follows: - app_home - log - flask - public - error - virtual_environments Compare this with the directory structure of the satshop/portal . Notice that the only difference is the lack of public/static directory - we allow the flask process to serve static assets instead of the apache server. There is no reason for this other than the time taken to set this up, this can easily be set up if serving assets via flask becomes an issue. Although we describe the purpose of each directory in the portal docs, we do the same again here for completeness. The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the application, namely app.py and config.ini (see project root ). The directory public/error houses static error files; when releasing, it is common to bring the flask server down, at which point apache will return the 503 error document in this directory. The log directory contains logs for the application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the subdirectory log/flask . First Release These are instructions if you need to release a new admin suite. The reader will also need to set up any ssl certificates and A records. See the web miscellaneous docs for more detail. If you need to release an update, please see the Release Update section. We assume user/processing databases are set up already. Set up project directory In the following, we use a location of a \"new-admin\". The reader should change the folder paths for the application they are setting up. If this is the first flask application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the Project directory structure section: sudo mkdir /var/www/new-admin/ cd /var/www/new-admin/ sudo mkdir public/ sudo chown flaskuser:apache public/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ Notice that flaskuser is the owner of all the directories, but that apache needs access to the public and logs directories. The former is so that the apache server can serve files from this directory without having to give send a proxy request to the flask application, if for example, serving the 503 page. The latter is so the apache server can write logs to this directory. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/new-admin/log(/.*)?\" sudo restorecon -R -v log/ The directories are now set up ready to be populated. Populate project directories We will need to: Download artifacts from the build stage of a satsense admin gitlab pipeline . Populate the app_home directory. Create a 503 document in public/error . Create a virtual environment for the application and install the project. We run through each of these steps in succession. Unless otherwise stated, we will assume that the following statements will be run as flaskuser . 1. Download satadmin artifacts We keep a shell script on the live server that downloads the artifacts automatically for us. This is kept in the file: /home/flaskuser/releases/admin/download_admin_artifacts We keep a copy here as well: #!/bin/bash TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") CURL_OUTFILE=\"satadmin_artifacts_$TIMESTAMP.zip\" SATADMIN_BRANCH=\"master\" HTTP_CODE=$(curl --write-out \"%{http_code}\" --location --output $CURL_OUTFILE --header \"PRIVATE-TOKEN: <gitlab ro access token>\" \"https://gitlab.com/api/v4/projects/16546505/jobs/artifacts/$SATADMIN_BRANCH/download?job=create_artifacts\") NEW_DIR=\"satadmin_$TIMESTAMP\" mkdir $NEW_DIR unzip $CURL_OUTFILE -d $NEW_DIR rm $CURL_OUTFILE printf \"Response code: $HTTP_CODE\\nOut Dir: $NEW_DIR\\n\" Note that if you use the code above, you should create a gitlab access token (preferably read only) and replace <gitlab ro access token> with it. However, the file on the server has an access token pre-filled. Further, if you need to release a branch other than master , then you can change the SATADMIN_BRANCH variable. By convention, we run the download_admin_artifacts file from inside its directory, i.e. cd /home/flaskuser/releases/admin ./download_admin_artifacts and this will create a timestamped directory of the needed artifacts for a satadmin release. 2. Populate app_home We assume that the current directory is the timestamped directory created in the first section cp dist/satadmin/app.py /var/www/new-admin/app_home cp dist/satadmin/config.ini /var/www/new-admin/app_home Here, app.py is the entry point for the application and config.ini is a config file. The latter needs to be edited with config settings for the application (e.g. database strings, live api keys etc). 3. Create a 503 document Create the required error folder: mkdir /var/www/new-admin/public/error And copy the 503 document from the admin artifacts (we assume the current directory is the directory created in the first section ): cp dist/satadmin/error/* /var/www/new-admin/public/error 4. Create a virtual environment Compare the following instructions with the instructions from the project README . Initialise and activate a virtual environment: cd /var/www/new-admin/virtual_environments python3.7 -m venv venv source venv/bin/activate Then change your current directory back to the timestamped directory created in the first section . Install the requirements: pip install \"$(cat dist/satadmin/requirements/production.txt | grep numpy)\" pip install GDAL==$(gdal-config --version | awk -F'[.]' '{print $1\".\"$2}') --global-option=build_ext --global-option=\"-I/usr/include/gdal\" pip install -r dist/satadmin/requirements/production.txt Then install satdom and satadmin wheels (the exact file names are indeterminable before downloading the artifacts - hence the wildcards): pip install dist/satdom/satdom-*.whl pip install dist/satadmin/satadmin-*.whl Deactivate the virtual environment deactivate Systemd and gunicorn set up Once we've set up the project directories/virtual environment as above, we need something to actually run the application. This is done via systemd and gunicorn. We assume the reader has followed the above instructions. Gunicorn is easy to install via pip. As flaskuser then run: source /var/www/new-admin/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the site is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/new-admin/app_home and replace <port> with a port number. We'd like the above process to be run automatically, which is done by using systemd . To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: sudo touch /etc/systemd/system/newadmin.service sudo chmod 664 /etc/systemd/system/newadmin.service Then populate the file, with something similar to following (we've assumed a port of \"5000\", but be warned this port is already used on the live server): [Unit] Description = NewAdmin After = network.target [Service] User=flaskuser WorkingDirectory=/var/www/new-admin/app_home ExecStart=/var/www/new-admin/virtual_environments/venv/bin/gunicorn -b localhost:5000 -w 4 app:app Restart=always [Install] WantedBy = multi-user.target For systemd to recognise the new file, you will need to run systemctl daemon-reload and you can check it has been found using systemctl list-unit-files The service can be started via: systemctl start newadmin We note that the service is named newadmin due to the name of the systemd file we created. The service can be stopped via: systemctl stop newadmin To allow the service to start on server reboot, it needs to be enabled: systemctl enable newadmin Apache set up Once the admin application is running using systemd. We need to let the web server (currently apache) know to proxy requests to this service. To do this we create a virtual host. For further information about virtual hosts, see the apache httpd set up . Here is an example virtual host for the new admin suite: <VirtualHost *:80> ServerName newadmin.satsense.com ServerAlias newadmin.satsense.com DocumentRoot /var/www/new-admin/public # rewrite to https RewriteEngine on RewriteCond %{SERVER_NAME} =newadmin.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName newadmin.satsense.com ServerAlias newadmin.satsense.com DocumentRoot /var/www/new-admin/public # flask proxy ProxyPass /error ! ProxyPass / http://localhost:5000/ ProxyPassReverse / http://localhost:5000/ # logs ErrorLog /var/www/newadmin/log/error.log CustomLog /var/www/newadmin/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=31536000; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html # ssl SSLCertificateFile /etc/letsencrypt/live/newadmin.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/newadmin.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/newadmin.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to newadmin.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to newadmin.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://newadmin.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5000 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /error ! ) mean that requests following this pattern should not be proxied (e.g. https://newadmin.satsense.com/error/503.html ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release . Release Update This section deals with releasing an update to an admin suite that is already live. See the previous section for a first release of a new admin suite. A lot of the steps in this section are similar to first release section - with this in mind, this section lacks the verbosity of the new release section. Check and apply database migrations For more information about alembic (the tool we use for database migrations), see the satdom README . At time of writing the live server has a satsense_domain repository at /home/centos/Projects/alembic/satsense-domain which houses a virtual environment called venv_alembic . The satsense_domain is installed as editable dependency inside venv_alembic . We use this project to run the alembic migrations. Make sure the project is up to date and activate the environment. Change alembic config files (specifically sqlalchemy.url ). From directories containing alembic.ini config files, run alembic history alembic current to see current version and alembic history. Note down what will be updated and check this seems reasonable. If the schema update is just adding new tables/columns (nullable or with default values) then running this migration is unlikely to break anything. However, if a column name has been changed, or if a column has been deleted then proceed with caution - this needs to be handled carefully and may require more app downtime. Finally, if tested and completely happy , run: alembic upgrade head Other steps Log onto api server as flaskuser (can run sudo su flaskuser as centos). Change directory to admin release directory cd ~/releases/admin . Check branch is correct in script download_admin_artifacts and run it. On gitlab, compare the master branch (if you are releasing the master branch) of satsense-admin to the most recent release tag. Check if the following have been updated: config.ini requirements/production.txt If fields have been added to config.ini, then you will need to add the same fields to /var/www/new-admin/app_home/config.ini . If fields have been deleted, then you can also delete them from the app config file, but it might be safer to do this once the code has been released. The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps - which might be best out of hours. This can be done via sudo systemctl stop newadmin which needs to be run as the centos user. The rest of these instructions assume you are logged on as flaskuser . Activate the application virtual environment source /var/www/new-admin/virtual_environments/venv/bin/activate . Change directory to the admin artifact directory created in step 3. Uninstall satdom/satadmin in the virtual environment pip uninstall satdom satadmin . If requirements/production.txt had been updated (see step 4), then install the new dependencies pip install -r dist/satadmin/requirements/production.txt . Reinstall satdom/satsense-admin into the venv: commandline pip install dist/satdom/satdom-*.whl pip install dist/satadmin/satadmin-*.whl Bring the site back up, as centos, run sudo systemctl start newadmin and check the site works as expected. Troubleshooting Problem Actions Web site isn't responding. For example https://admin.satsense.com doesn't respond. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check flask errors Web site reports \"Server Unavailable\" Check gunicorn systemd process is running Web site responds, but logging in does not work Check flask errors Restart flask application Actions Check Api server is running Check you can ssh into the api server. If not, contact unipart for further help. Check a record Log into cloudflare and check the A record for the domain that you're trying to access. Check flask errors The flask error logs are in the app log directories (locations detailed in the Live Server Locations section). Check httpd errors The httpd error logs are file called are in the app log directories (locations detailed in the Live Server Locations section). Check gunicorn systemd process is running systemctl status newadmin If process is reported as stopped. Then run sudo systemctl start newadmin Restart flask application Restart the application by stopping and starting: sudo systemctl stop newadmin sudo systemctl start newadmin","title":"Admin Suite (satadmin)"},{"location":"client-facing-applications/admin/#admin-suite-satadmin","text":"This is a web application with two main responsibilies: allow the management of users on the portal/satshop and api. monitor/control the processing of SatSense data. Instructions for how to install an instance of the admin suite into a virtual environment are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with how to set up apache to forward on requests.","title":"Admin Suite (satadmin)"},{"location":"client-facing-applications/admin/#contents","text":"Live Server Locations - where files related to the admin suite are kept on the live server. First Release - how to release a brand new admin suite. Release Update - how to release an update to an admin suite that's already been released. Troubleshooting - something not working? No problem.","title":"Contents"},{"location":"client-facing-applications/admin/#live-server-locations","text":"On the live server, we run several portals and in turn we therefore run several admin suites (which deal with the separate user databases). This is a list of the admin suites that are running, along with locations of related important files: Admin instance name Domain end point Associated portal name Project directory Httpd config file Systemd file satshop admin admin.satsense.com satshop /var/www/admin-live /etc/httpd/sites-available/admin-live.conf /etc/systemd/system/adminlive.service staging admin admin.staging.satsense.com staging /var/www/admin-staging /etc/httpd/sites-available/admin-staging.conf /etc/systemd/system/adminstaging.service portal2 admin portal2.satsense.com/admin portal2 /var/www/admin2 shared with portal2 i.e. /etc/httpd/sites-available/flask-portal2.conf /etc/systemd/system/admin2.service portal3 admin portal3.satsense.com/admin portal3 /var/www/admin3 shared with portal3 i.e. /etc/httpd/sites-available/portal3.conf /etc/systemd/system/admin3.service Notice that \"portal2 admin\" and \"portal3 admin\" share a domain with portal2 and portal3 respectively - we realised that it was easier to share this domain rather than set up two domains every single time we want a new portal. \"satshop admin\" and \"staging admin\" only use their dedicated domains for historical purposes.","title":"Live Server Locations"},{"location":"client-facing-applications/admin/#project-directory-structure","text":"The structure of each \"Project directory\" is as follows: - app_home - log - flask - public - error - virtual_environments Compare this with the directory structure of the satshop/portal . Notice that the only difference is the lack of public/static directory - we allow the flask process to serve static assets instead of the apache server. There is no reason for this other than the time taken to set this up, this can easily be set up if serving assets via flask becomes an issue. Although we describe the purpose of each directory in the portal docs, we do the same again here for completeness. The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the application, namely app.py and config.ini (see project root ). The directory public/error houses static error files; when releasing, it is common to bring the flask server down, at which point apache will return the 503 error document in this directory. The log directory contains logs for the application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the subdirectory log/flask .","title":"Project directory structure"},{"location":"client-facing-applications/admin/#first-release","text":"These are instructions if you need to release a new admin suite. The reader will also need to set up any ssl certificates and A records. See the web miscellaneous docs for more detail. If you need to release an update, please see the Release Update section. We assume user/processing databases are set up already.","title":"First Release"},{"location":"client-facing-applications/admin/#set-up-project-directory","text":"In the following, we use a location of a \"new-admin\". The reader should change the folder paths for the application they are setting up. If this is the first flask application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the Project directory structure section: sudo mkdir /var/www/new-admin/ cd /var/www/new-admin/ sudo mkdir public/ sudo chown flaskuser:apache public/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ Notice that flaskuser is the owner of all the directories, but that apache needs access to the public and logs directories. The former is so that the apache server can serve files from this directory without having to give send a proxy request to the flask application, if for example, serving the 503 page. The latter is so the apache server can write logs to this directory. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/new-admin/log(/.*)?\" sudo restorecon -R -v log/ The directories are now set up ready to be populated.","title":"Set up project directory"},{"location":"client-facing-applications/admin/#populate-project-directories","text":"We will need to: Download artifacts from the build stage of a satsense admin gitlab pipeline . Populate the app_home directory. Create a 503 document in public/error . Create a virtual environment for the application and install the project. We run through each of these steps in succession. Unless otherwise stated, we will assume that the following statements will be run as flaskuser .","title":"Populate project directories"},{"location":"client-facing-applications/admin/#1-download-satadmin-artifacts","text":"We keep a shell script on the live server that downloads the artifacts automatically for us. This is kept in the file: /home/flaskuser/releases/admin/download_admin_artifacts We keep a copy here as well: #!/bin/bash TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") CURL_OUTFILE=\"satadmin_artifacts_$TIMESTAMP.zip\" SATADMIN_BRANCH=\"master\" HTTP_CODE=$(curl --write-out \"%{http_code}\" --location --output $CURL_OUTFILE --header \"PRIVATE-TOKEN: <gitlab ro access token>\" \"https://gitlab.com/api/v4/projects/16546505/jobs/artifacts/$SATADMIN_BRANCH/download?job=create_artifacts\") NEW_DIR=\"satadmin_$TIMESTAMP\" mkdir $NEW_DIR unzip $CURL_OUTFILE -d $NEW_DIR rm $CURL_OUTFILE printf \"Response code: $HTTP_CODE\\nOut Dir: $NEW_DIR\\n\" Note that if you use the code above, you should create a gitlab access token (preferably read only) and replace <gitlab ro access token> with it. However, the file on the server has an access token pre-filled. Further, if you need to release a branch other than master , then you can change the SATADMIN_BRANCH variable. By convention, we run the download_admin_artifacts file from inside its directory, i.e. cd /home/flaskuser/releases/admin ./download_admin_artifacts and this will create a timestamped directory of the needed artifacts for a satadmin release.","title":"1. Download satadmin artifacts"},{"location":"client-facing-applications/admin/#2-populate-app_home","text":"We assume that the current directory is the timestamped directory created in the first section cp dist/satadmin/app.py /var/www/new-admin/app_home cp dist/satadmin/config.ini /var/www/new-admin/app_home Here, app.py is the entry point for the application and config.ini is a config file. The latter needs to be edited with config settings for the application (e.g. database strings, live api keys etc).","title":"2. Populate app_home"},{"location":"client-facing-applications/admin/#3-create-a-503-document","text":"Create the required error folder: mkdir /var/www/new-admin/public/error And copy the 503 document from the admin artifacts (we assume the current directory is the directory created in the first section ): cp dist/satadmin/error/* /var/www/new-admin/public/error","title":"3. Create a 503 document"},{"location":"client-facing-applications/admin/#4-create-a-virtual-environment","text":"Compare the following instructions with the instructions from the project README . Initialise and activate a virtual environment: cd /var/www/new-admin/virtual_environments python3.7 -m venv venv source venv/bin/activate Then change your current directory back to the timestamped directory created in the first section . Install the requirements: pip install \"$(cat dist/satadmin/requirements/production.txt | grep numpy)\" pip install GDAL==$(gdal-config --version | awk -F'[.]' '{print $1\".\"$2}') --global-option=build_ext --global-option=\"-I/usr/include/gdal\" pip install -r dist/satadmin/requirements/production.txt Then install satdom and satadmin wheels (the exact file names are indeterminable before downloading the artifacts - hence the wildcards): pip install dist/satdom/satdom-*.whl pip install dist/satadmin/satadmin-*.whl Deactivate the virtual environment deactivate","title":"4. Create a virtual environment"},{"location":"client-facing-applications/admin/#systemd-and-gunicorn-set-up","text":"Once we've set up the project directories/virtual environment as above, we need something to actually run the application. This is done via systemd and gunicorn. We assume the reader has followed the above instructions. Gunicorn is easy to install via pip. As flaskuser then run: source /var/www/new-admin/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the site is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/new-admin/app_home and replace <port> with a port number. We'd like the above process to be run automatically, which is done by using systemd . To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: sudo touch /etc/systemd/system/newadmin.service sudo chmod 664 /etc/systemd/system/newadmin.service Then populate the file, with something similar to following (we've assumed a port of \"5000\", but be warned this port is already used on the live server): [Unit] Description = NewAdmin After = network.target [Service] User=flaskuser WorkingDirectory=/var/www/new-admin/app_home ExecStart=/var/www/new-admin/virtual_environments/venv/bin/gunicorn -b localhost:5000 -w 4 app:app Restart=always [Install] WantedBy = multi-user.target For systemd to recognise the new file, you will need to run systemctl daemon-reload and you can check it has been found using systemctl list-unit-files The service can be started via: systemctl start newadmin We note that the service is named newadmin due to the name of the systemd file we created. The service can be stopped via: systemctl stop newadmin To allow the service to start on server reboot, it needs to be enabled: systemctl enable newadmin","title":"Systemd and gunicorn set up"},{"location":"client-facing-applications/admin/#apache-set-up","text":"Once the admin application is running using systemd. We need to let the web server (currently apache) know to proxy requests to this service. To do this we create a virtual host. For further information about virtual hosts, see the apache httpd set up . Here is an example virtual host for the new admin suite: <VirtualHost *:80> ServerName newadmin.satsense.com ServerAlias newadmin.satsense.com DocumentRoot /var/www/new-admin/public # rewrite to https RewriteEngine on RewriteCond %{SERVER_NAME} =newadmin.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName newadmin.satsense.com ServerAlias newadmin.satsense.com DocumentRoot /var/www/new-admin/public # flask proxy ProxyPass /error ! ProxyPass / http://localhost:5000/ ProxyPassReverse / http://localhost:5000/ # logs ErrorLog /var/www/newadmin/log/error.log CustomLog /var/www/newadmin/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=31536000; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html # ssl SSLCertificateFile /etc/letsencrypt/live/newadmin.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/newadmin.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/newadmin.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to newadmin.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to newadmin.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://newadmin.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5000 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /error ! ) mean that requests following this pattern should not be proxied (e.g. https://newadmin.satsense.com/error/503.html ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release .","title":"Apache set up"},{"location":"client-facing-applications/admin/#release-update","text":"This section deals with releasing an update to an admin suite that is already live. See the previous section for a first release of a new admin suite. A lot of the steps in this section are similar to first release section - with this in mind, this section lacks the verbosity of the new release section.","title":"Release Update"},{"location":"client-facing-applications/admin/#check-and-apply-database-migrations","text":"For more information about alembic (the tool we use for database migrations), see the satdom README . At time of writing the live server has a satsense_domain repository at /home/centos/Projects/alembic/satsense-domain which houses a virtual environment called venv_alembic . The satsense_domain is installed as editable dependency inside venv_alembic . We use this project to run the alembic migrations. Make sure the project is up to date and activate the environment. Change alembic config files (specifically sqlalchemy.url ). From directories containing alembic.ini config files, run alembic history alembic current to see current version and alembic history. Note down what will be updated and check this seems reasonable. If the schema update is just adding new tables/columns (nullable or with default values) then running this migration is unlikely to break anything. However, if a column name has been changed, or if a column has been deleted then proceed with caution - this needs to be handled carefully and may require more app downtime. Finally, if tested and completely happy , run: alembic upgrade head","title":"Check and apply database migrations"},{"location":"client-facing-applications/admin/#other-steps","text":"Log onto api server as flaskuser (can run sudo su flaskuser as centos). Change directory to admin release directory cd ~/releases/admin . Check branch is correct in script download_admin_artifacts and run it. On gitlab, compare the master branch (if you are releasing the master branch) of satsense-admin to the most recent release tag. Check if the following have been updated: config.ini requirements/production.txt If fields have been added to config.ini, then you will need to add the same fields to /var/www/new-admin/app_home/config.ini . If fields have been deleted, then you can also delete them from the app config file, but it might be safer to do this once the code has been released. The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps - which might be best out of hours. This can be done via sudo systemctl stop newadmin which needs to be run as the centos user. The rest of these instructions assume you are logged on as flaskuser . Activate the application virtual environment source /var/www/new-admin/virtual_environments/venv/bin/activate . Change directory to the admin artifact directory created in step 3. Uninstall satdom/satadmin in the virtual environment pip uninstall satdom satadmin . If requirements/production.txt had been updated (see step 4), then install the new dependencies pip install -r dist/satadmin/requirements/production.txt . Reinstall satdom/satsense-admin into the venv: commandline pip install dist/satdom/satdom-*.whl pip install dist/satadmin/satadmin-*.whl Bring the site back up, as centos, run sudo systemctl start newadmin and check the site works as expected.","title":"Other steps"},{"location":"client-facing-applications/admin/#troubleshooting","text":"Problem Actions Web site isn't responding. For example https://admin.satsense.com doesn't respond. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check flask errors Web site reports \"Server Unavailable\" Check gunicorn systemd process is running Web site responds, but logging in does not work Check flask errors Restart flask application","title":"Troubleshooting"},{"location":"client-facing-applications/admin/#actions","text":"","title":"Actions"},{"location":"client-facing-applications/admin/#check-api-server-is-running","text":"Check you can ssh into the api server. If not, contact unipart for further help.","title":"Check Api server is running"},{"location":"client-facing-applications/admin/#check-a-record","text":"Log into cloudflare and check the A record for the domain that you're trying to access.","title":"Check a record"},{"location":"client-facing-applications/admin/#check-flask-errors","text":"The flask error logs are in the app log directories (locations detailed in the Live Server Locations section).","title":"Check flask errors"},{"location":"client-facing-applications/admin/#check-httpd-errors","text":"The httpd error logs are file called are in the app log directories (locations detailed in the Live Server Locations section).","title":"Check httpd errors"},{"location":"client-facing-applications/admin/#check-gunicorn-systemd-process-is-running","text":"systemctl status newadmin If process is reported as stopped. Then run sudo systemctl start newadmin","title":"Check gunicorn systemd process is running"},{"location":"client-facing-applications/admin/#restart-flask-application","text":"Restart the application by stopping and starting: sudo systemctl stop newadmin sudo systemctl start newadmin","title":"Restart flask application"},{"location":"client-facing-applications/api/","text":"Overview This page includes documentation for the satsense API. Similarly to the portal , the API is written using flask . Whilst some details in the portal documentation are similar, the projects are quite different in design style for the following reasons: the API response contents are all json; there is no need for html, css or js (i.e. the templates/static/src directories); the API uses the flask-restful extension, which is quite different syntactically to vanilla flask. Instructions for how to install an instance of the portal/satshop into a virtual environment are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with how to set up apache to forward on requests. Contents Live Server Locations - where files related to the api are kept on the live server. First Release - how to release a brand new api. Release Update - how to release an update to an api that's already been released. Troubleshooting - something not working? No problem. Live Server Locations On the live server, we run a few apis; one live api and a couple of test apis. This is a list of the apis that are running, along with locations of related important files: Api instance name Domain end point Project directory Httpd config file Systemd file Celery systemd file live api.satsense.com /var/www/api-live /etc/httpd/sites-available/api-live.conf /etc/systemd/system/apilive.service /etc/systemd/system/apilivecelery.service test api.test.satsense.com /var/www/api-test /etc/httpd/sites-available/api-test.conf /etc/systemd/system/apitest.service /etc/systemd/system/apitestcelery.service staging api.staging.satsense.com /var/www/api-staging /etc/httpd/sites-available/api-staging.conf /etc/systemd/system/apistaging.service /etc/systemd/system/apistagingcelery.service Project directory structure Note that the directory structure is similar to that of the portal site , and although it may seem like this section repeats some of that documentation, we choose to be explicit here. Each \"Project directory\" (see table above) has the following structure: - app_home - celery - log - virtual_environments The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the applications, namely app.py , celery_app.py and config.ini . a config file for gunicorn; gunicorn_config.py . a config file for new relic (a web based monitoring/metric tool) - newrelic.ini . The log directory contains logs for application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the subdirectory log/flask . The celery directory contains: a config for celery; celery_env . pid files to help monitor when the app is running. logs for the celery application. Access To Apis Access to the apis is controlled by two elements, these are: the user having an api key the user having access to \"api resources\" The idea is that a user is added to the resources they need access to - the current resources are: report - referring to groundsure end points vels_ts - referring to obtaining velocities and time series data via an api A user with access to either of these resources can use an api key that's attributed to them. Or if they have access to both, the same api key will give them access to both resources. To give a user access to the live api, this can be done from the \"view user\" page on https://admin.satsense.com. Click on \"View User Api Details\" and add the user to resources and create them an api key. For the other apis (namely the \"test\" and \"staging\" apis), there may not be an admin suite associated with the user database for these apis. You can give access to these apis by running the following sql commands against a user database: INSERT INTO insar_api_keys(user_id, api_key) VALUES (<user id>, '<new api key>'); UPDATE portal_users SET api_resources = ARRAY['reports'] WHERE id = <user id>; Replace <user id> with the id of the user you'd like to give permissions to and replace <new api key> with a suitable api key. Obviously, you can also give the user access to the vel_ts resource by changing the update statement accordingly. Note in the code, we just use a uuid4 to generate an api key so you could just run python -c \"from uuid import uuid4; print(uuid4())\" to generate an ad hoc api key. A final note that at the time of writing, the staging api uses the user database staging users and the test api users the user database api_test_users . First Release In the following, we detail how to set up the initial release for the api. The reader will also need to set up any ssl certificates and A records. See the web miscellaneous docs for more detail. If you need to release an update to an api that is already live, then please see the Release Update section. In the following, we assume that user/InSAR databases are set up already. Set up project directory In the following, we use a location of a \"new-api\". The reader should change the folder paths for the application they are setting up. If this is the first application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the section: sudo mkdir /var/www/new-api/ cd /var/www/new-api/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir log/gunicorn sudo chown flaskuser:flaskuser log/gunicorn/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ sudo mkdir celery/ sudo chown flaskuser:flaskuser celery/ Notice that flaskuser is the owner of all the directories, but that apache needs access to the log directories. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/new-api/log(/.*)?\" sudo restorecon -R -v log/ The directories are now set up ready to be populated. Populate project directories We will need to: Download artifacts from the build stage of a satapi gitlab pipeline . Populate the app_home directory. Create a virtual environment for the application and install the project. We run through each of these steps in succession. Unless otherwise stated, we will assume that the following statements will be run as flaskuser . 1. Download artifacts We keep a shell script on the live server that downloads the artifacts automatically for us. This is kept in the file: /home/flaskuser/releases/api/download_api_artifacts We keep a copy here as well: #!/bin/bash TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") CURL_OUTFILE=\"satapi_artifacts_$TIMESTAMP.zip\" SATAPI_BRANCH=\"master\" HTTP_CODE=$(curl --write-out \"%{http_code}\" --location --output $CURL_OUTFILE --header \"PRIVATE-TOKEN: <gitlab ro access token>\" \"https://gitlab.com/api/v4/projects/11778627/jobs/artifacts/$SATAPI_BRANCH/download?job=create_artifacts\") NEW_DIR=\"satapi_$TIMESTAMP\" mkdir $NEW_DIR unzip $CURL_OUTFILE -d $NEW_DIR rm $CURL_OUTFILE printf \"Response code: $HTTP_CODE\\nOut Dir: $NEW_DIR\\n\" Note that if you use the code above, you should create a gitlab access token (preferably read only) and replace <gitlab ro access token> with it. However, the file on the server has an access token pre-filled. Further, if you need to release a branch other than master , then you can change the SATAPI_BRANCH variable. By convention, we run the download_api_artifacts file from inside its directory, i.e. cd /home/flaskuser/releases/api ./download_api_artifacts and this will create a timestamped directory of the needed artifacts for a satapi release. 2. Populate app_home We assume that the current directory is the timestamped directory created in the first section cp dist/satapi/app.py /var/www/new-api/app_home cp dist/satapi/celery_app.py /var/www/new-api/app_home cp dist/satapi/config.ini /var/www/new-api/app_home Here, app.py and celery_app.py are the entry points for the applications. The file config.ini is a config file for the applications. This config file needs to be edited with config settings for the application (e.g. database strings, etc). See more information about the config file in the project README . 3. Create virtual environment Compare the following instructions with the instructions from the project README . Initialise and activate a virtual environment: cd /var/www/new-api/virtual_environments /usr/local/bin/python3.7 -m venv venv source venv/bin/activate Then change your current directory back to the timestamped directory created in the first section . Install the requirements: pip install \"$(cat dist/satapi/requirements/production.txt | grep numpy)\" pip install GDAL==$(gdal-config --version | awk -F'[.]' '{print $1\".\"$2}') --global-option=build_ext --global-option=\"-I/usr/include/gdal\" pip install -r dist/satapi/requirements/production.txt If you run into trouble installing psycopg2 with an error that pg_config could not be found, specify the postgres installation path. On staging this would be: export PATH=/usr/pgsql-13/bin/:$PATH Make sure all requirements install without error before continuing. Then install satdom and satapi wheels (the exact file names are indeterminable before downloading the artifacts - hence the wildcards): pip install dist/satdom/satdom-*.whl pip install dist/satapi/satapi-*.whl Deactivate the virtual environment deactivate systemd and gunicorn set up Install gunicorn inside the virtual environment source /var/www/new-api/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the api is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/new-api/app_home and replace <port> with a port number. As discussed, the api actually requires two processes to be run; the app which handles the requests, and the celery_app process that handles asynchronous processes. We would like to set both of these processes to be run automatically, which is done by using systemd . set up for app To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: sudo touch /etc/systemd/system/newapi.service sudo chmod 664 /etc/systemd/system/newapi.service Then populate this file, here is an example config [Unit] Description = NewApi After = network.target [Service] User=flaskuser Environment=\"APP_HOME_DIR=/var/www/new-api/app_home\" Environment=\"APP_VENV_DIR=/var/www/new-api/virtual_environments/venv\" WorkingDirectory=/var/www/new-api/app_home ExecStart=/bin/sh -c '${APP_VENV_DIR}/bin/gunicorn -c ${APP_HOME_DIR}/gunicorn_config.py app:app' Restart=always [Install] WantedBy = multi-user.target Notice that this refers to a config file gunicorn_config.py in /var/www/new-api/app_home , we also need to create that file. Here is an example of the expected contents of that file: bind = \"localhost:5000\" workers = 4 accesslog = \"/var/www/new-api/log/gunicorn/accesslog\" errorlog = \"/var/www/new-api/log/gunicorn/errorlog\" loglevel = \"info\" The service can be started via: systemctl start newapi or stopped via: systemctl stop newapi To allow the service to start on server reboot, it needs to be enabled: systemctl enable newapi set up for celery_app First, create a file: sudo touch /etc/systemd/system/newapicelery.service sudo chmod 664 /etc/systemd/system/newapicelery.service Then populate this file, here is an example config [Unit] Description=NewApiCelery After=network.target [Service] Type=forking User=flaskuser Group=flaskuser EnvironmentFile=/var/www/new-api/celery/celery_env WorkingDirectory=/var/www/new-api/app_home ExecStart=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi start $CELERYD_NODES --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS' ExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait $CELERYD_NODES --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} --loglevel=\"${CELERYD_LOG_LEVEL}\"' ExecReload=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi restart $CELERYD_NODES --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS' Restart=always [Install] WantedBy=multi-user.target Notice that this config refers to a file containing environment varibles in the location /var/www/new-api/celery/celery_env . An example of the contents of this file is: CELERYD_NODES=\"newapiw1\" CELERY_BIN=\"/var/www/new-api/virtual_environments/venv/bin/celery\" CELERY_APP=\"celery_app\" CELERYD_OPTS=\"--time-limit=300 --concurrency=1\" CELERYD_PID_FILE=\"/var/www/new-api/celery/%n.pid\" CELERYD_LOG_FILE=\"/var/www/new-api/celery/%n%I.log\" CELERYD_LOG_LEVEL=\"INFO\" See the celery documentation for more information. The service can be altered similarly to the above, e.g. systemctl start newapicelery systemctl stop newapicelery systemctl enable newapicelery Apache set up Once the api application is running using systemd, we need to let the web server (currently apache) know to proxy requests to this service. To do this we create a virtual host. For further information about virtual hosts, see the apache httpd set up . Here is an example virtual host for the new api: <VirtualHost *:80> ServerName newapi.satsense.com ServerAlias newapi.satsense.com RewriteEngine on RewriteCond %{SERVER_NAME} =newapi.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName newapi.satsense.com ServerAlias newapi.satsense.com # flask proxy ProxyPass / http://localhost:5000/ ProxyPassReverse / http://localhost:5000/ # logs ErrorLog /var/www/new-api/log/error.log CustomLog /var/www/new-api/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=300; includeSubdomains\" Header always set X-Frame-Options \"deny\" #s sl SSLCertificateFile /etc/letsencrypt/live/newapi.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/newapi.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/newapi.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to newapi.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to newapi.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://newapi.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5000 (where the flask application is listening). The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release . Release Update This section deals with releasing an update to an api that is already live. See the previous section for a first release of a new api. A lot of the steps in this section are similar to first release section - with this in mind, this section lacks the verbosity of the new release section. First you might want to make back ups of the current project files that will change. For the staging api, as flaskuser you can run cp -r /var/www/api-staging/virtual_environments/venv ~/path/to/backup Check and apply database migrations For more information about alembic (the tool we use for database migrations), see the satdom README . At time of writing the live server has a satsense_domain repository at /home/centos/Projects/alembic/satsense-domain which houses a virtual environment called venv_alembic . The satsense_domain is installed as editable dependency inside venv_alembic . We use this project to run the alembic migrations. Make sure the project is up to date and activate the environment. Change alembic config files (specifically sqlalchemy.url ). From directories containing alembic.ini config files, run alembic history alembic current to see current version and alembic history. Note down what will be updated and check this seems reasonable. If the schema update is just adding new tables/columns (nullable or with default values) then running this migration is unlikely to break anything. However, if a column name has been changed, or if a column has been deleted then proceed with caution - this needs to be handled carefully and may require more app downtime. Finally, if tested and completely happy , run: alembic upgrade head Other steps Log onto api server as flaskuser (can run sudo su flaskuser as centos). Change directory to API release directory cd ~/releases/api . Check branch is correct in script download_api_artifacts and run it. On gitlab, compare the master branch (if you are releasing the master branch) of satsense-api to the most recent release tag. Check if the following have been updated: config.ini requirements/production.txt If fields have been added to config.ini, then you will need to add the same fields to /var/www/new-api/app_home/config.ini . If fields have been deleted, then you can also delete them from the app config file, but it might be safer to do this once the code has been released. The following will actually interact with the current running site. It is advisable to bring the api and celery process down whilst doing these steps - which might be best out of hours. This can be done via sudo systemctl stop newapi sudo systemctl stop newapicelery which needs to be run as the centos user. The rest of these instructions assume you are logged on as flaskuser . Activate the application virtual environment source /var/www/new-api/virtual_environments/venv/bin/activate . Change directory to the API artifact directory created in step 3. Uninstall satdom/satapi in the virtual environment pip uninstall satdom satapi . If requirements/production.txt had been updated (see step 4), then install the new dependencies pip install -r dist/satapis/requirements/production.txt . Reinstall satdom/satsense-api into the venv: commandline pip install dist/satdom/satdom-*.whl pip install dist/satapi/satapi-*.whl Bring the apps back up, as centos, run sudo systemctl start newapi sudo systemctl start newapicelery and check the api/celery process works as expected. Troubleshooting Problem Actions https://api.satsense.com doesn't respond. Check Api server is running Check httpd errors Check a record Api reports \"Unexpected error occurred\" Check flask errors Api reports \"Server Unavailable\" Check gunicorn systemd process is running Actions Check Api server is running Check you can ssh into the api server. If not, contact unipart for further help. Check a record Log into cloudflare and check the A record for the domain that you're trying to access. Check flask errors The flask error logs are in the app log directories (locations detailed in the Live Server Locations section). Check httpd errors The httpd error logs are file called are in the app log directories (locations detailed in the Live Server Locations section). Check gunicorn systemd process is running systemctl status newapi If process is reported as stopped. Then run sudo systemctl start newapi","title":"Overview"},{"location":"client-facing-applications/api/#overview","text":"This page includes documentation for the satsense API. Similarly to the portal , the API is written using flask . Whilst some details in the portal documentation are similar, the projects are quite different in design style for the following reasons: the API response contents are all json; there is no need for html, css or js (i.e. the templates/static/src directories); the API uses the flask-restful extension, which is quite different syntactically to vanilla flask. Instructions for how to install an instance of the portal/satshop into a virtual environment are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with how to set up apache to forward on requests.","title":"Overview"},{"location":"client-facing-applications/api/#contents","text":"Live Server Locations - where files related to the api are kept on the live server. First Release - how to release a brand new api. Release Update - how to release an update to an api that's already been released. Troubleshooting - something not working? No problem.","title":"Contents"},{"location":"client-facing-applications/api/#live-server-locations","text":"On the live server, we run a few apis; one live api and a couple of test apis. This is a list of the apis that are running, along with locations of related important files: Api instance name Domain end point Project directory Httpd config file Systemd file Celery systemd file live api.satsense.com /var/www/api-live /etc/httpd/sites-available/api-live.conf /etc/systemd/system/apilive.service /etc/systemd/system/apilivecelery.service test api.test.satsense.com /var/www/api-test /etc/httpd/sites-available/api-test.conf /etc/systemd/system/apitest.service /etc/systemd/system/apitestcelery.service staging api.staging.satsense.com /var/www/api-staging /etc/httpd/sites-available/api-staging.conf /etc/systemd/system/apistaging.service /etc/systemd/system/apistagingcelery.service","title":"Live Server Locations"},{"location":"client-facing-applications/api/#project-directory-structure","text":"Note that the directory structure is similar to that of the portal site , and although it may seem like this section repeats some of that documentation, we choose to be explicit here. Each \"Project directory\" (see table above) has the following structure: - app_home - celery - log - virtual_environments The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the applications, namely app.py , celery_app.py and config.ini . a config file for gunicorn; gunicorn_config.py . a config file for new relic (a web based monitoring/metric tool) - newrelic.ini . The log directory contains logs for application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the subdirectory log/flask . The celery directory contains: a config for celery; celery_env . pid files to help monitor when the app is running. logs for the celery application.","title":"Project directory structure"},{"location":"client-facing-applications/api/#access-to-apis","text":"Access to the apis is controlled by two elements, these are: the user having an api key the user having access to \"api resources\" The idea is that a user is added to the resources they need access to - the current resources are: report - referring to groundsure end points vels_ts - referring to obtaining velocities and time series data via an api A user with access to either of these resources can use an api key that's attributed to them. Or if they have access to both, the same api key will give them access to both resources. To give a user access to the live api, this can be done from the \"view user\" page on https://admin.satsense.com. Click on \"View User Api Details\" and add the user to resources and create them an api key. For the other apis (namely the \"test\" and \"staging\" apis), there may not be an admin suite associated with the user database for these apis. You can give access to these apis by running the following sql commands against a user database: INSERT INTO insar_api_keys(user_id, api_key) VALUES (<user id>, '<new api key>'); UPDATE portal_users SET api_resources = ARRAY['reports'] WHERE id = <user id>; Replace <user id> with the id of the user you'd like to give permissions to and replace <new api key> with a suitable api key. Obviously, you can also give the user access to the vel_ts resource by changing the update statement accordingly. Note in the code, we just use a uuid4 to generate an api key so you could just run python -c \"from uuid import uuid4; print(uuid4())\" to generate an ad hoc api key. A final note that at the time of writing, the staging api uses the user database staging users and the test api users the user database api_test_users .","title":"Access To Apis"},{"location":"client-facing-applications/api/#first-release","text":"In the following, we detail how to set up the initial release for the api. The reader will also need to set up any ssl certificates and A records. See the web miscellaneous docs for more detail. If you need to release an update to an api that is already live, then please see the Release Update section. In the following, we assume that user/InSAR databases are set up already.","title":"First Release"},{"location":"client-facing-applications/api/#set-up-project-directory","text":"In the following, we use a location of a \"new-api\". The reader should change the folder paths for the application they are setting up. If this is the first application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the section: sudo mkdir /var/www/new-api/ cd /var/www/new-api/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir log/gunicorn sudo chown flaskuser:flaskuser log/gunicorn/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ sudo mkdir celery/ sudo chown flaskuser:flaskuser celery/ Notice that flaskuser is the owner of all the directories, but that apache needs access to the log directories. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/new-api/log(/.*)?\" sudo restorecon -R -v log/ The directories are now set up ready to be populated.","title":"Set up project directory"},{"location":"client-facing-applications/api/#populate-project-directories","text":"We will need to: Download artifacts from the build stage of a satapi gitlab pipeline . Populate the app_home directory. Create a virtual environment for the application and install the project. We run through each of these steps in succession. Unless otherwise stated, we will assume that the following statements will be run as flaskuser .","title":"Populate project directories"},{"location":"client-facing-applications/api/#1-download-artifacts","text":"We keep a shell script on the live server that downloads the artifacts automatically for us. This is kept in the file: /home/flaskuser/releases/api/download_api_artifacts We keep a copy here as well: #!/bin/bash TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") CURL_OUTFILE=\"satapi_artifacts_$TIMESTAMP.zip\" SATAPI_BRANCH=\"master\" HTTP_CODE=$(curl --write-out \"%{http_code}\" --location --output $CURL_OUTFILE --header \"PRIVATE-TOKEN: <gitlab ro access token>\" \"https://gitlab.com/api/v4/projects/11778627/jobs/artifacts/$SATAPI_BRANCH/download?job=create_artifacts\") NEW_DIR=\"satapi_$TIMESTAMP\" mkdir $NEW_DIR unzip $CURL_OUTFILE -d $NEW_DIR rm $CURL_OUTFILE printf \"Response code: $HTTP_CODE\\nOut Dir: $NEW_DIR\\n\" Note that if you use the code above, you should create a gitlab access token (preferably read only) and replace <gitlab ro access token> with it. However, the file on the server has an access token pre-filled. Further, if you need to release a branch other than master , then you can change the SATAPI_BRANCH variable. By convention, we run the download_api_artifacts file from inside its directory, i.e. cd /home/flaskuser/releases/api ./download_api_artifacts and this will create a timestamped directory of the needed artifacts for a satapi release.","title":"1. Download artifacts"},{"location":"client-facing-applications/api/#2-populate-app_home","text":"We assume that the current directory is the timestamped directory created in the first section cp dist/satapi/app.py /var/www/new-api/app_home cp dist/satapi/celery_app.py /var/www/new-api/app_home cp dist/satapi/config.ini /var/www/new-api/app_home Here, app.py and celery_app.py are the entry points for the applications. The file config.ini is a config file for the applications. This config file needs to be edited with config settings for the application (e.g. database strings, etc). See more information about the config file in the project README .","title":"2. Populate app_home"},{"location":"client-facing-applications/api/#3-create-virtual-environment","text":"Compare the following instructions with the instructions from the project README . Initialise and activate a virtual environment: cd /var/www/new-api/virtual_environments /usr/local/bin/python3.7 -m venv venv source venv/bin/activate Then change your current directory back to the timestamped directory created in the first section . Install the requirements: pip install \"$(cat dist/satapi/requirements/production.txt | grep numpy)\" pip install GDAL==$(gdal-config --version | awk -F'[.]' '{print $1\".\"$2}') --global-option=build_ext --global-option=\"-I/usr/include/gdal\" pip install -r dist/satapi/requirements/production.txt If you run into trouble installing psycopg2 with an error that pg_config could not be found, specify the postgres installation path. On staging this would be: export PATH=/usr/pgsql-13/bin/:$PATH Make sure all requirements install without error before continuing. Then install satdom and satapi wheels (the exact file names are indeterminable before downloading the artifacts - hence the wildcards): pip install dist/satdom/satdom-*.whl pip install dist/satapi/satapi-*.whl Deactivate the virtual environment deactivate","title":"3. Create virtual environment"},{"location":"client-facing-applications/api/#systemd-and-gunicorn-set-up","text":"Install gunicorn inside the virtual environment source /var/www/new-api/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the api is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/new-api/app_home and replace <port> with a port number. As discussed, the api actually requires two processes to be run; the app which handles the requests, and the celery_app process that handles asynchronous processes. We would like to set both of these processes to be run automatically, which is done by using systemd .","title":"systemd and gunicorn set up"},{"location":"client-facing-applications/api/#set-up-for-app","text":"To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: sudo touch /etc/systemd/system/newapi.service sudo chmod 664 /etc/systemd/system/newapi.service Then populate this file, here is an example config [Unit] Description = NewApi After = network.target [Service] User=flaskuser Environment=\"APP_HOME_DIR=/var/www/new-api/app_home\" Environment=\"APP_VENV_DIR=/var/www/new-api/virtual_environments/venv\" WorkingDirectory=/var/www/new-api/app_home ExecStart=/bin/sh -c '${APP_VENV_DIR}/bin/gunicorn -c ${APP_HOME_DIR}/gunicorn_config.py app:app' Restart=always [Install] WantedBy = multi-user.target Notice that this refers to a config file gunicorn_config.py in /var/www/new-api/app_home , we also need to create that file. Here is an example of the expected contents of that file: bind = \"localhost:5000\" workers = 4 accesslog = \"/var/www/new-api/log/gunicorn/accesslog\" errorlog = \"/var/www/new-api/log/gunicorn/errorlog\" loglevel = \"info\" The service can be started via: systemctl start newapi or stopped via: systemctl stop newapi To allow the service to start on server reboot, it needs to be enabled: systemctl enable newapi","title":"set up for app"},{"location":"client-facing-applications/api/#set-up-for-celery_app","text":"First, create a file: sudo touch /etc/systemd/system/newapicelery.service sudo chmod 664 /etc/systemd/system/newapicelery.service Then populate this file, here is an example config [Unit] Description=NewApiCelery After=network.target [Service] Type=forking User=flaskuser Group=flaskuser EnvironmentFile=/var/www/new-api/celery/celery_env WorkingDirectory=/var/www/new-api/app_home ExecStart=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi start $CELERYD_NODES --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS' ExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait $CELERYD_NODES --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} --loglevel=\"${CELERYD_LOG_LEVEL}\"' ExecReload=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi restart $CELERYD_NODES --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS' Restart=always [Install] WantedBy=multi-user.target Notice that this config refers to a file containing environment varibles in the location /var/www/new-api/celery/celery_env . An example of the contents of this file is: CELERYD_NODES=\"newapiw1\" CELERY_BIN=\"/var/www/new-api/virtual_environments/venv/bin/celery\" CELERY_APP=\"celery_app\" CELERYD_OPTS=\"--time-limit=300 --concurrency=1\" CELERYD_PID_FILE=\"/var/www/new-api/celery/%n.pid\" CELERYD_LOG_FILE=\"/var/www/new-api/celery/%n%I.log\" CELERYD_LOG_LEVEL=\"INFO\" See the celery documentation for more information. The service can be altered similarly to the above, e.g. systemctl start newapicelery systemctl stop newapicelery systemctl enable newapicelery","title":"set up for celery_app"},{"location":"client-facing-applications/api/#apache-set-up","text":"Once the api application is running using systemd, we need to let the web server (currently apache) know to proxy requests to this service. To do this we create a virtual host. For further information about virtual hosts, see the apache httpd set up . Here is an example virtual host for the new api: <VirtualHost *:80> ServerName newapi.satsense.com ServerAlias newapi.satsense.com RewriteEngine on RewriteCond %{SERVER_NAME} =newapi.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName newapi.satsense.com ServerAlias newapi.satsense.com # flask proxy ProxyPass / http://localhost:5000/ ProxyPassReverse / http://localhost:5000/ # logs ErrorLog /var/www/new-api/log/error.log CustomLog /var/www/new-api/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=300; includeSubdomains\" Header always set X-Frame-Options \"deny\" #s sl SSLCertificateFile /etc/letsencrypt/live/newapi.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/newapi.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/newapi.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to newapi.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to newapi.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://newapi.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5000 (where the flask application is listening). The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release .","title":"Apache set up"},{"location":"client-facing-applications/api/#release-update","text":"This section deals with releasing an update to an api that is already live. See the previous section for a first release of a new api. A lot of the steps in this section are similar to first release section - with this in mind, this section lacks the verbosity of the new release section. First you might want to make back ups of the current project files that will change. For the staging api, as flaskuser you can run cp -r /var/www/api-staging/virtual_environments/venv ~/path/to/backup","title":"Release Update"},{"location":"client-facing-applications/api/#check-and-apply-database-migrations","text":"For more information about alembic (the tool we use for database migrations), see the satdom README . At time of writing the live server has a satsense_domain repository at /home/centos/Projects/alembic/satsense-domain which houses a virtual environment called venv_alembic . The satsense_domain is installed as editable dependency inside venv_alembic . We use this project to run the alembic migrations. Make sure the project is up to date and activate the environment. Change alembic config files (specifically sqlalchemy.url ). From directories containing alembic.ini config files, run alembic history alembic current to see current version and alembic history. Note down what will be updated and check this seems reasonable. If the schema update is just adding new tables/columns (nullable or with default values) then running this migration is unlikely to break anything. However, if a column name has been changed, or if a column has been deleted then proceed with caution - this needs to be handled carefully and may require more app downtime. Finally, if tested and completely happy , run: alembic upgrade head","title":"Check and apply database migrations"},{"location":"client-facing-applications/api/#other-steps","text":"Log onto api server as flaskuser (can run sudo su flaskuser as centos). Change directory to API release directory cd ~/releases/api . Check branch is correct in script download_api_artifacts and run it. On gitlab, compare the master branch (if you are releasing the master branch) of satsense-api to the most recent release tag. Check if the following have been updated: config.ini requirements/production.txt If fields have been added to config.ini, then you will need to add the same fields to /var/www/new-api/app_home/config.ini . If fields have been deleted, then you can also delete them from the app config file, but it might be safer to do this once the code has been released. The following will actually interact with the current running site. It is advisable to bring the api and celery process down whilst doing these steps - which might be best out of hours. This can be done via sudo systemctl stop newapi sudo systemctl stop newapicelery which needs to be run as the centos user. The rest of these instructions assume you are logged on as flaskuser . Activate the application virtual environment source /var/www/new-api/virtual_environments/venv/bin/activate . Change directory to the API artifact directory created in step 3. Uninstall satdom/satapi in the virtual environment pip uninstall satdom satapi . If requirements/production.txt had been updated (see step 4), then install the new dependencies pip install -r dist/satapis/requirements/production.txt . Reinstall satdom/satsense-api into the venv: commandline pip install dist/satdom/satdom-*.whl pip install dist/satapi/satapi-*.whl Bring the apps back up, as centos, run sudo systemctl start newapi sudo systemctl start newapicelery and check the api/celery process works as expected.","title":"Other steps"},{"location":"client-facing-applications/api/#troubleshooting","text":"Problem Actions https://api.satsense.com doesn't respond. Check Api server is running Check httpd errors Check a record Api reports \"Unexpected error occurred\" Check flask errors Api reports \"Server Unavailable\" Check gunicorn systemd process is running","title":"Troubleshooting"},{"location":"client-facing-applications/api/#actions","text":"","title":"Actions"},{"location":"client-facing-applications/api/#check-api-server-is-running","text":"Check you can ssh into the api server. If not, contact unipart for further help.","title":"Check Api server is running"},{"location":"client-facing-applications/api/#check-a-record","text":"Log into cloudflare and check the A record for the domain that you're trying to access.","title":"Check a record"},{"location":"client-facing-applications/api/#check-flask-errors","text":"The flask error logs are in the app log directories (locations detailed in the Live Server Locations section).","title":"Check flask errors"},{"location":"client-facing-applications/api/#check-httpd-errors","text":"The httpd error logs are file called are in the app log directories (locations detailed in the Live Server Locations section).","title":"Check httpd errors"},{"location":"client-facing-applications/api/#check-gunicorn-systemd-process-is-running","text":"systemctl status newapi If process is reported as stopped. Then run sudo systemctl start newapi","title":"Check gunicorn systemd process is running"},{"location":"client-facing-applications/database/","text":"Overview The portal and api have access to SatSense InSAR and user data contained in a PostgreSQL database (or sometimes known as a \"postgres\" database). We are currently using PostgreSQL version 11. Since the InSAR and user data is geographically aware, we use the extension PostGIS . PostGIS is a highly capable open source extension to PostgreSQL that allows efficient storage and queries of geographical datasets. This page aims to be a reference for how to install, set up and use PostgreSQL and PostGIS. It aims to include instructions specific to our use case, but also to be a generic reference as well. All links to PostgreSQL documentation will be to version 11 documentation. Contents: 1. Installation of PostgreSQL and PostGIS 2. User Creation 3. Tuning (TODO) 4. Backing Up Procedure 5. SatSense Postgres Ingester 6. Current Database Setup 1. Installation of PostgreSQL and PostGIS Production on Centos 7 TODO PostgreSQL 12 + PostGIS on Ubuntu 20.04 PostgreSQL Install postgres via sudo apt install postgresql postgresql-contrib To check it's working correctly, you can log in to psql as postgres sudo su postgres psql Change data directory The following assumes a clean installation of postgres. Open the config: vi /etc/postgresql/12/main/postgresql.conf and change the value data_directory to the location you'd like. You also need to initialise this directory via: /usr/lib/postgresql/12/bin/initdb <data_directory> The change requires a restart of the postgresql process: sudo systemctl restart postgresql You can then log into psql and check it has been update by using the command SHOW data_directory; . Change authentication By default, postgresql only allows peer authentication. This means that the linux user name has to match the postgresql user name for you to log in. To allow logging in by using a password, first set a password for the postgresql postgres user by running the following in psql : ALTER ROLE postgres WITH PASSWORD 'new_password'; Then edit the file sudo vi /etc/postgresql/12/main/pg_hba.conf and change all lines that are similar to: local all all peer to local all all md5 And restart the postgres service: sudo systemctl restart postgresql You'll then be able to log in using a password, try using psql -U postgres where -U means the postgres user name you are providing. PostGIS Add the ubuntugis ppa: sudo add-apt-repository ppa:ubuntugis/ppa sudo apt-get update And then postgis: sudo apt install postgis postgresql-12-postgis-3 2. User Creation and Permissions In the following, replace text surrounded '<' and '>' with values you would like. The following assumes that you are connected to postgresql via psql as a superuser (e.g. postgres). Create New User To create a new user: \\set usertograntaccessto '<portal_user>' CREATE USER :usertograntaccessto WITH ENCRYPTED PASSWORD '<password>'; where <password> is sufficiently strong, it is recommended to use a random password generator. The line \\set usertograntaccessto '<portal_user>' sets a variable in the psql session - the value is called with a preceding colon i.e. :usertograntaccessto . Grant Read Only Privileges We assume that the variable :usertograntaccessto is set as per the \"Create New User\" section. To grant read only access to a database: \\c <db name> \\set dbname '<db name>' GRANT CONNECT ON DATABASE :dbname TO :usertograntaccessto; GRANT USAGE ON SCHEMA public TO :usertograntaccessto; GRANT SELECT ON ALL TABLES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO :usertograntaccessto; Note that it is recommended to connect to the database first - the last three lines don't specify which database to grant permissions to, rather it is the database you are connected to that defines this. The line ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO :usertograntaccessto; will mean that if tables are added to the schema, then :usertograntaccessto will automatically be given the SELECT privilege. Important Default privileges will only be granted to tables added by the same user as who ran the line \"ALTER DEFAULT PRIVILEGES...\". That is, if \"postgres\" ran the line \"ALTER DEFAULT PRIVILEGES...\", then \"postgres\" must be the user that changes the schema. Grant Read Write Privileges SELECT, INSERT, UPDATE We assume that the variable :usertograntaccessto is set as per the \"Create New User\" section. To grant SELECT, INSERT, UPDATE access to user database: \\c <db name> \\set dbname '<db name>' GRANT CONNECT ON DATABASE :dbname TO :usertograntaccessto; GRANT USAGE ON SCHEMA public TO :usertograntaccessto; GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE ON TABLES TO :usertograntaccessto; GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO :usertograntaccessto; As above, it is recommended to connect to the database first (i.e. with the first line). Also as above, lines starting with ALTER DEFAULT PRIVILEGES will mean that if tables are added to the schema, then :usertograntaccessto will automatically be given the correct privileges. Important Default privileges will only be granted to tables added by the same user as who ran the line \"ALTER DEFAULT PRIVILEGES...\". That is, if \"postgres\" ran the line \"ALTER DEFAULT PRIVILEGES...\", then \"postgres\" must be the user that changes the schema. SELECT, INSERT, UPDATE, DELETE We note that some apps may also require the DELETE privilege. For instance, the admin site has the ability to delete users, whereas the portal does not. To grant SELECT, INSERT, UPDATE, DELETE access to user database: \\c <db name> \\set dbname '<db name>' GRANT CONNECT ON DATABASE :dbname TO :usertograntaccessto; GRANT USAGE ON SCHEMA public TO :usertograntaccessto; GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO :usertograntaccessto; GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO :usertograntaccessto; Change Table Ownership We finish by noting that Postgres Ingester requires greater access to tables than SELECT, INSERT, UPDATE and DELETE. Because it runs manual vacuuming, the user needs to own the tables it vacuums. You can change user ownership via: ALTER TABLE <table_name> OWNER TO <new_owner>; Note that it is easiest to run this command as a superuser (e.g. postgres ). Query Current Permissions Whilst connected to a you can use \\dp to query current permissions. And \\ddp to query the default permissions for all users. 3. Tuning See https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server Open the postgresql.conf file, on live this is sudo vi /data/pgdata11/postgresql.conf And change the following: * You could increase max_connections (live is 200). Much more than a few hundred, should consider connection pooling ( PgBouncer ). * Increase shared_buffers (live is 8GB). * Increase work_mem (live is 40MB). * Increase maintenance_work_mem (live is 1GB). * Increase effective_cache_size , advice ranges from 1/4 to 1/2 of RAM, live is 32GB. 4. Backing Up Procedure pg_dump To back up our databases, we currently use the PostgreSQL utility pg_dump . This produces a single file which can then be used to restore in another PostgreSQL instance. Example usage pg_dump database_name -Fc -p 5440 -U postgres -v > name_of_backup.bak In the above: * database_name should be replaced with the name of the database that you would like to back up. * -Fc denotes that pg_dump should use a custom format. The format here is .bak , which is determined by the suffix of the out file name. For more options, see the docs . * -p 5440 denotes the port that the PostgreSQL is listening on. * -U postgres is the user that pg_dump should connect to the database as. * -v adds verbosity. A back up of the live InSAR database can take a long time (2 days). * name_of_backup.bak should be replaced with the name of the back up file you'd like to create. Troubleshooting If you get an error like \"server mismatch error\" then it's possible that more than one version of pg_dump is installed. Check that you are calling the correct version, it should be bundled with the postgres installation. For example the current server's pg_dump is at /usr/pgsql-11/bin/pg_dump . Set up pg_dump cron job It is possibly a good idea to set up a separate user for cron jobs: sudo useradd cronuser It might be a good idea to create a readonly user in postgreSQL as well: CREATE USER cronuser WITH ENCRYPTED PASSWORD '<pg_password>'; GRANT CONNECT ON DATABASE <database_name> TO cronuser; \\c <database_name> GRANT USAGE ON SCHEMA public TO cronuser; GRANT SELECT ON ALL TABLES IN SCHEMA public TO cronuser; GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO cronuser; GRANT USAGE ON SCHEMA topology TO cronuser; GRANT SELECT ON ALL TABLES IN SCHEMA topology TO cronuser; GRANT SELECT ON ALL SEQUENCES IN SCHEMA topology TO cronuser; It is not a good idea to put the cronuser <pg_password> in the cron file. Instead, we create a .pgpass file. As the linux user cronuser , create the file touch ~/.pgpass chmod 0600 ~/.pgpass which should be populated with the structure server:port:database:username:password . For example, inserting the line: localhost:5440:*:cronuser:<pg_password> will allow credentials to any database (assuming cronuser has the correct permissions). Now run crontab -e and insert the something like: 0 22 * * * /usr/pgsql-11/bin/pg_dump <database_name> -Fc -w -p 5440 -U cronuser > /path/to/backups/database_name_$(date +\"\\%Y\\%m\\%d\").bak which will back up the database everyday at 22:00. Notice that we've escaped '%' and make sure you also enter a new line after the above line. A lovely feature of crontab is that they don't run commands without a new line after them. Restoring a .bak file For the following commands, you many need to use -p <port> -U <username> , the commands may also suffer a similar \"server mismatch error\" to pg_dump . First create a new database: createdb -T template0 mynewdb Here: * -T template0 means that nothing is created in the new database. By default, createdb will use template1 which may include some default schemas which you will not need. * mynewdb should be replaced with name of the new database you'd like to create. It should not exist. Once the database has been created, you can restore the back up: pg_restore -d mynewdb -v name_of_backup.bak -d mynewdb is the database name, as above. -v adds verbosity. name_of_backup.bak is the name of the back up file you'd like to restore. We note that the back up will try to restore the user/role access defined on the original database. The pg_restore function will show some errors if the users/roles don't exist. You shouldn't need to worry, the data should have restored fine but you will need to add any user access that you need. Sometimes the pg_restore command can fail with an error like: pg_restore: [archiver] unsupported version (1.14) in file header This may be due to using the version of pg_restore which is within your conda environment. Deactivate the conda environment and try rerunning the command. After restoring the backup, it is recommended to run ANALYSE; whilst connected to the database via psql . Here is some brief information about ANALYSE : PostgreSQL ANALYZE command collects statistics about specific table columns, entire table, or entire database. The PostgreSQL query planner then uses that data to generate efficient execution plans for queries. 5. SatSense PostgreSQL Ingester The SatSense PostgreSQL Ingester (SatPGI) handles all updating of the SatSense InSAR dataset. Documentation on how to checkout a development/production instance of SatPGI is held in the project README. This chapter is intended to be supplementary to that README; the contents are: Current Installation Details (TODO) Setting Up A User (TODO) Vacuuming. 3. Vacuuming Introduction PostgreSQL is based on a \"Multi Version Concurrency Control\" (MVCC) architecture. Here is quite a good post about MVCC: http://shiroyasha.io/multiversion-concurrency-control.html The important take away is that when updating (or deleting) a row in the database, there can be two \"versions\" (called tuples) of that row. A query will get a particular tuple depending on when the query is run. Some of the database transactions that SatPGI runs are very long running. Queries that are run in the duration of one of these transactions will not see any updated data; they will read the old tuples. However, queries run after a transaction has finished will see the updated tuples and not be able to read the old tuples. A priori, a tuple does not know if it is able to be read (known as live) or not (known as dead). There needs to be a process which detects dead tuples and deletes them. This process is known as \"vacuuming\". By default, PostgreSQL automates a periodic vacuuming process (autovacuuming). However, if large updates or deletes are run then autovaccuming may not be enough and a database can grow massively as it will be storing multiple tuples for each row (effectively doubling/tripling the storage size of that row). To help mitigate this problem, SatPGI will manually run Vacuum statements after it has run large updates. So a SatPGI user should not have to worry too much, however this section should help anyone who wants to debug/further investigate vacuuming. For reference, the PostgreSQL documentation page for vacuuming can be found here: https://www.postgresql.org/docs/11/sql-vacuum.html Analysing Connect to the database using psql and then run the following to get statistics about each table: SELECT relname AS TableName, n_live_tup, n_dead_tup, last_vacuum, last_autovacuum FROM pg_stat_user_tables; In the above query: * n_live_tup denotes the number of live tuples in the table; * n_dead_tup denotes the number of dead tuples in the table; * last_vacuum is a time stamp of when vacuum was last manually run (or null for never); * last_autovacuum is a time stamp of when vacuum was last automatically run (or null for never); The above statistics are only an estimation and certain processes (such as vacuuming) can update these statistics (finding out exactly when these stats are updated are a TODO). SatPGI's vacuuming implementation SatPGI applies a standard (as opposed to a \"full\") vacuum to points tables that have just had large updates run on them. This type of vacuum does not apply an exclusive lock on the table (as opposed to full vacuum which does) but it can be less effective at releasing hard disk space back to the system. Even if this is that case, the space can be still be used for new/updated rows for the table in question. The vacuum process cannot be run inside a transaction, as a result we have defined a OutOfTransactionUnitOfWork object (see unit_of_work.py ) which will handle this process for us. Another interesting feature of vacuuming is that it must be run by either: * a database superuser (such as postgres); * the owner of the database containing the table being vacuumed; * the owner of the table being vacuumed. In the interest of giving the least amount of privileges, we opt for the last option for the user that SatPGI uses to connect to the database with. One can alter the owner of a table via the command: ALTER TABLE <table_name> OWNER TO <new_owner>; Note that it is easiest to run this command as a superuser (although it is possible to run it without the superuser privilege).","title":"Overview"},{"location":"client-facing-applications/database/#overview","text":"The portal and api have access to SatSense InSAR and user data contained in a PostgreSQL database (or sometimes known as a \"postgres\" database). We are currently using PostgreSQL version 11. Since the InSAR and user data is geographically aware, we use the extension PostGIS . PostGIS is a highly capable open source extension to PostgreSQL that allows efficient storage and queries of geographical datasets. This page aims to be a reference for how to install, set up and use PostgreSQL and PostGIS. It aims to include instructions specific to our use case, but also to be a generic reference as well. All links to PostgreSQL documentation will be to version 11 documentation. Contents: 1. Installation of PostgreSQL and PostGIS 2. User Creation 3. Tuning (TODO) 4. Backing Up Procedure 5. SatSense Postgres Ingester 6. Current Database Setup","title":"Overview"},{"location":"client-facing-applications/database/#1-installation-of-postgresql-and-postgis","text":"","title":"1. Installation of PostgreSQL and PostGIS"},{"location":"client-facing-applications/database/#production-on-centos-7","text":"TODO","title":"Production on Centos 7"},{"location":"client-facing-applications/database/#postgresql-12-postgis-on-ubuntu-2004","text":"","title":"PostgreSQL 12 + PostGIS on Ubuntu 20.04"},{"location":"client-facing-applications/database/#postgresql","text":"Install postgres via sudo apt install postgresql postgresql-contrib To check it's working correctly, you can log in to psql as postgres sudo su postgres psql","title":"PostgreSQL"},{"location":"client-facing-applications/database/#change-data-directory","text":"The following assumes a clean installation of postgres. Open the config: vi /etc/postgresql/12/main/postgresql.conf and change the value data_directory to the location you'd like. You also need to initialise this directory via: /usr/lib/postgresql/12/bin/initdb <data_directory> The change requires a restart of the postgresql process: sudo systemctl restart postgresql You can then log into psql and check it has been update by using the command SHOW data_directory; .","title":"Change data directory"},{"location":"client-facing-applications/database/#change-authentication","text":"By default, postgresql only allows peer authentication. This means that the linux user name has to match the postgresql user name for you to log in. To allow logging in by using a password, first set a password for the postgresql postgres user by running the following in psql : ALTER ROLE postgres WITH PASSWORD 'new_password'; Then edit the file sudo vi /etc/postgresql/12/main/pg_hba.conf and change all lines that are similar to: local all all peer to local all all md5 And restart the postgres service: sudo systemctl restart postgresql You'll then be able to log in using a password, try using psql -U postgres where -U means the postgres user name you are providing.","title":"Change authentication"},{"location":"client-facing-applications/database/#postgis","text":"Add the ubuntugis ppa: sudo add-apt-repository ppa:ubuntugis/ppa sudo apt-get update And then postgis: sudo apt install postgis postgresql-12-postgis-3","title":"PostGIS"},{"location":"client-facing-applications/database/#2-user-creation-and-permissions","text":"In the following, replace text surrounded '<' and '>' with values you would like. The following assumes that you are connected to postgresql via psql as a superuser (e.g. postgres).","title":"2. User Creation and Permissions"},{"location":"client-facing-applications/database/#create-new-user","text":"To create a new user: \\set usertograntaccessto '<portal_user>' CREATE USER :usertograntaccessto WITH ENCRYPTED PASSWORD '<password>'; where <password> is sufficiently strong, it is recommended to use a random password generator. The line \\set usertograntaccessto '<portal_user>' sets a variable in the psql session - the value is called with a preceding colon i.e. :usertograntaccessto .","title":"Create New User"},{"location":"client-facing-applications/database/#grant-read-only-privileges","text":"We assume that the variable :usertograntaccessto is set as per the \"Create New User\" section. To grant read only access to a database: \\c <db name> \\set dbname '<db name>' GRANT CONNECT ON DATABASE :dbname TO :usertograntaccessto; GRANT USAGE ON SCHEMA public TO :usertograntaccessto; GRANT SELECT ON ALL TABLES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO :usertograntaccessto; Note that it is recommended to connect to the database first - the last three lines don't specify which database to grant permissions to, rather it is the database you are connected to that defines this. The line ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO :usertograntaccessto; will mean that if tables are added to the schema, then :usertograntaccessto will automatically be given the SELECT privilege. Important Default privileges will only be granted to tables added by the same user as who ran the line \"ALTER DEFAULT PRIVILEGES...\". That is, if \"postgres\" ran the line \"ALTER DEFAULT PRIVILEGES...\", then \"postgres\" must be the user that changes the schema.","title":"Grant Read Only Privileges"},{"location":"client-facing-applications/database/#grant-read-write-privileges","text":"","title":"Grant Read Write Privileges"},{"location":"client-facing-applications/database/#select-insert-update","text":"We assume that the variable :usertograntaccessto is set as per the \"Create New User\" section. To grant SELECT, INSERT, UPDATE access to user database: \\c <db name> \\set dbname '<db name>' GRANT CONNECT ON DATABASE :dbname TO :usertograntaccessto; GRANT USAGE ON SCHEMA public TO :usertograntaccessto; GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE ON TABLES TO :usertograntaccessto; GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO :usertograntaccessto; As above, it is recommended to connect to the database first (i.e. with the first line). Also as above, lines starting with ALTER DEFAULT PRIVILEGES will mean that if tables are added to the schema, then :usertograntaccessto will automatically be given the correct privileges. Important Default privileges will only be granted to tables added by the same user as who ran the line \"ALTER DEFAULT PRIVILEGES...\". That is, if \"postgres\" ran the line \"ALTER DEFAULT PRIVILEGES...\", then \"postgres\" must be the user that changes the schema.","title":"SELECT, INSERT, UPDATE"},{"location":"client-facing-applications/database/#select-insert-update-delete","text":"We note that some apps may also require the DELETE privilege. For instance, the admin site has the ability to delete users, whereas the portal does not. To grant SELECT, INSERT, UPDATE, DELETE access to user database: \\c <db name> \\set dbname '<db name>' GRANT CONNECT ON DATABASE :dbname TO :usertograntaccessto; GRANT USAGE ON SCHEMA public TO :usertograntaccessto; GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO :usertograntaccessto; GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO :usertograntaccessto; ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO :usertograntaccessto;","title":"SELECT, INSERT, UPDATE, DELETE"},{"location":"client-facing-applications/database/#change-table-ownership","text":"We finish by noting that Postgres Ingester requires greater access to tables than SELECT, INSERT, UPDATE and DELETE. Because it runs manual vacuuming, the user needs to own the tables it vacuums. You can change user ownership via: ALTER TABLE <table_name> OWNER TO <new_owner>; Note that it is easiest to run this command as a superuser (e.g. postgres ).","title":"Change Table Ownership"},{"location":"client-facing-applications/database/#query-current-permissions","text":"Whilst connected to a you can use \\dp to query current permissions. And \\ddp to query the default permissions for all users.","title":"Query Current Permissions"},{"location":"client-facing-applications/database/#3-tuning","text":"See https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server Open the postgresql.conf file, on live this is sudo vi /data/pgdata11/postgresql.conf And change the following: * You could increase max_connections (live is 200). Much more than a few hundred, should consider connection pooling ( PgBouncer ). * Increase shared_buffers (live is 8GB). * Increase work_mem (live is 40MB). * Increase maintenance_work_mem (live is 1GB). * Increase effective_cache_size , advice ranges from 1/4 to 1/2 of RAM, live is 32GB.","title":"3. Tuning"},{"location":"client-facing-applications/database/#4-backing-up-procedure","text":"","title":"4. Backing Up Procedure"},{"location":"client-facing-applications/database/#pg_dump","text":"To back up our databases, we currently use the PostgreSQL utility pg_dump . This produces a single file which can then be used to restore in another PostgreSQL instance.","title":"pg_dump"},{"location":"client-facing-applications/database/#example-usage","text":"pg_dump database_name -Fc -p 5440 -U postgres -v > name_of_backup.bak In the above: * database_name should be replaced with the name of the database that you would like to back up. * -Fc denotes that pg_dump should use a custom format. The format here is .bak , which is determined by the suffix of the out file name. For more options, see the docs . * -p 5440 denotes the port that the PostgreSQL is listening on. * -U postgres is the user that pg_dump should connect to the database as. * -v adds verbosity. A back up of the live InSAR database can take a long time (2 days). * name_of_backup.bak should be replaced with the name of the back up file you'd like to create.","title":"Example usage"},{"location":"client-facing-applications/database/#troubleshooting","text":"If you get an error like \"server mismatch error\" then it's possible that more than one version of pg_dump is installed. Check that you are calling the correct version, it should be bundled with the postgres installation. For example the current server's pg_dump is at /usr/pgsql-11/bin/pg_dump .","title":"Troubleshooting"},{"location":"client-facing-applications/database/#set-up-pg_dump-cron-job","text":"It is possibly a good idea to set up a separate user for cron jobs: sudo useradd cronuser It might be a good idea to create a readonly user in postgreSQL as well: CREATE USER cronuser WITH ENCRYPTED PASSWORD '<pg_password>'; GRANT CONNECT ON DATABASE <database_name> TO cronuser; \\c <database_name> GRANT USAGE ON SCHEMA public TO cronuser; GRANT SELECT ON ALL TABLES IN SCHEMA public TO cronuser; GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO cronuser; GRANT USAGE ON SCHEMA topology TO cronuser; GRANT SELECT ON ALL TABLES IN SCHEMA topology TO cronuser; GRANT SELECT ON ALL SEQUENCES IN SCHEMA topology TO cronuser; It is not a good idea to put the cronuser <pg_password> in the cron file. Instead, we create a .pgpass file. As the linux user cronuser , create the file touch ~/.pgpass chmod 0600 ~/.pgpass which should be populated with the structure server:port:database:username:password . For example, inserting the line: localhost:5440:*:cronuser:<pg_password> will allow credentials to any database (assuming cronuser has the correct permissions). Now run crontab -e and insert the something like: 0 22 * * * /usr/pgsql-11/bin/pg_dump <database_name> -Fc -w -p 5440 -U cronuser > /path/to/backups/database_name_$(date +\"\\%Y\\%m\\%d\").bak which will back up the database everyday at 22:00. Notice that we've escaped '%' and make sure you also enter a new line after the above line. A lovely feature of crontab is that they don't run commands without a new line after them.","title":"Set up pg_dump cron job"},{"location":"client-facing-applications/database/#restoring-a-bak-file","text":"For the following commands, you many need to use -p <port> -U <username> , the commands may also suffer a similar \"server mismatch error\" to pg_dump . First create a new database: createdb -T template0 mynewdb Here: * -T template0 means that nothing is created in the new database. By default, createdb will use template1 which may include some default schemas which you will not need. * mynewdb should be replaced with name of the new database you'd like to create. It should not exist. Once the database has been created, you can restore the back up: pg_restore -d mynewdb -v name_of_backup.bak -d mynewdb is the database name, as above. -v adds verbosity. name_of_backup.bak is the name of the back up file you'd like to restore. We note that the back up will try to restore the user/role access defined on the original database. The pg_restore function will show some errors if the users/roles don't exist. You shouldn't need to worry, the data should have restored fine but you will need to add any user access that you need. Sometimes the pg_restore command can fail with an error like: pg_restore: [archiver] unsupported version (1.14) in file header This may be due to using the version of pg_restore which is within your conda environment. Deactivate the conda environment and try rerunning the command. After restoring the backup, it is recommended to run ANALYSE; whilst connected to the database via psql . Here is some brief information about ANALYSE : PostgreSQL ANALYZE command collects statistics about specific table columns, entire table, or entire database. The PostgreSQL query planner then uses that data to generate efficient execution plans for queries.","title":"Restoring a .bak file"},{"location":"client-facing-applications/database/#5-satsense-postgresql-ingester","text":"The SatSense PostgreSQL Ingester (SatPGI) handles all updating of the SatSense InSAR dataset. Documentation on how to checkout a development/production instance of SatPGI is held in the project README. This chapter is intended to be supplementary to that README; the contents are: Current Installation Details (TODO) Setting Up A User (TODO) Vacuuming.","title":"5. SatSense PostgreSQL Ingester"},{"location":"client-facing-applications/database/#3-vacuuming","text":"","title":"3. Vacuuming"},{"location":"client-facing-applications/database/#introduction","text":"PostgreSQL is based on a \"Multi Version Concurrency Control\" (MVCC) architecture. Here is quite a good post about MVCC: http://shiroyasha.io/multiversion-concurrency-control.html The important take away is that when updating (or deleting) a row in the database, there can be two \"versions\" (called tuples) of that row. A query will get a particular tuple depending on when the query is run. Some of the database transactions that SatPGI runs are very long running. Queries that are run in the duration of one of these transactions will not see any updated data; they will read the old tuples. However, queries run after a transaction has finished will see the updated tuples and not be able to read the old tuples. A priori, a tuple does not know if it is able to be read (known as live) or not (known as dead). There needs to be a process which detects dead tuples and deletes them. This process is known as \"vacuuming\". By default, PostgreSQL automates a periodic vacuuming process (autovacuuming). However, if large updates or deletes are run then autovaccuming may not be enough and a database can grow massively as it will be storing multiple tuples for each row (effectively doubling/tripling the storage size of that row). To help mitigate this problem, SatPGI will manually run Vacuum statements after it has run large updates. So a SatPGI user should not have to worry too much, however this section should help anyone who wants to debug/further investigate vacuuming. For reference, the PostgreSQL documentation page for vacuuming can be found here: https://www.postgresql.org/docs/11/sql-vacuum.html","title":"Introduction"},{"location":"client-facing-applications/database/#analysing","text":"Connect to the database using psql and then run the following to get statistics about each table: SELECT relname AS TableName, n_live_tup, n_dead_tup, last_vacuum, last_autovacuum FROM pg_stat_user_tables; In the above query: * n_live_tup denotes the number of live tuples in the table; * n_dead_tup denotes the number of dead tuples in the table; * last_vacuum is a time stamp of when vacuum was last manually run (or null for never); * last_autovacuum is a time stamp of when vacuum was last automatically run (or null for never); The above statistics are only an estimation and certain processes (such as vacuuming) can update these statistics (finding out exactly when these stats are updated are a TODO).","title":"Analysing"},{"location":"client-facing-applications/database/#satpgis-vacuuming-implementation","text":"SatPGI applies a standard (as opposed to a \"full\") vacuum to points tables that have just had large updates run on them. This type of vacuum does not apply an exclusive lock on the table (as opposed to full vacuum which does) but it can be less effective at releasing hard disk space back to the system. Even if this is that case, the space can be still be used for new/updated rows for the table in question. The vacuum process cannot be run inside a transaction, as a result we have defined a OutOfTransactionUnitOfWork object (see unit_of_work.py ) which will handle this process for us. Another interesting feature of vacuuming is that it must be run by either: * a database superuser (such as postgres); * the owner of the database containing the table being vacuumed; * the owner of the table being vacuumed. In the interest of giving the least amount of privileges, we opt for the last option for the user that SatPGI uses to connect to the database with. One can alter the owner of a table via the command: ALTER TABLE <table_name> OWNER TO <new_owner>; Note that it is easiest to run this command as a superuser (although it is possible to run it without the superuser privilege).","title":"SatPGI's vacuuming implementation"},{"location":"client-facing-applications/demo-portal/","text":"","title":"Demo portal"},{"location":"client-facing-applications/geoserver/","text":"Overview Contents: Installation and Configuration Install Tomcat Install GeoServer Enable Reverse Proxy GeoServer Configuration Using Geoserver Useful Resources Official User Manual Geo-Solutions Training Modules Installation and Configuration We choose to install GeoServer using the web archive via a tomcat container . This seems to be recommended by some users in the community above using the command line installation which utilises an in built jetty container . We first provide instructions for installing tomcat, and then for installing GeoServer itself. Finally, we add some notes about configuring GeoServer before it should be used. Install Tomcat We use this linuxize post for reference, but make some changes - for instance, we use java 11 and not 8. First make sure the yum packages are up to date: ```shell script sudo yum update First we make sure that we've installed a Java Development Kit. One can us the openjdk version: ```shell script sudo yum install java-11-openjdk-devel We add a tomcat user and log in: ```shell script sudo useradd tomcat sudo su tomcat Get the latest download url from the tomcat [download page](https://tomcat.apache.org/download-90.cgi), by right clicking on the core `tar.gz` link and copying it. Note the linked page is for tomcat 9, there may be later version available. Once you have the url, `wget` the `tar.gz` file and unpack it: ```shell script # change the following with your url! wget https://mirrors.ukfast.co.uk/sites/ftp.apache.org/tomcat/tomcat-9/v9.0.36/bin/apache-tomcat-9.0.36.tar.gz tar -xf apache-tomcat-9.0.36.tar.gz Now create a symbolic link so that it is easy to upgrade versions: ```shell script ln -s /home/tomcat/apache-tomcat-9.0.36 /home/tomcat/tomcat-latest We now want to create a systemd process to run tomcat. Create the service config file: ```shell script sudo touch /etc/systemd/system/tomcat.service and populate it with: [Unit] Description=Tomcat 9 servlet container After=network.target [Service] Type=forking User=tomcat Group=tomcat Environment=\"JAVA_HOME=/usr/lib/jvm/jre\" Environment=\"JAVA_OPTS=-Djava.security.egd=file:///dev/urandom\" Environment=\"CATALINA_BASE=/home/tomcat/tomcat-latest\" Environment=\"CATALINA_HOME=/home/tomcat/tomcat-latest\" Environment=\"CATALINA_PID=/home/tomcat/tomcat-latest/temp/tomcat.pid\" Environment=\"CATALINA_OPTS=-Xms512M -Xmx1024M -server -XX:+UseParallelGC\" ExecStart=/home/tomcat/tomcat-latest/bin/startup.sh ExecStop=/home/tomcat/tomcat-latest/bin/shutdown.sh [Install] WantedBy=multi-user.target Reload the daemon and start and enable the service: ```shell script sudo systemctl daemon-reload sudo systemctl start tomcat.service sudo systemctl enable tomcat.service ## Install GeoServer We follow the instructions on the [web archive installation page](https://docs.geoserver.org/latest/en/user/installation/war.html). We already have the JDK installed. Go to the [GeoServer download page](http://geoserver.org/download/), click on `stable` and copy the link for the `Web Archive` package. Back in the command line, whilst logged in as the `tomcat` user, get the package and unzip: ```shell script wget https://sourceforge.net/projects/geoserver/files/GeoServer/2.17.1/geoserver-2.17.1-war.zip unzip ~/geoserver-2.17.1-war.zip -d geoserver_2_17 which will unzip it in a new directory called geoserver_2_17 . To deploy GeoServer, either copy the file geoserver.war from the unzipped directory to /home/tomcat/apache-tomcat-9.0.36/webapps or create a symbolic link to it: ```shell script ln -s /home/tomcat/geoserver_2_17/geoserver.war /home/tomcat/apache-tomcat-9.0.36/webapps and restart tomcat. #### Change Data Directory To ease installing new versions, it is recommended to change the data directory. To do this, add the following context parameter ```xml <context-param> <param-name>GEOSERVER_DATA_DIR</param-name> <param-value>/path/to/geoserver_data</param-value> </context-param> to the GeoServer web.xml file. This geoserver_data directory should be owned by the tomcat user. With the above installation instructions the web.xml file is located at: ```shell script /home/tomcat/apache-tomcat-9.0.36/webapps/geoserver/WEB-INF/web.xml Restart tomcat when finished. ## Enable reverse proxy from apache httpd GeoServer should now be running on port 8080. However, to access the web administration interface, we need to proxy certain web request to this port. This can be done either by adding a new [virtual host](webmisc.md#apache-httpd-set-up) or adding the following to an existing virtual host: ServerName data.satsense.com ServerAlias data.satsense.com ProxyPass /geoserver http://localhost:8080/geoserver ProxyPassReverse /geoserver http://localhost:8080/geoserver and restart the httpd server ```shell script sudo systemctl restart httpd.service It's possible that you'll need to set tell SELinux to allow httpd proxies: ```shell script sudo setsebool -P httpd_can_network_connect 1 Note that the -P flag means that this settings persists upon restart. Check that you can access the admin page by navigating to `http://data.satsense.com/geoserver/` or similar for your domain. ## GeoServer configuration ### Security If you've followed the above instructions you should be on the web admin page. You can log in with the default details: username: admin password: geoserver The home page will warn you about: 1. Read the file security/masterpw.info in the GeoServer data directory and then delete it. 2. The default user/group service should use digest password encoding. 3. The administrator password for this server has not been changed from the default. It should be clear what to do for the last point. For the second point, you can edit the default user/group service by clicking on `User, Groups, Roles` under `Security`, and then clicking `default`. For the first point, navigate to the file `security/masterpw.info` in the [data directory](#change-data-directory) and read its contents. It provides a master password, and should test that you can log in with that password and the username `root`. You may need to enable root sign in by editing security/masterpw/default/config.xml in the data directory. Change the value in the `loginEnabled` tag to `true`, and then restart tomcat. Remember to change the `loginEnabled` back and to delete the `masterpw.info` file after you've checked the password works. ### Add domain to GeoServer csrf whitelist As a layer of protection, GeoServer uses [csrf protection](https://docs.geoserver.org/latest/en/user/security/webadmin/csrf.html) and this can be problematic behind a proxy. Add the following: ```xml <context-param> <param-name>GEOSERVER_CSRF_WHITELIST</param-name> <param-value>satsense.com</param-value> </context-param> to the GeoServer web.xml file. And then restart tomcat. Change Proxy Base Url Once you've added a layer, you may find that layer preview urls are incorrect the urls may be generated with localhost:8080 in them. Clearly this isn't going to work, unless you are running GeoServer locally. To fix this, click on Global under the Settings section and set the Proxy Base URL to http://data.satsense.com/geoserver/ Using GeoServer Add a geotiff layer Preparing a geotiff We've found that compressing with predictor 2 (i.e. with gdal_translate -co \"PREDICTOR=2\" ) can be problematic. See this thread . Unfortunately, some of our code (at time of writing) outputs geotiffs with predictor 2, so you may need to change the predictor before inserting into GeoServer. This can be done via gdal_translate : ```shell script gdal_translate -co \"TILED=YES\" -co \"BLOCKXSIZE=512\" -co \"BLOCKYSIZE=512\" -co \"COMPRESS=LZW\" -co \"BIGTIFF=YES\" -co \"PREDICTOR=1\" Notice that the geotiff is also tiled - this is recommended, otherwise the geotiff is blocked in strips and small reads can be very expensive. We also need to add overviews to the geotiff. The current tileserver uses different geotiffs for its overviews. GeoServer can handle internal overviews which are generated via: ```shell script gdaladdo -r average --config COMPRESS_OVERVIEW LZW <geotiff needing overviews> 2 4 8 16 The geotiff can then be put into a directory onto the server, which GeoServer can then access. The directory should be owned by the tomcat user. The live server geotiffs are contained in the folder /home/tomcat/geoserver_geotiffs which is symbolic linked to /data/geoserver_geotiffs . Add custom style Click Styles under Data and then Add a new style . Give it a name and a workspace. Leave Format as SLD and add <?xml version=\"1.0\" encoding=\"UTF-8\"?> <StyledLayerDescriptor xmlns=\"http://www.opengis.net/sld\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/sld http://schemas.opengis.net/sld/1.0.0/StyledLayerDescriptor.xsd\" version=\"1.0.0\"> <NamedLayer> <Name>SatSenseRaster</Name> <UserStyle> <Title>SatSense Velocity Raster</Title> <FeatureTypeStyle> <Rule> <RasterSymbolizer> <Opacity>0.85</Opacity> <ColorMap> <ColorMapEntry opacity=\"0\" color=\"#d7191c\" quantity=\"-9999\"/> <ColorMapEntry opacity=\"0.85\" label=\"-7.0\" color=\"#d7191c\" quantity=\"-7.0\"/> <ColorMapEntry opacity=\"0.85\" label=\"-3.5\" color=\"#eb8c6d\" quantity=\"-3.5\"/> <ColorMapEntry opacity=\"0.85\" label=\"0.0\" color=\"#fffffe\" quantity=\"0.0\"/> <ColorMapEntry opacity=\"0.85\" label=\"3.5\" color=\"#95c1bd\" quantity=\"3.5\"/> <ColorMapEntry opacity=\"0.85\" label=\"7.0\" color=\"#2b83ba\" quantity=\"7.0\"/> </ColorMap> </RasterSymbolizer> </Rule> </FeatureTypeStyle> </UserStyle> </NamedLayer> </StyledLayerDescriptor> to the text box at the bottom. Add the layer to GeoServer First add a workspace, which should be seen as a container for logically similar layers. Click Workspaces under Data and then Add a new workspace . Populate Name and the Namespace URI . Specifying what these mean is a TODO. Then add a store. Click Stores under Data and Add a new store . Click Geotiff . Choose a workspace, and a name for your store. Then click Browse and navigate to the geotiff. Then add a layer. Click Layers under Data and Add a new layer . Select the Store you've just added. Click Publish . Give it a name and a title. Click publishing tab, and select the style to be the raster style you created. Protect end point We can protect end points on a per workspace or per layer basis. For example, in a workspace, selecting the security tab, we can select which roles can access the workspace. Adding ROLE_AUTHENTICATED means any user with a user name and password can access wms. Other options (details is a TODO): * Remove anonymous authentication; * Disable WCS/WFS;","title":"Overview"},{"location":"client-facing-applications/geoserver/#overview","text":"","title":"Overview"},{"location":"client-facing-applications/geoserver/#contents","text":"Installation and Configuration Install Tomcat Install GeoServer Enable Reverse Proxy GeoServer Configuration Using Geoserver","title":"Contents:"},{"location":"client-facing-applications/geoserver/#useful-resources","text":"Official User Manual Geo-Solutions Training Modules","title":"Useful Resources"},{"location":"client-facing-applications/geoserver/#installation-and-configuration","text":"We choose to install GeoServer using the web archive via a tomcat container . This seems to be recommended by some users in the community above using the command line installation which utilises an in built jetty container . We first provide instructions for installing tomcat, and then for installing GeoServer itself. Finally, we add some notes about configuring GeoServer before it should be used.","title":"Installation and Configuration"},{"location":"client-facing-applications/geoserver/#install-tomcat","text":"We use this linuxize post for reference, but make some changes - for instance, we use java 11 and not 8. First make sure the yum packages are up to date: ```shell script sudo yum update First we make sure that we've installed a Java Development Kit. One can us the openjdk version: ```shell script sudo yum install java-11-openjdk-devel We add a tomcat user and log in: ```shell script sudo useradd tomcat sudo su tomcat Get the latest download url from the tomcat [download page](https://tomcat.apache.org/download-90.cgi), by right clicking on the core `tar.gz` link and copying it. Note the linked page is for tomcat 9, there may be later version available. Once you have the url, `wget` the `tar.gz` file and unpack it: ```shell script # change the following with your url! wget https://mirrors.ukfast.co.uk/sites/ftp.apache.org/tomcat/tomcat-9/v9.0.36/bin/apache-tomcat-9.0.36.tar.gz tar -xf apache-tomcat-9.0.36.tar.gz Now create a symbolic link so that it is easy to upgrade versions: ```shell script ln -s /home/tomcat/apache-tomcat-9.0.36 /home/tomcat/tomcat-latest We now want to create a systemd process to run tomcat. Create the service config file: ```shell script sudo touch /etc/systemd/system/tomcat.service and populate it with: [Unit] Description=Tomcat 9 servlet container After=network.target [Service] Type=forking User=tomcat Group=tomcat Environment=\"JAVA_HOME=/usr/lib/jvm/jre\" Environment=\"JAVA_OPTS=-Djava.security.egd=file:///dev/urandom\" Environment=\"CATALINA_BASE=/home/tomcat/tomcat-latest\" Environment=\"CATALINA_HOME=/home/tomcat/tomcat-latest\" Environment=\"CATALINA_PID=/home/tomcat/tomcat-latest/temp/tomcat.pid\" Environment=\"CATALINA_OPTS=-Xms512M -Xmx1024M -server -XX:+UseParallelGC\" ExecStart=/home/tomcat/tomcat-latest/bin/startup.sh ExecStop=/home/tomcat/tomcat-latest/bin/shutdown.sh [Install] WantedBy=multi-user.target Reload the daemon and start and enable the service: ```shell script sudo systemctl daemon-reload sudo systemctl start tomcat.service sudo systemctl enable tomcat.service ## Install GeoServer We follow the instructions on the [web archive installation page](https://docs.geoserver.org/latest/en/user/installation/war.html). We already have the JDK installed. Go to the [GeoServer download page](http://geoserver.org/download/), click on `stable` and copy the link for the `Web Archive` package. Back in the command line, whilst logged in as the `tomcat` user, get the package and unzip: ```shell script wget https://sourceforge.net/projects/geoserver/files/GeoServer/2.17.1/geoserver-2.17.1-war.zip unzip ~/geoserver-2.17.1-war.zip -d geoserver_2_17 which will unzip it in a new directory called geoserver_2_17 . To deploy GeoServer, either copy the file geoserver.war from the unzipped directory to /home/tomcat/apache-tomcat-9.0.36/webapps or create a symbolic link to it: ```shell script ln -s /home/tomcat/geoserver_2_17/geoserver.war /home/tomcat/apache-tomcat-9.0.36/webapps and restart tomcat. #### Change Data Directory To ease installing new versions, it is recommended to change the data directory. To do this, add the following context parameter ```xml <context-param> <param-name>GEOSERVER_DATA_DIR</param-name> <param-value>/path/to/geoserver_data</param-value> </context-param> to the GeoServer web.xml file. This geoserver_data directory should be owned by the tomcat user. With the above installation instructions the web.xml file is located at: ```shell script /home/tomcat/apache-tomcat-9.0.36/webapps/geoserver/WEB-INF/web.xml Restart tomcat when finished. ## Enable reverse proxy from apache httpd GeoServer should now be running on port 8080. However, to access the web administration interface, we need to proxy certain web request to this port. This can be done either by adding a new [virtual host](webmisc.md#apache-httpd-set-up) or adding the following to an existing virtual host: ServerName data.satsense.com ServerAlias data.satsense.com ProxyPass /geoserver http://localhost:8080/geoserver ProxyPassReverse /geoserver http://localhost:8080/geoserver and restart the httpd server ```shell script sudo systemctl restart httpd.service It's possible that you'll need to set tell SELinux to allow httpd proxies: ```shell script sudo setsebool -P httpd_can_network_connect 1 Note that the -P flag means that this settings persists upon restart. Check that you can access the admin page by navigating to `http://data.satsense.com/geoserver/` or similar for your domain. ## GeoServer configuration ### Security If you've followed the above instructions you should be on the web admin page. You can log in with the default details: username: admin password: geoserver The home page will warn you about: 1. Read the file security/masterpw.info in the GeoServer data directory and then delete it. 2. The default user/group service should use digest password encoding. 3. The administrator password for this server has not been changed from the default. It should be clear what to do for the last point. For the second point, you can edit the default user/group service by clicking on `User, Groups, Roles` under `Security`, and then clicking `default`. For the first point, navigate to the file `security/masterpw.info` in the [data directory](#change-data-directory) and read its contents. It provides a master password, and should test that you can log in with that password and the username `root`. You may need to enable root sign in by editing security/masterpw/default/config.xml in the data directory. Change the value in the `loginEnabled` tag to `true`, and then restart tomcat. Remember to change the `loginEnabled` back and to delete the `masterpw.info` file after you've checked the password works. ### Add domain to GeoServer csrf whitelist As a layer of protection, GeoServer uses [csrf protection](https://docs.geoserver.org/latest/en/user/security/webadmin/csrf.html) and this can be problematic behind a proxy. Add the following: ```xml <context-param> <param-name>GEOSERVER_CSRF_WHITELIST</param-name> <param-value>satsense.com</param-value> </context-param> to the GeoServer web.xml file. And then restart tomcat.","title":"Install Tomcat"},{"location":"client-facing-applications/geoserver/#change-proxy-base-url","text":"Once you've added a layer, you may find that layer preview urls are incorrect the urls may be generated with localhost:8080 in them. Clearly this isn't going to work, unless you are running GeoServer locally. To fix this, click on Global under the Settings section and set the Proxy Base URL to http://data.satsense.com/geoserver/","title":"Change Proxy Base Url"},{"location":"client-facing-applications/geoserver/#using-geoserver","text":"","title":"Using GeoServer"},{"location":"client-facing-applications/geoserver/#add-a-geotiff-layer","text":"","title":"Add a geotiff layer"},{"location":"client-facing-applications/geoserver/#preparing-a-geotiff","text":"We've found that compressing with predictor 2 (i.e. with gdal_translate -co \"PREDICTOR=2\" ) can be problematic. See this thread . Unfortunately, some of our code (at time of writing) outputs geotiffs with predictor 2, so you may need to change the predictor before inserting into GeoServer. This can be done via gdal_translate : ```shell script gdal_translate -co \"TILED=YES\" -co \"BLOCKXSIZE=512\" -co \"BLOCKYSIZE=512\" -co \"COMPRESS=LZW\" -co \"BIGTIFF=YES\" -co \"PREDICTOR=1\" Notice that the geotiff is also tiled - this is recommended, otherwise the geotiff is blocked in strips and small reads can be very expensive. We also need to add overviews to the geotiff. The current tileserver uses different geotiffs for its overviews. GeoServer can handle internal overviews which are generated via: ```shell script gdaladdo -r average --config COMPRESS_OVERVIEW LZW <geotiff needing overviews> 2 4 8 16 The geotiff can then be put into a directory onto the server, which GeoServer can then access. The directory should be owned by the tomcat user. The live server geotiffs are contained in the folder /home/tomcat/geoserver_geotiffs which is symbolic linked to /data/geoserver_geotiffs .","title":"Preparing a geotiff"},{"location":"client-facing-applications/geoserver/#add-custom-style","text":"Click Styles under Data and then Add a new style . Give it a name and a workspace. Leave Format as SLD and add <?xml version=\"1.0\" encoding=\"UTF-8\"?> <StyledLayerDescriptor xmlns=\"http://www.opengis.net/sld\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/sld http://schemas.opengis.net/sld/1.0.0/StyledLayerDescriptor.xsd\" version=\"1.0.0\"> <NamedLayer> <Name>SatSenseRaster</Name> <UserStyle> <Title>SatSense Velocity Raster</Title> <FeatureTypeStyle> <Rule> <RasterSymbolizer> <Opacity>0.85</Opacity> <ColorMap> <ColorMapEntry opacity=\"0\" color=\"#d7191c\" quantity=\"-9999\"/> <ColorMapEntry opacity=\"0.85\" label=\"-7.0\" color=\"#d7191c\" quantity=\"-7.0\"/> <ColorMapEntry opacity=\"0.85\" label=\"-3.5\" color=\"#eb8c6d\" quantity=\"-3.5\"/> <ColorMapEntry opacity=\"0.85\" label=\"0.0\" color=\"#fffffe\" quantity=\"0.0\"/> <ColorMapEntry opacity=\"0.85\" label=\"3.5\" color=\"#95c1bd\" quantity=\"3.5\"/> <ColorMapEntry opacity=\"0.85\" label=\"7.0\" color=\"#2b83ba\" quantity=\"7.0\"/> </ColorMap> </RasterSymbolizer> </Rule> </FeatureTypeStyle> </UserStyle> </NamedLayer> </StyledLayerDescriptor> to the text box at the bottom.","title":"Add custom style"},{"location":"client-facing-applications/geoserver/#add-the-layer-to-geoserver","text":"First add a workspace, which should be seen as a container for logically similar layers. Click Workspaces under Data and then Add a new workspace . Populate Name and the Namespace URI . Specifying what these mean is a TODO. Then add a store. Click Stores under Data and Add a new store . Click Geotiff . Choose a workspace, and a name for your store. Then click Browse and navigate to the geotiff. Then add a layer. Click Layers under Data and Add a new layer . Select the Store you've just added. Click Publish . Give it a name and a title. Click publishing tab, and select the style to be the raster style you created.","title":"Add the layer to GeoServer"},{"location":"client-facing-applications/geoserver/#protect-end-point","text":"We can protect end points on a per workspace or per layer basis. For example, in a workspace, selecting the security tab, we can select which roles can access the workspace. Adding ROLE_AUTHENTICATED means any user with a user name and password can access wms. Other options (details is a TODO): * Remove anonymous authentication; * Disable WCS/WFS;","title":"Protect end point"},{"location":"client-facing-applications/overview/","text":"SatSense Client-Facing Applications Overview The purpose of this section is to document the set up and usage of the SatSense client-facing application ecosystem. The following diagram illustrates this ecosystem: An editable version of this diagram is kept on sharepoint . We now explain this diagram in some detail; we run through each section of this diagram in the order that the data follows; from creation to delivery. Raw InSAR Data Pipeline (a black box) SatSense's processing pipeline (labelled as \"Raw InSAR Data Pipeline\") is intentionally represented as a black box. It's not too important to know the details about this pipeline, but the unenlightened and interested reader can find more details here . The really important takeaways are: This is where the magic starts (i.e. this is where SatSense data is created); The output is a bunch of hdf5 files , and the postgres ingester accepts these as an input; A subset of the admin suite (known as the \"Processing Controller\") helps monitor this pipeline, and the intention is for the admin suite to eventually control this pipeline. Satpgi (PostgresIngester) The soul responsibility of this set of python scripts is to get the output of the processing pipeline into a format that is easily queryable by applications. These scripts take in a set of hdf5 files as input and outputs a load of that data into the InSAR Database . The repository is kept here and more information on this project can be found here . InSAR Database This is a very large PostGIS enabled PostgreSQL database. For this database, we use a schema migration tool called alembic , the migrations are stored here . See here for more information. Satdes (Data Extract Service) This project houses a load of python scripts that take data from the InSAR Database and extracts them into files (e.g. csv, shapefile, geojson). These files can provide a friendly format to send to clients or for local analysis. SatShop utilises satdes in order to honour its orders (although, it is currently a manual process). More information here . SatSense Domain (satdom) Scripts These are python scripts that live in the satdom project. Satdom is a centralised library of code that is utilised by a number of other projects, more information in the satdom project README . The purpose of these scripts is to provide a repeatable and testable way to extract large amounts of InSAR data into files (generally geotiffs). The reader is probably confused why these scripts do not exist in satdes (and rightfully so). The distinction is as follows. Satdes is a tool that is accessible to the majority of the SatSense team and allows extraction of a geographic subset of InSAR data. In contrast, the satdom scripts are tools used to generate derived or cached data assets that are served by applications (e.g. srisk geotiffs for the API, or velocity tiles for the portal). More information is here . API A very lightweight project that serves SatSense data. Using flask-restful , the project is essentially just a wrapper around code that exists in the satdom . The main end points expect a small posted polygon and in return will serve a traffic light (green, amber, red). This traffic light indicates how much movement SatSense data detects within the polygon using various derived products. These derived products can be quite time-consuming to calculate, so we have opted to cache them in a big geotiff (an output of a satdom script). More information here . SatShop/Portal (satportal) A web GIS application built using flask, angular js, and leaflet. It allows a user to browse SatSense data, or to order SatSense data to download and analyse locally. The web interface connects directly connects to the InSAR Database allowing queries of point time series. It also hooks into the Tileserver. A lot of the satportal code wraps functions in satdom - you can read more about the project here . Tileserver The main purpose of this project is to render tiles for web portal part of satportal. Having said that, it is possible to utilise the tileserver from other clients (e.g. QGIS). When asking for tiles at a high enough zoom level (higher means more zoomed in), then the tileserver will render velocities for individual points. However, for lower zoom levels, it's not possible for the tileserver to render all points for a tile nor is it possible for the tileserver to render aggregated velocities - in either case, there are just too many points. Instead, we cache aggregated results in a geotiff (output of a satdom script), and use these geotiffs to display tiles at these lower zoom levels. Tileserver repository is here and more information is here . Admin suite The diagram at the top details the journey of SatSense InSAR data. But it misses out how we control access to all of these assets. All of the applications (boxes in yellow) hook into a PostgreSQL database that contains user information - it was clunky to represent this on the diagram but also easy to describe in words. The admin suite controls access to the applications (including itself). Additionally, as we've already mentioned, a subset of admin suite also helps monitor the processing pipeline. Repository is here and more information is here .","title":"SatSense Client-Facing Applications Overview"},{"location":"client-facing-applications/overview/#satsense-client-facing-applications-overview","text":"The purpose of this section is to document the set up and usage of the SatSense client-facing application ecosystem. The following diagram illustrates this ecosystem: An editable version of this diagram is kept on sharepoint . We now explain this diagram in some detail; we run through each section of this diagram in the order that the data follows; from creation to delivery.","title":"SatSense Client-Facing Applications Overview"},{"location":"client-facing-applications/overview/#raw-insar-data-pipeline-a-black-box","text":"SatSense's processing pipeline (labelled as \"Raw InSAR Data Pipeline\") is intentionally represented as a black box. It's not too important to know the details about this pipeline, but the unenlightened and interested reader can find more details here . The really important takeaways are: This is where the magic starts (i.e. this is where SatSense data is created); The output is a bunch of hdf5 files , and the postgres ingester accepts these as an input; A subset of the admin suite (known as the \"Processing Controller\") helps monitor this pipeline, and the intention is for the admin suite to eventually control this pipeline.","title":"Raw InSAR Data Pipeline (a black box)"},{"location":"client-facing-applications/overview/#satpgi-postgresingester","text":"The soul responsibility of this set of python scripts is to get the output of the processing pipeline into a format that is easily queryable by applications. These scripts take in a set of hdf5 files as input and outputs a load of that data into the InSAR Database . The repository is kept here and more information on this project can be found here .","title":"Satpgi (PostgresIngester)"},{"location":"client-facing-applications/overview/#insar-database","text":"This is a very large PostGIS enabled PostgreSQL database. For this database, we use a schema migration tool called alembic , the migrations are stored here . See here for more information.","title":"InSAR Database"},{"location":"client-facing-applications/overview/#satdes-data-extract-service","text":"This project houses a load of python scripts that take data from the InSAR Database and extracts them into files (e.g. csv, shapefile, geojson). These files can provide a friendly format to send to clients or for local analysis. SatShop utilises satdes in order to honour its orders (although, it is currently a manual process). More information here .","title":"Satdes (Data Extract Service)"},{"location":"client-facing-applications/overview/#satsense-domain-satdom-scripts","text":"These are python scripts that live in the satdom project. Satdom is a centralised library of code that is utilised by a number of other projects, more information in the satdom project README . The purpose of these scripts is to provide a repeatable and testable way to extract large amounts of InSAR data into files (generally geotiffs). The reader is probably confused why these scripts do not exist in satdes (and rightfully so). The distinction is as follows. Satdes is a tool that is accessible to the majority of the SatSense team and allows extraction of a geographic subset of InSAR data. In contrast, the satdom scripts are tools used to generate derived or cached data assets that are served by applications (e.g. srisk geotiffs for the API, or velocity tiles for the portal). More information is here .","title":"SatSense Domain (satdom) Scripts"},{"location":"client-facing-applications/overview/#api","text":"A very lightweight project that serves SatSense data. Using flask-restful , the project is essentially just a wrapper around code that exists in the satdom . The main end points expect a small posted polygon and in return will serve a traffic light (green, amber, red). This traffic light indicates how much movement SatSense data detects within the polygon using various derived products. These derived products can be quite time-consuming to calculate, so we have opted to cache them in a big geotiff (an output of a satdom script). More information here .","title":"API"},{"location":"client-facing-applications/overview/#satshopportal-satportal","text":"A web GIS application built using flask, angular js, and leaflet. It allows a user to browse SatSense data, or to order SatSense data to download and analyse locally. The web interface connects directly connects to the InSAR Database allowing queries of point time series. It also hooks into the Tileserver. A lot of the satportal code wraps functions in satdom - you can read more about the project here .","title":"SatShop/Portal (satportal)"},{"location":"client-facing-applications/overview/#tileserver","text":"The main purpose of this project is to render tiles for web portal part of satportal. Having said that, it is possible to utilise the tileserver from other clients (e.g. QGIS). When asking for tiles at a high enough zoom level (higher means more zoomed in), then the tileserver will render velocities for individual points. However, for lower zoom levels, it's not possible for the tileserver to render all points for a tile nor is it possible for the tileserver to render aggregated velocities - in either case, there are just too many points. Instead, we cache aggregated results in a geotiff (output of a satdom script), and use these geotiffs to display tiles at these lower zoom levels. Tileserver repository is here and more information is here .","title":"Tileserver"},{"location":"client-facing-applications/overview/#admin-suite","text":"The diagram at the top details the journey of SatSense InSAR data. But it misses out how we control access to all of these assets. All of the applications (boxes in yellow) hook into a PostgreSQL database that contains user information - it was clunky to represent this on the diagram but also easy to describe in words. The admin suite controls access to the applications (including itself). Additionally, as we've already mentioned, a subset of admin suite also helps monitor the processing pipeline. Repository is here and more information is here .","title":"Admin suite"},{"location":"client-facing-applications/portal/","text":"Portal/SatShop (satportal) This is a web GIS application consisting of two major features: allows a user to browse SatSense data that is streamed from the server; allows a user to order and download SatSense data extracted from the server. Historically, we have named the project the \"portal\", but with the addition of the ordering feature we rebranded the site to \"satshop\". This documentation may refer to the project by either name. We also have a demo portal, but because that is still using a legacy php version of the code, we separate documentation for the demo portal to here . Instructions for how to install an instance of the portal/satshop into a virtual environment are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with how to set up apache to forward on requests. Contents Live Server Locations - where files related to the portal are kept on the live server. First Release - how to release a brand new portal. Release Update - how to release an update to a portal that's already been released. Troubleshooting - something not working? No problem. Live Server Locations On the live server, we run several portals, this is so that we can test new datasets/provide other data sets/test new versions without affecting the live site. This is a list of the portals that are running, along with locations of related important files: Portal instance name Domain end point Project directory Httpd config file Systemd file satshop satshop.satsense.com /var/www/satshop /etc/httpd/sites-available/satshop.conf /etc/systemd/system/satshop.service staging portal.staging.satsense.com /var/www/flask-portal-staging /etc/httpd/sites-available/flask-portal-staging.conf /etc/systemd/system/portalstaging.service portal2 portal2.satsense.com /var/www/flask-portal2 /etc/httpd/sites-available/flask-portal2.conf /etc/systemd/system/portal2.service portal3 portal3.satsense.com /var/www/portal3 /etc/httpd/sites-available/portal3.conf /etc/systemd/system/portal3.service The httpd config files are shared with the tileserver httpd files because they are provided by the same domain. Project directory structure The structure of each \"Project directory\" is as follows: - app_home - log - flask - public - error - static - virtual_environments The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the application, namely app.py and config.ini (see project root ). The directory public contains static assets that are not served by the flask application - the apache server serves them directly. The directory public/error houses static error files; when releasing, it is common to bring the flask server down, at which point apache will return the 503 error document in this directory. The public/static folder provides static assets needed for the website (e.g. js, css, images etc), these assets are build from the project src folder during a gitlab build. The log directory contains logs for the application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the subdirectory log/flask . First Release These are instructions if you need to release a new portal. The reader will also need to set up any ssl certificates and A records. See the web miscellaneous docs for more detail. If you need to release an update, please see the Release Update section. We comment that you may also want to release a new tileserver as well. We assume user/InSAR databases are set up already. Set up project directory In the following, we use a location of a \"new-portal\". The reader should change the folder paths for the application they are setting up. If this is the first flask application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the Project directory structure section: sudo mkdir /var/www/new-portal/ cd /var/www/new-portal/ sudo mkdir public/ sudo chown flaskuser:apache public/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ Notice that flaskuser is the owner of all the directories, but that apache needs access to the public and logs directories. The former is so that the apache server can serve files from this directory without having to give send a proxy request to the flask application. The latter is so the apache server can write logs to this directory. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/new-portal/log(/.*)?\" sudo restorecon -R -v log/ The directories are now set up ready to be populated. Populate project directories We will need to: Download artifacts from the build stage of a satportal gitlab pipeline . Populate the app_home directory. Create a 503 document in public/error . Populate public/static with the static assets. Create a virtual environment for the application and install the project. We run through each of these steps in succession. Unless otherwise stated, we will assume that the following statements will be run as flaskuser . 1. Download satportal artifacts We keep a shell script on the live server that downloads the artifacts automatically for us. This is kept in the file: /home/flaskuser/releases/portal/download_portal_artifacts We keep a copy here as well: #!/bin/bash TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") CURL_OUTFILE=\"satportal_artifacts_$TIMESTAMP.zip\" SATPORTAL_BRANCH=\"master\" HTTP_CODE=$(curl --write-out \"%{http_code}\" --location --output $CURL_OUTFILE --header \"PRIVATE-TOKEN: <gitlab ro access token>\" \"https://gitlab.com/api/v4/projects/16331419/jobs/artifacts/$SATPORTAL_BRANCH/download?job=create_artifacts\") NEW_DIR=\"satportal_$TIMESTAMP\" mkdir $NEW_DIR unzip $CURL_OUTFILE -d $NEW_DIR rm $CURL_OUTFILE printf \"Response code: $HTTP_CODE\\nOut Dir: $NEW_DIR\\n\" Note that if you use the code above, you should create a gitlab access token (preferably read only) and replace <gitlab ro access token> with it. However, the file on the server has an access token pre-filled. Further, if you need to release a branch other than master , then you can change the SATPORTAL_BRANCH variable. For example, at the time of writing (but this is always subject to change), we release a separate branch to \"portal3\" (whose branch is also called portal3 ). By convention, we run the download_portal_artifacts file from inside its directory, i.e. cd /home/flaskuser/releases/portal ./download_portal_artifacts and this will create a timestamped directory of the needed artifacts for a satportal release. 2. Populate app_home We assume that the current directory is the timestamped directory created in the first section cp dist/satportal/app.py /var/www/new-portal/app_home cp dist/satportal/config.ini /var/www/new-portal/app_home Here, app.py is the entry point for the application and config.ini is a config file. The latter needs to be edited with config settings for the application (e.g. database strings, live api keys etc). 3. Create a 503 document Create the required error folder: mkdir /var/www/new-portal/public/error And copy the 503 document from the portal artifacts (we assume the current directory is the directory created in the first section ): cp dist/satportal/error/* /var/www/new-portal/public/error 4. Populate public/static Create the required static folder: mkdir /var/www/new-portal/public/static And copy the static assets from the project assets (we assume the current directory is the directory created in the first section ): cp -r dist/satportal/static/* /var/www/new-portal/public/static There is one caveat. There is a js config and the value of which almost certainly needs changing (unless releasing to portal-staging). Because the js code is transpiled and minified, it is not obvious where to make this change. Open the file (exact name not known before artifact download, hence the wildcard) vi /var/www/new-portal/public/static/js/index-*.js And then search for the string that needs changing (press \"/\" and type part of the string that needs changing (e.g. \"https\") and press return). Edit the string and exit vi. 5. Create a virtual environment Compare the following instructions with the instructions from the project README . Initialise and activate a virtual environment: cd /var/www/new-portal/virtual_environments python3.7 -m venv venv source venv/bin/activate Then change your current directory back to the timestamped directory created in the first section . Install the requirements: pip install \"$(cat dist/satportal/requirements/production.txt | grep numpy)\" pip install GDAL==$(gdal-config --version | awk -F'[.]' '{print $1\".\"$2}') --global-option=build_ext --global-option=\"-I/usr/include/gdal\" pip install -r dist/satportal/requirements/production.txt Then install satdom and satportal wheels (the exact file names are indeterminable before downloading the artifacts - hence the wildcards): pip install dist/satdom/satdom-*.whl pip install dist/satportal/satportal-*.whl Deactivate the virtual environment deactivate Systemd and gunicorn set up Once we've set up the project directories/virtual environment as above, we need something to actually run the application. This is done via systemd and gunicorn. We assume the reader has followed the above instructions. Gunicorn is easy to install via pip. As flaskuser then run: source /var/www/new-portal/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the site is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/new-portal/app_home and replace <port> with a port number. We'd like the above process to be run automatically, which is done by using systemd . To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: sudo touch /etc/systemd/system/newportal.service sudo chmod 664 /etc/systemd/system/newportal.service Then populate the file, with something similar to following (we've assumed a port of \"5000\", but be warned this port is already used on the live server): [Unit] Description = NewPortal After = network.target [Service] User=flaskuser WorkingDirectory=/var/www/new-portal/app_home ExecStart=/var/www/new-portal/virtual_environments/venv/bin/gunicorn -b localhost:5000 -w 4 app:app Restart=always [Install] WantedBy = multi-user.target For systemd to recognise the new file, you will need to run systemctl daemon-reload and you can check it has been found using systemctl list-unit-files The service can be started via: systemctl start newportal We note that the service is named newportal due to the name of the systemd file we created. The service can be stopped via: systemctl stop newportal To allow the service to start on server reboot, it needs to be enabled: systemctl enable newportal Apache set up Once the portal application is running using systemd. We need to let the web server (currently apache) know to proxy requests to this service. To do this we create a virtual host. For further information about virtual hosts, see the apache httpd set up . Here is an example virtual host for the new portal: <VirtualHost *:80> ServerName newportal.satsense.com ServerAlias newportal.satsense.com DocumentRoot /var/www/new-portal/public # rewrite to https RewriteEngine on RewriteCond %{SERVER_NAME} =newportal.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName newportal.satsense.com ServerAlias newportal.satsense.com DocumentRoot /var/www/new-portal/public # flask proxy ProxyPass /static ! ProxyPass /error ! ProxyPass /tiles ! ProxyPass / http://localhost:5000/ ProxyPassReverse / http://localhost:5000/ # logs ErrorLog /var/www/newportal/log/error.log CustomLog /var/www/newportal/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=31536000; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html # wsgi WSGIScriptAlias /tiles /var/www/tileserver-new-ts/Tileserver/tileserver.wsgi WSGIDaemonProcess tileserver_new_ts python-home=/var/www/venvs/tileserver-new-ts processes=4 threads=1 WSGIProcessGroup tileserver_new_ts # ssl SSLCertificateFile /etc/letsencrypt/live/newportal.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/newportal.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/newportal.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to newportal.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to newportal.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://newportal.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5000 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /static ! ) mean that requests following this pattern should not be proxied (e.g. https://newportal.satsense.com/static/resource.js ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The wsgi section sets up the tileserver. Requests to https://newportal.satsense.com/tiles are forwarded to the tileserver. See the page about the tileserver . The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release . Release Update This section deals with releasing an update to a portal that is already live. See the previous section for a first release of a new portal. A lot of the steps in this section are similar to first release section - with this in mind, this section lacks the verbosity of the new release section. Check and apply database migrations For more information about alembic (the tool we use for database migrations), see the satdom README . At time of writing the live server has a satsense_domain repository at /home/centos/Projects/alembic/satsense-domain which houses a virtual environment called venv_alembic . The satsense_domain is installed as editable dependency inside venv_alembic . We use this project to run the alembic migrations. Make sure the project is up to date and activate the environment. Change alembic config files (specifically sqlalchemy.url ). From directories containing alembic.ini config files, run alembic history alembic current to see current version and alembic history. Note down what will be updated and check this seems reasonable. If the schema update is just adding new tables/columns (nullable or with default values) then running this migration is unlikely to break anything. However, if a column name has been changed, or if a column has been deleted then proceed with caution - this needs to be handled carefully and may require more app downtime. Finally, if tested and completely happy , run: alembic upgrade head Other steps Log onto api server as flaskuser (can run sudo su flaskuser as centos). Change directory to portal release directory cd ~/releases/portal . Check branch is correct in script download_portal_artifacts and run it. On gitlab, compare the master branch (if you are releasing the master branch) of satsense-portal to the most recent release tag. Check if the following have been updated: config.ini requirements/production.txt If fields have been added to config.ini, then you will need to add the same fields to /var/www/new-portal/app_home/config.ini . If fields have been deleted, then you can also delete them from the app config file, but it might be safer to do this once the code has been released. The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps - which might be best out of hours. This can be done via sudo systemctl stop newportal which needs to be run as the centos user. The rest of these instructions assume you are logged on as flaskuser . Activate the application virtual environment source /var/www/new-portal/virtual_environments/venv/bin/activate . Change directory to the portal artifact directory created in step 3. Uninstall satdom/satportal in the virtual environment pip uninstall satdom satportal . If requirements/production.txt had been updated (see step 4), then install the new dependencies pip install -r dist/satportal/requirements/production.txt . Reinstall satdom/satsense-portal into the venv: commandline pip install dist/satdom/satdom-*.whl pip install dist/satportal/satportal-*.whl Replace static files in public static cd /var/www/new-portal/public/static rm -rv * cp -rv ~/releases/pathtothisrelease/dist/satportal/static/* /var/www/new-portal/public/static edit index.js vi /var/www/new-portal/public/static/js/index.js and change the tiles url to the correct setting (usually the domain of the portal with the route \"tiles\", e.g. https://satshop.satsense.com/tiles ) Bring the site back up, as centos, run sudo systemctl start newportal and check the site works as expected. Troubleshooting Problem Actions Web site isn't responding. For example https://satshop.satsense.com doesn't respond. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check flask errors Web site reports \"Server Unavailable\" Check gunicorn systemd process is running Web site responds, but logging in does not work Check flask errors Restart flask application Actions Check Api server is running Check you can ssh into the api server. If not, contact unipart for further help. Check a record Log into cloudflare and check the A record for the domain that you're trying to access. Check flask errors The flask error logs are in the app log directories (locations detailed in the Live Server Locations section). Check httpd errors The httpd error logs are file called are in the app log directories (locations detailed in the Live Server Locations section). Check gunicorn systemd process is running systemctl status newportal If process is reported as stopped. Then run sudo systemctl start newportal Restart flask application Restart the application by stopping and starting: sudo systemctl stop newportal sudo systemctl start newportal","title":"Portal/SatShop (satportal)"},{"location":"client-facing-applications/portal/#portalsatshop-satportal","text":"This is a web GIS application consisting of two major features: allows a user to browse SatSense data that is streamed from the server; allows a user to order and download SatSense data extracted from the server. Historically, we have named the project the \"portal\", but with the addition of the ordering feature we rebranded the site to \"satshop\". This documentation may refer to the project by either name. We also have a demo portal, but because that is still using a legacy php version of the code, we separate documentation for the demo portal to here . Instructions for how to install an instance of the portal/satshop into a virtual environment are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with how to set up apache to forward on requests.","title":"Portal/SatShop (satportal)"},{"location":"client-facing-applications/portal/#contents","text":"Live Server Locations - where files related to the portal are kept on the live server. First Release - how to release a brand new portal. Release Update - how to release an update to a portal that's already been released. Troubleshooting - something not working? No problem.","title":"Contents"},{"location":"client-facing-applications/portal/#live-server-locations","text":"On the live server, we run several portals, this is so that we can test new datasets/provide other data sets/test new versions without affecting the live site. This is a list of the portals that are running, along with locations of related important files: Portal instance name Domain end point Project directory Httpd config file Systemd file satshop satshop.satsense.com /var/www/satshop /etc/httpd/sites-available/satshop.conf /etc/systemd/system/satshop.service staging portal.staging.satsense.com /var/www/flask-portal-staging /etc/httpd/sites-available/flask-portal-staging.conf /etc/systemd/system/portalstaging.service portal2 portal2.satsense.com /var/www/flask-portal2 /etc/httpd/sites-available/flask-portal2.conf /etc/systemd/system/portal2.service portal3 portal3.satsense.com /var/www/portal3 /etc/httpd/sites-available/portal3.conf /etc/systemd/system/portal3.service The httpd config files are shared with the tileserver httpd files because they are provided by the same domain.","title":"Live Server Locations"},{"location":"client-facing-applications/portal/#project-directory-structure","text":"The structure of each \"Project directory\" is as follows: - app_home - log - flask - public - error - static - virtual_environments The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the application, namely app.py and config.ini (see project root ). The directory public contains static assets that are not served by the flask application - the apache server serves them directly. The directory public/error houses static error files; when releasing, it is common to bring the flask server down, at which point apache will return the 503 error document in this directory. The public/static folder provides static assets needed for the website (e.g. js, css, images etc), these assets are build from the project src folder during a gitlab build. The log directory contains logs for the application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the subdirectory log/flask .","title":"Project directory structure"},{"location":"client-facing-applications/portal/#first-release","text":"These are instructions if you need to release a new portal. The reader will also need to set up any ssl certificates and A records. See the web miscellaneous docs for more detail. If you need to release an update, please see the Release Update section. We comment that you may also want to release a new tileserver as well. We assume user/InSAR databases are set up already.","title":"First Release"},{"location":"client-facing-applications/portal/#set-up-project-directory","text":"In the following, we use a location of a \"new-portal\". The reader should change the folder paths for the application they are setting up. If this is the first flask application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the Project directory structure section: sudo mkdir /var/www/new-portal/ cd /var/www/new-portal/ sudo mkdir public/ sudo chown flaskuser:apache public/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ Notice that flaskuser is the owner of all the directories, but that apache needs access to the public and logs directories. The former is so that the apache server can serve files from this directory without having to give send a proxy request to the flask application. The latter is so the apache server can write logs to this directory. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/new-portal/log(/.*)?\" sudo restorecon -R -v log/ The directories are now set up ready to be populated.","title":"Set up project directory"},{"location":"client-facing-applications/portal/#populate-project-directories","text":"We will need to: Download artifacts from the build stage of a satportal gitlab pipeline . Populate the app_home directory. Create a 503 document in public/error . Populate public/static with the static assets. Create a virtual environment for the application and install the project. We run through each of these steps in succession. Unless otherwise stated, we will assume that the following statements will be run as flaskuser .","title":"Populate project directories"},{"location":"client-facing-applications/portal/#1-download-satportal-artifacts","text":"We keep a shell script on the live server that downloads the artifacts automatically for us. This is kept in the file: /home/flaskuser/releases/portal/download_portal_artifacts We keep a copy here as well: #!/bin/bash TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") CURL_OUTFILE=\"satportal_artifacts_$TIMESTAMP.zip\" SATPORTAL_BRANCH=\"master\" HTTP_CODE=$(curl --write-out \"%{http_code}\" --location --output $CURL_OUTFILE --header \"PRIVATE-TOKEN: <gitlab ro access token>\" \"https://gitlab.com/api/v4/projects/16331419/jobs/artifacts/$SATPORTAL_BRANCH/download?job=create_artifacts\") NEW_DIR=\"satportal_$TIMESTAMP\" mkdir $NEW_DIR unzip $CURL_OUTFILE -d $NEW_DIR rm $CURL_OUTFILE printf \"Response code: $HTTP_CODE\\nOut Dir: $NEW_DIR\\n\" Note that if you use the code above, you should create a gitlab access token (preferably read only) and replace <gitlab ro access token> with it. However, the file on the server has an access token pre-filled. Further, if you need to release a branch other than master , then you can change the SATPORTAL_BRANCH variable. For example, at the time of writing (but this is always subject to change), we release a separate branch to \"portal3\" (whose branch is also called portal3 ). By convention, we run the download_portal_artifacts file from inside its directory, i.e. cd /home/flaskuser/releases/portal ./download_portal_artifacts and this will create a timestamped directory of the needed artifacts for a satportal release.","title":"1. Download satportal artifacts"},{"location":"client-facing-applications/portal/#2-populate-app_home","text":"We assume that the current directory is the timestamped directory created in the first section cp dist/satportal/app.py /var/www/new-portal/app_home cp dist/satportal/config.ini /var/www/new-portal/app_home Here, app.py is the entry point for the application and config.ini is a config file. The latter needs to be edited with config settings for the application (e.g. database strings, live api keys etc).","title":"2. Populate app_home"},{"location":"client-facing-applications/portal/#3-create-a-503-document","text":"Create the required error folder: mkdir /var/www/new-portal/public/error And copy the 503 document from the portal artifacts (we assume the current directory is the directory created in the first section ): cp dist/satportal/error/* /var/www/new-portal/public/error","title":"3. Create a 503 document"},{"location":"client-facing-applications/portal/#4-populate-publicstatic","text":"Create the required static folder: mkdir /var/www/new-portal/public/static And copy the static assets from the project assets (we assume the current directory is the directory created in the first section ): cp -r dist/satportal/static/* /var/www/new-portal/public/static There is one caveat. There is a js config and the value of which almost certainly needs changing (unless releasing to portal-staging). Because the js code is transpiled and minified, it is not obvious where to make this change. Open the file (exact name not known before artifact download, hence the wildcard) vi /var/www/new-portal/public/static/js/index-*.js And then search for the string that needs changing (press \"/\" and type part of the string that needs changing (e.g. \"https\") and press return). Edit the string and exit vi.","title":"4. Populate public/static"},{"location":"client-facing-applications/portal/#5-create-a-virtual-environment","text":"Compare the following instructions with the instructions from the project README . Initialise and activate a virtual environment: cd /var/www/new-portal/virtual_environments python3.7 -m venv venv source venv/bin/activate Then change your current directory back to the timestamped directory created in the first section . Install the requirements: pip install \"$(cat dist/satportal/requirements/production.txt | grep numpy)\" pip install GDAL==$(gdal-config --version | awk -F'[.]' '{print $1\".\"$2}') --global-option=build_ext --global-option=\"-I/usr/include/gdal\" pip install -r dist/satportal/requirements/production.txt Then install satdom and satportal wheels (the exact file names are indeterminable before downloading the artifacts - hence the wildcards): pip install dist/satdom/satdom-*.whl pip install dist/satportal/satportal-*.whl Deactivate the virtual environment deactivate","title":"5. Create a virtual environment"},{"location":"client-facing-applications/portal/#systemd-and-gunicorn-set-up","text":"Once we've set up the project directories/virtual environment as above, we need something to actually run the application. This is done via systemd and gunicorn. We assume the reader has followed the above instructions. Gunicorn is easy to install via pip. As flaskuser then run: source /var/www/new-portal/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the site is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/new-portal/app_home and replace <port> with a port number. We'd like the above process to be run automatically, which is done by using systemd . To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: sudo touch /etc/systemd/system/newportal.service sudo chmod 664 /etc/systemd/system/newportal.service Then populate the file, with something similar to following (we've assumed a port of \"5000\", but be warned this port is already used on the live server): [Unit] Description = NewPortal After = network.target [Service] User=flaskuser WorkingDirectory=/var/www/new-portal/app_home ExecStart=/var/www/new-portal/virtual_environments/venv/bin/gunicorn -b localhost:5000 -w 4 app:app Restart=always [Install] WantedBy = multi-user.target For systemd to recognise the new file, you will need to run systemctl daemon-reload and you can check it has been found using systemctl list-unit-files The service can be started via: systemctl start newportal We note that the service is named newportal due to the name of the systemd file we created. The service can be stopped via: systemctl stop newportal To allow the service to start on server reboot, it needs to be enabled: systemctl enable newportal","title":"Systemd and gunicorn set up"},{"location":"client-facing-applications/portal/#apache-set-up","text":"Once the portal application is running using systemd. We need to let the web server (currently apache) know to proxy requests to this service. To do this we create a virtual host. For further information about virtual hosts, see the apache httpd set up . Here is an example virtual host for the new portal: <VirtualHost *:80> ServerName newportal.satsense.com ServerAlias newportal.satsense.com DocumentRoot /var/www/new-portal/public # rewrite to https RewriteEngine on RewriteCond %{SERVER_NAME} =newportal.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName newportal.satsense.com ServerAlias newportal.satsense.com DocumentRoot /var/www/new-portal/public # flask proxy ProxyPass /static ! ProxyPass /error ! ProxyPass /tiles ! ProxyPass / http://localhost:5000/ ProxyPassReverse / http://localhost:5000/ # logs ErrorLog /var/www/newportal/log/error.log CustomLog /var/www/newportal/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=31536000; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html # wsgi WSGIScriptAlias /tiles /var/www/tileserver-new-ts/Tileserver/tileserver.wsgi WSGIDaemonProcess tileserver_new_ts python-home=/var/www/venvs/tileserver-new-ts processes=4 threads=1 WSGIProcessGroup tileserver_new_ts # ssl SSLCertificateFile /etc/letsencrypt/live/newportal.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/newportal.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/newportal.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to newportal.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to newportal.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://newportal.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5000 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /static ! ) mean that requests following this pattern should not be proxied (e.g. https://newportal.satsense.com/static/resource.js ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The wsgi section sets up the tileserver. Requests to https://newportal.satsense.com/tiles are forwarded to the tileserver. See the page about the tileserver . The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release .","title":"Apache set up"},{"location":"client-facing-applications/portal/#release-update","text":"This section deals with releasing an update to a portal that is already live. See the previous section for a first release of a new portal. A lot of the steps in this section are similar to first release section - with this in mind, this section lacks the verbosity of the new release section.","title":"Release Update"},{"location":"client-facing-applications/portal/#check-and-apply-database-migrations","text":"For more information about alembic (the tool we use for database migrations), see the satdom README . At time of writing the live server has a satsense_domain repository at /home/centos/Projects/alembic/satsense-domain which houses a virtual environment called venv_alembic . The satsense_domain is installed as editable dependency inside venv_alembic . We use this project to run the alembic migrations. Make sure the project is up to date and activate the environment. Change alembic config files (specifically sqlalchemy.url ). From directories containing alembic.ini config files, run alembic history alembic current to see current version and alembic history. Note down what will be updated and check this seems reasonable. If the schema update is just adding new tables/columns (nullable or with default values) then running this migration is unlikely to break anything. However, if a column name has been changed, or if a column has been deleted then proceed with caution - this needs to be handled carefully and may require more app downtime. Finally, if tested and completely happy , run: alembic upgrade head","title":"Check and apply database migrations"},{"location":"client-facing-applications/portal/#other-steps","text":"Log onto api server as flaskuser (can run sudo su flaskuser as centos). Change directory to portal release directory cd ~/releases/portal . Check branch is correct in script download_portal_artifacts and run it. On gitlab, compare the master branch (if you are releasing the master branch) of satsense-portal to the most recent release tag. Check if the following have been updated: config.ini requirements/production.txt If fields have been added to config.ini, then you will need to add the same fields to /var/www/new-portal/app_home/config.ini . If fields have been deleted, then you can also delete them from the app config file, but it might be safer to do this once the code has been released. The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps - which might be best out of hours. This can be done via sudo systemctl stop newportal which needs to be run as the centos user. The rest of these instructions assume you are logged on as flaskuser . Activate the application virtual environment source /var/www/new-portal/virtual_environments/venv/bin/activate . Change directory to the portal artifact directory created in step 3. Uninstall satdom/satportal in the virtual environment pip uninstall satdom satportal . If requirements/production.txt had been updated (see step 4), then install the new dependencies pip install -r dist/satportal/requirements/production.txt . Reinstall satdom/satsense-portal into the venv: commandline pip install dist/satdom/satdom-*.whl pip install dist/satportal/satportal-*.whl Replace static files in public static cd /var/www/new-portal/public/static rm -rv * cp -rv ~/releases/pathtothisrelease/dist/satportal/static/* /var/www/new-portal/public/static edit index.js vi /var/www/new-portal/public/static/js/index.js and change the tiles url to the correct setting (usually the domain of the portal with the route \"tiles\", e.g. https://satshop.satsense.com/tiles ) Bring the site back up, as centos, run sudo systemctl start newportal and check the site works as expected.","title":"Other steps"},{"location":"client-facing-applications/portal/#troubleshooting","text":"Problem Actions Web site isn't responding. For example https://satshop.satsense.com doesn't respond. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check flask errors Web site reports \"Server Unavailable\" Check gunicorn systemd process is running Web site responds, but logging in does not work Check flask errors Restart flask application","title":"Troubleshooting"},{"location":"client-facing-applications/portal/#actions","text":"","title":"Actions"},{"location":"client-facing-applications/portal/#check-api-server-is-running","text":"Check you can ssh into the api server. If not, contact unipart for further help.","title":"Check Api server is running"},{"location":"client-facing-applications/portal/#check-a-record","text":"Log into cloudflare and check the A record for the domain that you're trying to access.","title":"Check a record"},{"location":"client-facing-applications/portal/#check-flask-errors","text":"The flask error logs are in the app log directories (locations detailed in the Live Server Locations section).","title":"Check flask errors"},{"location":"client-facing-applications/portal/#check-httpd-errors","text":"The httpd error logs are file called are in the app log directories (locations detailed in the Live Server Locations section).","title":"Check httpd errors"},{"location":"client-facing-applications/portal/#check-gunicorn-systemd-process-is-running","text":"systemctl status newportal If process is reported as stopped. Then run sudo systemctl start newportal","title":"Check gunicorn systemd process is running"},{"location":"client-facing-applications/portal/#restart-flask-application","text":"Restart the application by stopping and starting: sudo systemctl stop newportal sudo systemctl start newportal","title":"Restart flask application"},{"location":"client-facing-applications/satdes/","text":"Satdes (Data Extraction Service) This is a few scripts that are used to make extract data from an InSAR database. Instructions for how to install an instance of satdes are kept in the project README . What that README does not make explicit is where we typically run these scripts on unipart servers. We detail that in this documentation. We also have documentation for users of satdes. Part of this is held the help pages when one runs satdes --help . We also have a useful document here . Contents Unipart Server Set Up - where files related to the satdes scripts are kept on the unipart instances. Enable Another User Access to Satdes Unipart Server Set Up The \"live\" instance of the satdes scripts should be run whilst logged into the api server. This instance of satdes is set up inside a virtual environment which is held: /rust2/workspace/satdes/venv We note the satdes and its dependency satdom are installed in this environment as a non-editable dependency. To update the above venv instance: Update (i.e. git pull) satsense-domain and data-extract-service repositories located in /rust2/workspace/satdes/live . Activate the above venv source /rust2/workspace/satdes/venv/bin/activate Uninstall satdom and satdes by running pip uninstall satdom satdes . Check whether dependencies need updating, and is so, run pip install -r requirements/production.txt from root of data-extract-service repository. Reinstall new versions of satdom and data-extract-service , that is run pip install . from satsense-domain root and data-extract-service root. One can find the config.ini at /rust2/workspace/satdes/live/data-extract-service/satdes and logs for this application are held in the folder /data/logs/satdes . Enable Another User Access to Satdes As centos on the api server, create a new user sudo adduser <new username> Then log in as that user (e.g. run sudo su <new username> ) and create authorized keys: mkdir ~/.ssh chmod 700 ~/.ssh touch ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys Then add a public ssh key for that user to authorized keys. The user should be able to use their ssh to log in to the api server. Once in they can activate satdes via source /rust2/workspace/satdes/venv/bin/activate and run satdes --help to access the help page. It might then be useful for a user to have a space to extract files to. For example, historically we have set up directories for users inside /rust2/workspace/data_extract . For example you might create a new folder: mkdir /rust2/workspace/data_extract/<new username> and then set the permissions: chown <new user>:centos /rust2/workspace/data_extract/<new username>","title":"Satdes (Data Extraction Service)"},{"location":"client-facing-applications/satdes/#satdes-data-extraction-service","text":"This is a few scripts that are used to make extract data from an InSAR database. Instructions for how to install an instance of satdes are kept in the project README . What that README does not make explicit is where we typically run these scripts on unipart servers. We detail that in this documentation. We also have documentation for users of satdes. Part of this is held the help pages when one runs satdes --help . We also have a useful document here .","title":"Satdes (Data Extraction Service)"},{"location":"client-facing-applications/satdes/#contents","text":"Unipart Server Set Up - where files related to the satdes scripts are kept on the unipart instances. Enable Another User Access to Satdes","title":"Contents"},{"location":"client-facing-applications/satdes/#unipart-server-set-up","text":"The \"live\" instance of the satdes scripts should be run whilst logged into the api server. This instance of satdes is set up inside a virtual environment which is held: /rust2/workspace/satdes/venv We note the satdes and its dependency satdom are installed in this environment as a non-editable dependency. To update the above venv instance: Update (i.e. git pull) satsense-domain and data-extract-service repositories located in /rust2/workspace/satdes/live . Activate the above venv source /rust2/workspace/satdes/venv/bin/activate Uninstall satdom and satdes by running pip uninstall satdom satdes . Check whether dependencies need updating, and is so, run pip install -r requirements/production.txt from root of data-extract-service repository. Reinstall new versions of satdom and data-extract-service , that is run pip install . from satsense-domain root and data-extract-service root. One can find the config.ini at /rust2/workspace/satdes/live/data-extract-service/satdes and logs for this application are held in the folder /data/logs/satdes .","title":"Unipart Server Set Up"},{"location":"client-facing-applications/satdes/#enable-another-user-access-to-satdes","text":"As centos on the api server, create a new user sudo adduser <new username> Then log in as that user (e.g. run sudo su <new username> ) and create authorized keys: mkdir ~/.ssh chmod 700 ~/.ssh touch ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys Then add a public ssh key for that user to authorized keys. The user should be able to use their ssh to log in to the api server. Once in they can activate satdes via source /rust2/workspace/satdes/venv/bin/activate and run satdes --help to access the help page. It might then be useful for a user to have a space to extract files to. For example, historically we have set up directories for users inside /rust2/workspace/data_extract . For example you might create a new folder: mkdir /rust2/workspace/data_extract/<new username> and then set the permissions: chown <new user>:centos /rust2/workspace/data_extract/<new username>","title":"Enable Another User Access to Satdes"},{"location":"client-facing-applications/satdom-scripts/","text":"Satdom Scripts This is a few scripts that are used to make assets for other applications. The scripts produce derived data from an InSAR database or geotiffs. Instructions for how to install an instance of satdom are kept in the project README . What that README does not make explicit is where we typically run these scripts on unipart servers. We detail that in this documentation. Contents Unipart Server Set Up - where files related to the satdom scripts are kept on the unipart instances. Overview of each script - what each script does and where the output is used. Unipart Server Set Up The \"live\" instance of the satdom scripts is run from the unipart vm machines (vm3 and vm4). This instance of satdom is set up on the unipart servers inside a conda environment called satdom_scripts . The editable repositories that this environment points to are kept in the following directories: /data/Software/satsense-domain Note that this is shared with the satpgi setup , so updating this instance needs to be in tandem with updating satpgi (this can be changed if it proves a pain - just set up a new instance). Running live instance We typically run the ingester as the centos user (try running sudo su centos if not logged in as centos ). Herein we assume that we're logged into either vm as centos . We usually maintain a screen running on each vm called satdom_scripts . To see if such a screen exists, run screen -ls and it should be listed. If it is running, then you can connect to the screen using screen -r satdom_scripts . If it isn't running then you can create a new screen via screen -S satdom_scripts . Make sure the satdom_scripts conda environment is activated using conda activate satdom_scripts . It is then best to run satdom_scripts from the /data/Software/satsense_domain/scripts . You can see the help page of each script using: python <script file.py> --help Don't forget to update config.ini with any values on databases you need. Updating live instance It's probably best if you don't do this step if there are any running commands. Check for any screens called something like satdom_scripts and satpgi (since satpgi uses this instance of satdom . Otherwise, it's just a matter of git pulling the latest repositories in: /data/Software/satsense-domain Overview of each script At the time of writing we have the following scripts: generate_tiles.py generate_srisks_tifs.py filter_geotiff.py generate_tiles.py This produces the overview tiles for the tileserver. When the portal gets to zoom level 14 or below there too many points to render. To solve this, we take an average of the points inside a square region (which we refer to as a tile) and store those inside a geotiff. The script generates these tiles, it will create a geotiff of extent as per \"bng_extent\" in config.ini (which can be altered). The resolutions as committed in the project are a good suggestion to use, but could be changed if the data changes. The script generates the finest (smallest number - which refers to the distance in meters between each cell in the geotiff) resolution first using a cartesian coordinate system e.g. BNG. It then uses gdal scripts to generate the other resolutions. Finally, a gdal warp method is used to reproject the geotiffs into wgs 84 (epsg 4326) - the portal/tileserver expects to use spatial data in this projection. generate_srisk_tifs.py This produces big srisk geotiffs, see here for more information about srisks. These are currently used to cache data for the api because the calculation took too long for bigger query areas. There are a couple of non-trivial options for this script: --include-temporal-srisks - this was added in for historical reasons. Temporal srisks refer to srisks generated from the time series of the data (i.e. sriska, sriskr). Initially, we attempted to only cache the spatial srisks (the non-temporal srisks i.e. sriskabs, srisk100, sriskp, sriskg). By offering this option, we allow the user to generate of only spatial srisks by default (but also give them the option of creating everything). --store-in-single-geotiff - after a while, we needed to improve the speed of the api and we realised that we could do this by also caching the temporal srisks. However, we realised that this would mean opening six files. To improve on this, we just create one file and store the srisks as separate bands. For the sake of clarity, the cached data that the api uses expects one to use both of above flags when extracting the srisks. filter_geotiff.py This script will take in a geotiff and output another geotiff which is a spatially filtered (like sriskabs) version of the input geotiff. Groundsure provide a map layer of satsense data in their reports. This layer is a velocity geotiff that is filtered using a spatial filter of 100m. To generate this geotiff for groundsure, you may take the 10m resolution BNG-projected geotiff of the output of generate_tiles.py and run it through this script with a filter of 100m.","title":"Satdom Scripts"},{"location":"client-facing-applications/satdom-scripts/#satdom-scripts","text":"This is a few scripts that are used to make assets for other applications. The scripts produce derived data from an InSAR database or geotiffs. Instructions for how to install an instance of satdom are kept in the project README . What that README does not make explicit is where we typically run these scripts on unipart servers. We detail that in this documentation.","title":"Satdom Scripts"},{"location":"client-facing-applications/satdom-scripts/#contents","text":"Unipart Server Set Up - where files related to the satdom scripts are kept on the unipart instances. Overview of each script - what each script does and where the output is used.","title":"Contents"},{"location":"client-facing-applications/satdom-scripts/#unipart-server-set-up","text":"The \"live\" instance of the satdom scripts is run from the unipart vm machines (vm3 and vm4). This instance of satdom is set up on the unipart servers inside a conda environment called satdom_scripts . The editable repositories that this environment points to are kept in the following directories: /data/Software/satsense-domain Note that this is shared with the satpgi setup , so updating this instance needs to be in tandem with updating satpgi (this can be changed if it proves a pain - just set up a new instance).","title":"Unipart Server Set Up"},{"location":"client-facing-applications/satdom-scripts/#running-live-instance","text":"We typically run the ingester as the centos user (try running sudo su centos if not logged in as centos ). Herein we assume that we're logged into either vm as centos . We usually maintain a screen running on each vm called satdom_scripts . To see if such a screen exists, run screen -ls and it should be listed. If it is running, then you can connect to the screen using screen -r satdom_scripts . If it isn't running then you can create a new screen via screen -S satdom_scripts . Make sure the satdom_scripts conda environment is activated using conda activate satdom_scripts . It is then best to run satdom_scripts from the /data/Software/satsense_domain/scripts . You can see the help page of each script using: python <script file.py> --help Don't forget to update config.ini with any values on databases you need.","title":"Running live instance"},{"location":"client-facing-applications/satdom-scripts/#updating-live-instance","text":"It's probably best if you don't do this step if there are any running commands. Check for any screens called something like satdom_scripts and satpgi (since satpgi uses this instance of satdom . Otherwise, it's just a matter of git pulling the latest repositories in: /data/Software/satsense-domain","title":"Updating live instance"},{"location":"client-facing-applications/satdom-scripts/#overview-of-each-script","text":"At the time of writing we have the following scripts: generate_tiles.py generate_srisks_tifs.py filter_geotiff.py","title":"Overview of each script"},{"location":"client-facing-applications/satdom-scripts/#generate_tilespy","text":"This produces the overview tiles for the tileserver. When the portal gets to zoom level 14 or below there too many points to render. To solve this, we take an average of the points inside a square region (which we refer to as a tile) and store those inside a geotiff. The script generates these tiles, it will create a geotiff of extent as per \"bng_extent\" in config.ini (which can be altered). The resolutions as committed in the project are a good suggestion to use, but could be changed if the data changes. The script generates the finest (smallest number - which refers to the distance in meters between each cell in the geotiff) resolution first using a cartesian coordinate system e.g. BNG. It then uses gdal scripts to generate the other resolutions. Finally, a gdal warp method is used to reproject the geotiffs into wgs 84 (epsg 4326) - the portal/tileserver expects to use spatial data in this projection.","title":"generate_tiles.py"},{"location":"client-facing-applications/satdom-scripts/#generate_srisk_tifspy","text":"This produces big srisk geotiffs, see here for more information about srisks. These are currently used to cache data for the api because the calculation took too long for bigger query areas. There are a couple of non-trivial options for this script: --include-temporal-srisks - this was added in for historical reasons. Temporal srisks refer to srisks generated from the time series of the data (i.e. sriska, sriskr). Initially, we attempted to only cache the spatial srisks (the non-temporal srisks i.e. sriskabs, srisk100, sriskp, sriskg). By offering this option, we allow the user to generate of only spatial srisks by default (but also give them the option of creating everything). --store-in-single-geotiff - after a while, we needed to improve the speed of the api and we realised that we could do this by also caching the temporal srisks. However, we realised that this would mean opening six files. To improve on this, we just create one file and store the srisks as separate bands. For the sake of clarity, the cached data that the api uses expects one to use both of above flags when extracting the srisks.","title":"generate_srisk_tifs.py"},{"location":"client-facing-applications/satdom-scripts/#filter_geotiffpy","text":"This script will take in a geotiff and output another geotiff which is a spatially filtered (like sriskabs) version of the input geotiff. Groundsure provide a map layer of satsense data in their reports. This layer is a velocity geotiff that is filtered using a spatial filter of 100m. To generate this geotiff for groundsure, you may take the 10m resolution BNG-projected geotiff of the output of generate_tiles.py and run it through this script with a filter of 100m.","title":"filter_geotiff.py"},{"location":"client-facing-applications/satpgi/","text":"Postgres Ingester (satpgi) The satsense postgresql ingester (aka PostgresIngester, satpgi) is a set of scripts that takes a set of hdf5 files (typically called \"velocity\" and \"data\" files) and inserts them into a postgresql database. Instructions for how to set up satpgi are kept in the project README . What that README does not make explicit is where everything is installed on the unipart instances. We detail that in this documentation, along with brief instructions with what to run to keep the database up to date. Contents Unipart Server Set Up - where files related to satpgi are kept on the unipart instances. Overview of commands - what commands to run and when. Unipart Server Set Up The \"live\" instance of the satpgi is run from the unipart vm machines (vm3 and vm4). This instance of satpgi is set up on the unipart servers inside a conda environment called satpgi . The editable repositories that this environment points to are kept in the following directories: /data/Software/satsense-domain /data/Software/postgresingester Running live instance We typically run the ingester as the centos user (try running sudo su centos if not logged in as centos ). Herein we assume that we're logged into either vm as centos . We usually maintain a screen running on each vm called satpgi . To see if such a screen exists, run screen -ls and it should be listed. If it is running, then you can connect to the screen using screen -r satpgi . If it isn't running then you can create a new screen via screen -S satpgi . Make sure the satpgi conda environment is activated using conda activate satpgi . It is then best to run satpgi from the /data/Software/postgresingester/ingester , and you can access the help page using: python main.py --help Don't forget to update config.ini with any values. Do check the following: db_name - the database name (very important) db_username db_password include_frame_boundary - this should be True , but the data might not be available if it is not sentinel data (e.g. India or csk data). This will insert a polygon representing the boundary of the frame, these are contained in a file called ingester/UK_frame_coords_ASF.txt . Polygon boundary file name can be changed in config, see asf_frame_coords_name in ingester/config.ini . Updating live instance It's probably best if you don't do this step if there are any running commands. Check for any screens called something like satpgi . Otherwise, it's just a matter of git pulling the latest repositories in: /data/Software/satsense-domain /data/Software/postgresingester Logs Logs are contained in the directoy /data/Software/logs (although the reader could have checked config.ini to find that out). We generally only run one instance per vm, and we append the vm name onto the log file to keep these log files distinct. Other instances of satpgi on unipart machines There is another conda environment called test_satpgi , this should only be used on vm4. The corresponding installed editable repositories are contained at: /home/centos/satsense-domain /home/centos/postgresingester on vm4. This instance is useful for testing new datasets or ingesting into different databases. Overview of commands At the time of writing, printing the help page for satpgi will yield information about the following commands: insert-csv Insert HDF5 files using metadata stored in a csv file. This is particularly useful for setting up more than one file for ingestion at once. See example_input.csv. initial-insert Insert using flags. This is limited to only ingesting one HDF5 at a time, but may be more useful for automation. reingest-points-for-frame Reingest the points for frame. This will read the dates that are currently in the database and only ingest those dates. Points not in the database will be inserted, points that shouldn't be in the database will be deleted, and all points that are already in the database will be fully updated. insert-dates Update points in the db with dates that aren't in the database already. delete-dates-in-frame Remove dates in the time series for points within frame. update-dates Update dates in the db that already have a placeholder in the database. Option to start from specific batch. Useful if an 'insert-dates' script had to be paused. update-fields Update fields on points. There must be exactly one of this type of data per point (for example, velocities and not displacements) delete-frame Delete both high resolution and rural points from the db for a given frame. delete-point-ids Delete points in database with ids defined in a csv file. Whilst these are documented, we add some more context about these commands i.e. some of the circumstances behind why we might use each command. Roughly these are split up into the categories Inserting a new frame Updating data spatially - adding, updating or removing points. Updating data temporally - updating the time series for points. Updating fields - updating any data on points that isn't the time series. Inserting a new frame Imagine you have an empty database, or a brand-new processing frame to play with - these scripts are what you want. We initially wrote the command initial-insert , but this can be laborious if we want to run loads of insertion scripts in a row. To solve this problem, we wrote insert-csv . In most cases, these two commands are essentially equivalent. initial-insert former offers slightly more options, for example, the ability to filter by extent upon ingestion - this might useful for ingesting into a demo portal database. These commands are handle points in batches and should be fine to run at any point without too much other load on the database (i.e. not too many satpgi scripts at once). Updating data spatially If a frame has a number of suspicious points, then we allow a few mechanisms to handle this: delete-frame - nuclear option, it will delete all points for a frame. This probably shouldn't be run. delete-point-ids - Whilst it is easy to run a sql statement to delete point ids, historically it has been preferred to run scripts that are tested. This takes in a csv of ids and will delete points in the database with those ids. reingest-points-for-frame - the outcome of this is equivalent to running delete-frame and then initial-insert except there is never a point where the database doesn't contain points for the frame. It ensures a clear reingest if the Reliable Pixels dataset in the velocity file has been updated. Done in batches and should be fine to run at any point without too much other load on the database. Updating data temporally For frames whose time series has been updated in hdf5 files. For instance, if there is a new (or set of new) date(s) in the time series then you would run insert-dates . If you find some processing error for one date in a frame then you would run: update-dates if the error has been fixed in the hdf5 files and you need to get this data into the database. delete-dates-in-frame if the error has not been fixed in the hdf5 files - perhaps it will take some time to figure out the issue. The script update-dates handles points in batches and should be fine to run at any point without too much other load on the database. The script delete-dates-in-frame is quite write intensive - it has to rewrite every time series for every point in one transaction (although that transaction is long-lived). Best to start this in the evening or weekend. Wouldn't have more than one of this kind of script running at once. The script insert-dates is the most commonly used script. It consists of two parts: Adding NaNs as placeholders in every points time series Updating those points with real values The first part is so to ensure that the database is always in a consistent state. It is quite write intensive, and best to start in the evening or weekend - depending on the frame it can take a long time. The second part is handled in batches so should be fine to run alongside other scripts. Indeed, once this script has started its second phase, then another instance of this script can be run. Updating fields on points There is a generic script called update-fields . This script can handle updating fields that are represented by a single (non-array like) column in the database. A full list of the possible fields to update is given in the help page for this script (i.e. run python main.py update-fields --help ). Common use cases include and update of the velocities for a frame or if a new column/field to the database has been added then this script can easily be amended to allow updating. This is handled in batches and should be fine to run at any point without too much other load on the database.","title":"Postgres Ingester (satpgi)"},{"location":"client-facing-applications/satpgi/#postgres-ingester-satpgi","text":"The satsense postgresql ingester (aka PostgresIngester, satpgi) is a set of scripts that takes a set of hdf5 files (typically called \"velocity\" and \"data\" files) and inserts them into a postgresql database. Instructions for how to set up satpgi are kept in the project README . What that README does not make explicit is where everything is installed on the unipart instances. We detail that in this documentation, along with brief instructions with what to run to keep the database up to date.","title":"Postgres Ingester (satpgi)"},{"location":"client-facing-applications/satpgi/#contents","text":"Unipart Server Set Up - where files related to satpgi are kept on the unipart instances. Overview of commands - what commands to run and when.","title":"Contents"},{"location":"client-facing-applications/satpgi/#unipart-server-set-up","text":"The \"live\" instance of the satpgi is run from the unipart vm machines (vm3 and vm4). This instance of satpgi is set up on the unipart servers inside a conda environment called satpgi . The editable repositories that this environment points to are kept in the following directories: /data/Software/satsense-domain /data/Software/postgresingester","title":"Unipart Server Set Up"},{"location":"client-facing-applications/satpgi/#running-live-instance","text":"We typically run the ingester as the centos user (try running sudo su centos if not logged in as centos ). Herein we assume that we're logged into either vm as centos . We usually maintain a screen running on each vm called satpgi . To see if such a screen exists, run screen -ls and it should be listed. If it is running, then you can connect to the screen using screen -r satpgi . If it isn't running then you can create a new screen via screen -S satpgi . Make sure the satpgi conda environment is activated using conda activate satpgi . It is then best to run satpgi from the /data/Software/postgresingester/ingester , and you can access the help page using: python main.py --help Don't forget to update config.ini with any values. Do check the following: db_name - the database name (very important) db_username db_password include_frame_boundary - this should be True , but the data might not be available if it is not sentinel data (e.g. India or csk data). This will insert a polygon representing the boundary of the frame, these are contained in a file called ingester/UK_frame_coords_ASF.txt . Polygon boundary file name can be changed in config, see asf_frame_coords_name in ingester/config.ini .","title":"Running live instance"},{"location":"client-facing-applications/satpgi/#updating-live-instance","text":"It's probably best if you don't do this step if there are any running commands. Check for any screens called something like satpgi . Otherwise, it's just a matter of git pulling the latest repositories in: /data/Software/satsense-domain /data/Software/postgresingester","title":"Updating live instance"},{"location":"client-facing-applications/satpgi/#logs","text":"Logs are contained in the directoy /data/Software/logs (although the reader could have checked config.ini to find that out). We generally only run one instance per vm, and we append the vm name onto the log file to keep these log files distinct.","title":"Logs"},{"location":"client-facing-applications/satpgi/#other-instances-of-satpgi-on-unipart-machines","text":"There is another conda environment called test_satpgi , this should only be used on vm4. The corresponding installed editable repositories are contained at: /home/centos/satsense-domain /home/centos/postgresingester on vm4. This instance is useful for testing new datasets or ingesting into different databases.","title":"Other instances of satpgi on unipart machines"},{"location":"client-facing-applications/satpgi/#overview-of-commands","text":"At the time of writing, printing the help page for satpgi will yield information about the following commands: insert-csv Insert HDF5 files using metadata stored in a csv file. This is particularly useful for setting up more than one file for ingestion at once. See example_input.csv. initial-insert Insert using flags. This is limited to only ingesting one HDF5 at a time, but may be more useful for automation. reingest-points-for-frame Reingest the points for frame. This will read the dates that are currently in the database and only ingest those dates. Points not in the database will be inserted, points that shouldn't be in the database will be deleted, and all points that are already in the database will be fully updated. insert-dates Update points in the db with dates that aren't in the database already. delete-dates-in-frame Remove dates in the time series for points within frame. update-dates Update dates in the db that already have a placeholder in the database. Option to start from specific batch. Useful if an 'insert-dates' script had to be paused. update-fields Update fields on points. There must be exactly one of this type of data per point (for example, velocities and not displacements) delete-frame Delete both high resolution and rural points from the db for a given frame. delete-point-ids Delete points in database with ids defined in a csv file. Whilst these are documented, we add some more context about these commands i.e. some of the circumstances behind why we might use each command. Roughly these are split up into the categories Inserting a new frame Updating data spatially - adding, updating or removing points. Updating data temporally - updating the time series for points. Updating fields - updating any data on points that isn't the time series.","title":"Overview of commands"},{"location":"client-facing-applications/satpgi/#inserting-a-new-frame","text":"Imagine you have an empty database, or a brand-new processing frame to play with - these scripts are what you want. We initially wrote the command initial-insert , but this can be laborious if we want to run loads of insertion scripts in a row. To solve this problem, we wrote insert-csv . In most cases, these two commands are essentially equivalent. initial-insert former offers slightly more options, for example, the ability to filter by extent upon ingestion - this might useful for ingesting into a demo portal database. These commands are handle points in batches and should be fine to run at any point without too much other load on the database (i.e. not too many satpgi scripts at once).","title":"Inserting a new frame"},{"location":"client-facing-applications/satpgi/#updating-data-spatially","text":"If a frame has a number of suspicious points, then we allow a few mechanisms to handle this: delete-frame - nuclear option, it will delete all points for a frame. This probably shouldn't be run. delete-point-ids - Whilst it is easy to run a sql statement to delete point ids, historically it has been preferred to run scripts that are tested. This takes in a csv of ids and will delete points in the database with those ids. reingest-points-for-frame - the outcome of this is equivalent to running delete-frame and then initial-insert except there is never a point where the database doesn't contain points for the frame. It ensures a clear reingest if the Reliable Pixels dataset in the velocity file has been updated. Done in batches and should be fine to run at any point without too much other load on the database.","title":"Updating data spatially"},{"location":"client-facing-applications/satpgi/#updating-data-temporally","text":"For frames whose time series has been updated in hdf5 files. For instance, if there is a new (or set of new) date(s) in the time series then you would run insert-dates . If you find some processing error for one date in a frame then you would run: update-dates if the error has been fixed in the hdf5 files and you need to get this data into the database. delete-dates-in-frame if the error has not been fixed in the hdf5 files - perhaps it will take some time to figure out the issue. The script update-dates handles points in batches and should be fine to run at any point without too much other load on the database. The script delete-dates-in-frame is quite write intensive - it has to rewrite every time series for every point in one transaction (although that transaction is long-lived). Best to start this in the evening or weekend. Wouldn't have more than one of this kind of script running at once. The script insert-dates is the most commonly used script. It consists of two parts: Adding NaNs as placeholders in every points time series Updating those points with real values The first part is so to ensure that the database is always in a consistent state. It is quite write intensive, and best to start in the evening or weekend - depending on the frame it can take a long time. The second part is handled in batches so should be fine to run alongside other scripts. Indeed, once this script has started its second phase, then another instance of this script can be run.","title":"Updating data temporally"},{"location":"client-facing-applications/satpgi/#updating-fields-on-points","text":"There is a generic script called update-fields . This script can handle updating fields that are represented by a single (non-array like) column in the database. A full list of the possible fields to update is given in the help page for this script (i.e. run python main.py update-fields --help ). Common use cases include and update of the velocities for a frame or if a new column/field to the database has been added then this script can easily be amended to allow updating. This is handled in batches and should be fine to run at any point without too much other load on the database.","title":"Updating fields on points"},{"location":"client-facing-applications/tileserver-qgis-fiddle/","text":"Integrating Tileservers into QGIS (fiddle) Whilst the portal is a useful tool, it doesn't currently match the feature-rich environment that QGIS provides. Here, we detail how to integrate the satsense tileservers into QGIS. These instructions were written for QGIS 3.4, but they should be transferable to other versions. The idea is to add a new \"XYZ Tiles\" connection to QGIS, and this connection will contain details of the tileserver that the portal plugs into. We first give a general overview of how to add a new \"XYZ Tiles\" connection and then this will motivate the parameters we need to find from the portal. Adding a new \"XYZ Tiles\" connection into QGIS Make sure the \"Browser\" panel is open, if not you can open by clicking \"View\" -> \"Panels\" -> Check \"Browser\". In the \"Browser\" panel, right click \"XYZ Tiles\" and click \"New Connection\", as seen here: This will open a window much like the following: In the above image: The \"Name\" can be anything you want (although I would recommend making it descriptive); The \"URL\" is the url of the tileserver. We will discuss the URL for the satsense tileservers in the next session . Sometimes tileservers have some authentication to prevent unauthorised access and that can be set up in the \"Authentication\" section. However, for the satsense tileservers, we can safely ignore this section - panic not, the tileserver is protected by api keys contained in the url (as you shall see). Hopefully the \"Min/Max Zoom levels\" are fairly self-evident. The portal uses a Min Zoom level of 0 and a Max Zoom level of 19. Finding the url for a satsense tileserver For the tileserver that provides tiles for the site https://satshop.satsense.com , tileserver urls are: # For ascending data https://satshop.satsense.com/tiles/hr_asc_vels/{z}/{x}/{y}.png?access_token=ThisIsAnAccessToken&scale_min=-10&scale_max=10 # For descending data https://satshop.satsense.com/tiles/hr_desc_vels/{z}/{x}/{y}.png?access_token=ThisIsAnAccessToken&scale_min=-10&scale_max=10 However, the reader will need to find their access token (which will not be equal to the value ThisIsAnAccessToken suggested above). Currently, there is no user-friendly way to do this, but we will now go into some detail in how to obtain the access token. First, log into the satshop/portal . Your access token will now be stored in session storage . Session storage is a bit like cookie storage except that the data is never transferred to a server, and it is deleted when the browser/tab is closed. Most modern browsers allow easy access to values in their session storage. We detail how to see session storage for firefox and chrome - other browsers should provide a similar mechanism. In both of the following examples, we've redacted any sensitive values. In these examples, the reader is looking for a value starting with \"8a3e...\" and whose key is called \"apiKey\" (we acknowledge that the name \"apiKey\" is not ideal since we've been calling it an \"access token\" for some time). The reader's own access token (\"apiKey\") is unlikely to start with \"8a3e...\". Firefox Right click anywhere on the portal page that isn't interactive (e.g. a button, leaflet map etc). Click \"Inspect Element\" from the menu. The \"developer tools\" should open. The reader is looking for a tab called \"Storage\", for which they might need to press the arrows >>. Open \"Session Storage\" and click \"https://satshop.satsense.com\". The reader should see something like this: Chrome Right click anywhere on the portal page that isn't interactive (e.g. a button, leaflet map etc). Click \"Inspect\" from the menu. The \"developer tools\" should open. Click the tab \"Application\". Under the \"Storage\" section, open \"Session Storage\". Click \"https://satshop.satsense.com\" The reader should see something like this: Final Notes Once the reader has found their session token, they can replace the string \"ThisIsAnAccessToken\" with their token in the urls suggested at the start of the previous section . One of these urls (depending one whether you want ascending or descending data) then goes into \"URL\" section when adding a new connection to QGIS . If you want both ascending and descending data, you should add two connections. Once the connection has been created, the reader can add it to their project by right clicking their created connection in the \"Browser\" panel and then clicking \"Add Selected Layer(s) to Canvas\". See the following screenshot: We finish on the note that one can change the \"scale\" (in the same meaning as the colour bar in the portal), by altering the values for \"scale_min\" and \"scale_max\" in the urls.","title":"Integrating Tileservers into QGIS (fiddle)"},{"location":"client-facing-applications/tileserver-qgis-fiddle/#integrating-tileservers-into-qgis-fiddle","text":"Whilst the portal is a useful tool, it doesn't currently match the feature-rich environment that QGIS provides. Here, we detail how to integrate the satsense tileservers into QGIS. These instructions were written for QGIS 3.4, but they should be transferable to other versions. The idea is to add a new \"XYZ Tiles\" connection to QGIS, and this connection will contain details of the tileserver that the portal plugs into. We first give a general overview of how to add a new \"XYZ Tiles\" connection and then this will motivate the parameters we need to find from the portal.","title":"Integrating Tileservers into QGIS (fiddle)"},{"location":"client-facing-applications/tileserver-qgis-fiddle/#adding-a-new-xyz-tiles-connection-into-qgis","text":"Make sure the \"Browser\" panel is open, if not you can open by clicking \"View\" -> \"Panels\" -> Check \"Browser\". In the \"Browser\" panel, right click \"XYZ Tiles\" and click \"New Connection\", as seen here: This will open a window much like the following: In the above image: The \"Name\" can be anything you want (although I would recommend making it descriptive); The \"URL\" is the url of the tileserver. We will discuss the URL for the satsense tileservers in the next session . Sometimes tileservers have some authentication to prevent unauthorised access and that can be set up in the \"Authentication\" section. However, for the satsense tileservers, we can safely ignore this section - panic not, the tileserver is protected by api keys contained in the url (as you shall see). Hopefully the \"Min/Max Zoom levels\" are fairly self-evident. The portal uses a Min Zoom level of 0 and a Max Zoom level of 19.","title":"Adding a new \"XYZ Tiles\" connection into QGIS"},{"location":"client-facing-applications/tileserver-qgis-fiddle/#finding-the-url-for-a-satsense-tileserver","text":"For the tileserver that provides tiles for the site https://satshop.satsense.com , tileserver urls are: # For ascending data https://satshop.satsense.com/tiles/hr_asc_vels/{z}/{x}/{y}.png?access_token=ThisIsAnAccessToken&scale_min=-10&scale_max=10 # For descending data https://satshop.satsense.com/tiles/hr_desc_vels/{z}/{x}/{y}.png?access_token=ThisIsAnAccessToken&scale_min=-10&scale_max=10 However, the reader will need to find their access token (which will not be equal to the value ThisIsAnAccessToken suggested above). Currently, there is no user-friendly way to do this, but we will now go into some detail in how to obtain the access token. First, log into the satshop/portal . Your access token will now be stored in session storage . Session storage is a bit like cookie storage except that the data is never transferred to a server, and it is deleted when the browser/tab is closed. Most modern browsers allow easy access to values in their session storage. We detail how to see session storage for firefox and chrome - other browsers should provide a similar mechanism. In both of the following examples, we've redacted any sensitive values. In these examples, the reader is looking for a value starting with \"8a3e...\" and whose key is called \"apiKey\" (we acknowledge that the name \"apiKey\" is not ideal since we've been calling it an \"access token\" for some time). The reader's own access token (\"apiKey\") is unlikely to start with \"8a3e...\".","title":"Finding the url for a satsense tileserver"},{"location":"client-facing-applications/tileserver-qgis-fiddle/#firefox","text":"Right click anywhere on the portal page that isn't interactive (e.g. a button, leaflet map etc). Click \"Inspect Element\" from the menu. The \"developer tools\" should open. The reader is looking for a tab called \"Storage\", for which they might need to press the arrows >>. Open \"Session Storage\" and click \"https://satshop.satsense.com\". The reader should see something like this:","title":"Firefox"},{"location":"client-facing-applications/tileserver-qgis-fiddle/#chrome","text":"Right click anywhere on the portal page that isn't interactive (e.g. a button, leaflet map etc). Click \"Inspect\" from the menu. The \"developer tools\" should open. Click the tab \"Application\". Under the \"Storage\" section, open \"Session Storage\". Click \"https://satshop.satsense.com\" The reader should see something like this:","title":"Chrome"},{"location":"client-facing-applications/tileserver-qgis-fiddle/#final-notes","text":"Once the reader has found their session token, they can replace the string \"ThisIsAnAccessToken\" with their token in the urls suggested at the start of the previous section . One of these urls (depending one whether you want ascending or descending data) then goes into \"URL\" section when adding a new connection to QGIS . If you want both ascending and descending data, you should add two connections. Once the connection has been created, the reader can add it to their project by right clicking their created connection in the \"Browser\" panel and then clicking \"Add Selected Layer(s) to Canvas\". See the following screenshot: We finish on the note that one can change the \"scale\" (in the same meaning as the colour bar in the portal), by altering the values for \"scale_min\" and \"scale_max\" in the urls.","title":"Final Notes"},{"location":"client-facing-applications/tileservers/","text":"Tileservers Instructions for how to install sat-tileserver are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with some caveats when trying to run the tileserver behind apache. Contents Live Server Locations - where files related to the tileservers are kept on the live server. First Release - how to release a brand new tileserver. Release Update - how to release an update to tileserver that's already been released. Troubleshooting - something not working? No problem. Live Server Locations On the live server, we run several tileservers, one for each portal project. This is a list of the tile servers that are running, along with locations of related important files: Tileserver name Domain end point Httpd log directory Httpd config file tileserver-satshop satshop.satsense.com/tiles /var/www/satshop/log /etc/httpd/sites-available/satshop.conf tileserver-staging portal.staging.satsense.com/tiles /var/www/flask-portal-staging/log /etc/httpd/sites-available/flask-portal-staging.conf tileserver-demo demo.satsense.com/tiles /var/www/demo-portal-live/log /etc/httpd/sites-available/demo-portal-live.conf tileserver-demo-staging demo.staging.satsense.com/tiles /var/www/demo-portal-staging/log /etc/httpd/sites-available/demo-portal-staging.conf tileserver-portal2 portal2.satsense.com/tiles /var/www/flask-portal2/log /etc/httpd/sites-available/flask-portal2.conf tileserver-portal3 portal3.satsense.com/tiles /var/www/portal3/log /etc/httpd/sites-available/portal3.conf The httpd log directories and httpd config files are shared with the portal httpd set up because they are provided by the same domain. Other files related to the above projects are kept in the following locations on the live server: Virtual environments are in the directories /var/www/venvs/<Tileserver name> . Project code is in the directories /var/www/<Tileserver name>/Tileserver . Tile overview geotiffs are kept in the directory /data/tile_geotiffs . We don't keep an explicit log for where each tileserver's geotiffs are kept. However, one can look in the tileserver config files to see which geotiffs are being used e.g. /var/www/tileserver-satshop/Tileserver/config.ini will refer to which geotiffs are being used for tileserver-satshop . First Release These are instructions for if you need to release a new tileserver. If you need to release an update, please see the Release Update section. Set Up Code and Virtual Environment Create the venvs folder, if it doesn't exist: sudo mkdir /var/www/venvs sudo chown centos:apache /var/www/venvs Create and activate a new virtual environment for the tileserver: virtualenv /var/www/venvs/tileserver-new-ts source /var/www/venvs/tileserver-new-ts/bin/activate Make sure mapnik is installed, see the project README . Create a new directory for the tileserver project, and checkout the project inside that directory: sudo mkdir /var/www/tileserver-new-ts sudo chown centos:apache /var/www/tileserver-new-ts git clone https://gitlab.com/SatSenseLtd/sat-tileserver.git /var/www/tileserver-new-ts/Tileserver Then install the project into the virtual environment as per the project README . Some of the dependencies in the virtual environment will fall fowl of SELinux once the WSGI is set up. You'll need to update the SELinux context of these dependencies: semanage fcontext -a -t httpd_sys_script_exec_t '/var/www/venvs/tileserver-new-ts/lib/python2.7/site-packages/.*\\.so(\\..*)?' sudo restorecon -R -v /var/www/venvs/tileserver-new-ts/lib/python2.7/site-packages/ Finally, make sure the project configuration is set up correctly (see the project README ). If you want to test the virtual environment and config is set up correctly, you can run the development server by running python /var/www/tileserver-new-ts/Tileserver/Scripts/run_tilestache_dev_server.py with the /var/www/venvs/tileserver-new-ts virtual environment activated. Note you might need to first run export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH Finally, you will be wanting to serve overview geotiffs from a folder. With selinux, that folder needs to have the httpd_sys_content_t context. To give an explicit example of how to set this context up, we assume you are storing tile geotiffs within /data/tile_geotiffs : sudo semanage fcontext -a -t httpd_sys_content_t \"/data/tile_geotiffs(/.*)?\" sudo restorecon -R -v /data/tile_geotiffs WSGI set up We currently run the tileserver using the apache module mod_wsgi . Check the folder /etc/httpd/modules for a file called mod_wsgi.so to see it is installed. If not, this can be installed via: sudo yum install mod_wsgi By default, mapnik installs in /usr/local/lib . We need to update the library path in apache so that it knows to find it. This can be set by adding the variable LD_LIBRARY_PATH=/usr/local/lib/ to /etc/sysconfig/httpd . Then, a virtual host (e.g. /etc/httpd/sites-available/new_portal , full instructions are here ) should be populated with something like: WSGIScriptAlias /tiles /var/www/tileserver-new-ts/Tileserver/tileserver.wsgi WSGIDaemonProcess tileserver_new_ts python-home=/var/www/venvs/tileserver-new-ts processes=4 threads=1 WSGIProcessGroup tileserver_new_ts Then to load in the new configurations, this requires a httpd restart: sudo systemctl restart httpd.service Bear in mind that a httpd restart will mean that the server is unable to respond to requests for a few seconds (therefore best to perform this out of hours). Release Update These are instructions for if you need to release an update to a tileserver that is already released. You can update the config as needed, see the project README . To update the code, just use git to pull in the latest required changes. After a change in the project, apache needs to be reloaded: sudo systemctl reload httpd.service This is a soft restart and does not interrupt the current request handling i.e. this can be performed at any point. Troubleshooting If the tileserver is already set up and it suddenly stops working, see the following table: Problem Actions No tiles render Check httpd errors Test development server Httpd reload or restart Overview geotiff tiles render but point tiles do not Check httpd errors Test development server Httpd reload or restart Point tiles render, but overview geotiff tiles do not Check tileserver config vs overview geotiffs Check httpd errors Test development server Httpd reload or restart Some top tips for when setting up the tileserver and you run into problems. Check the logs and see if the error matches with the following: Problem Actions ImportError: No module named Image Check the virtual environment .so files have the correct selinux context, see above about adding httpd_sys_script_exec_t context NameError: global name 'mapnik' is not defined Check you've added LD_LIBRARY_PATH=/usr/local/lib/ to /etc/sysconfig/httpd . /data/tile_geotiffs/.../path/to/geotiff/tiles_4326_10.tif does not exist in file system Check the geotiff files have the correct selinux context, see above about adding httpd_sys_content_t context Actions These are the instructions for the actions list above, we try to provide generic instructions but for illustrate them with examples of commands specific to the satshop tileserver (i.e. the tileserver named \"tileserver-satshop\"). Check httpd errors The httpd error logs are in the httpd log directories (locations detailed in the Live Server Locations section). Test development server This might give you more insights into the errors that are being thrown. Activate the tileserver virtual environment source /var/www/venvs/tileserver-satshop/bin/activate Change directory to the tileserver root cd /var/www/tileserver-satshop/Tileserver And run the development server: python Scripts/run_tilestache_dev_server.py -p <port of your choosing> If the server runs without errors, you may want to check it can receive requests successfully. You can set this up using a proxy in apache, which will forward the requests to this port (similar to what we do with the flask applications). Do not leave the application running in this state - the above command just runs a development server and it should not be used in production. Check tileserver config vs overview geotiffs Check where the config (locations are in the root of the Project code, see Live Server Locations section) is expecting to find the geotiff overview tiles, make sure they exist/replace with back ups. Httpd reload or restart Reloading is a softer version of the \"restarting\" the httpd process. Reloading should not impact the server dealing with requests, but restarting may. The commands are: sudo systemctl reload httpd.service sudo systemctl restart httpd.service","title":"Tileservers"},{"location":"client-facing-applications/tileservers/#tileservers","text":"Instructions for how to install sat-tileserver are kept in the project README . What that README does not make explicit is where everything is installed on the live server. We detail that in this documentation, along with some caveats when trying to run the tileserver behind apache.","title":"Tileservers"},{"location":"client-facing-applications/tileservers/#contents","text":"Live Server Locations - where files related to the tileservers are kept on the live server. First Release - how to release a brand new tileserver. Release Update - how to release an update to tileserver that's already been released. Troubleshooting - something not working? No problem.","title":"Contents"},{"location":"client-facing-applications/tileservers/#live-server-locations","text":"On the live server, we run several tileservers, one for each portal project. This is a list of the tile servers that are running, along with locations of related important files: Tileserver name Domain end point Httpd log directory Httpd config file tileserver-satshop satshop.satsense.com/tiles /var/www/satshop/log /etc/httpd/sites-available/satshop.conf tileserver-staging portal.staging.satsense.com/tiles /var/www/flask-portal-staging/log /etc/httpd/sites-available/flask-portal-staging.conf tileserver-demo demo.satsense.com/tiles /var/www/demo-portal-live/log /etc/httpd/sites-available/demo-portal-live.conf tileserver-demo-staging demo.staging.satsense.com/tiles /var/www/demo-portal-staging/log /etc/httpd/sites-available/demo-portal-staging.conf tileserver-portal2 portal2.satsense.com/tiles /var/www/flask-portal2/log /etc/httpd/sites-available/flask-portal2.conf tileserver-portal3 portal3.satsense.com/tiles /var/www/portal3/log /etc/httpd/sites-available/portal3.conf The httpd log directories and httpd config files are shared with the portal httpd set up because they are provided by the same domain. Other files related to the above projects are kept in the following locations on the live server: Virtual environments are in the directories /var/www/venvs/<Tileserver name> . Project code is in the directories /var/www/<Tileserver name>/Tileserver . Tile overview geotiffs are kept in the directory /data/tile_geotiffs . We don't keep an explicit log for where each tileserver's geotiffs are kept. However, one can look in the tileserver config files to see which geotiffs are being used e.g. /var/www/tileserver-satshop/Tileserver/config.ini will refer to which geotiffs are being used for tileserver-satshop .","title":"Live Server Locations"},{"location":"client-facing-applications/tileservers/#first-release","text":"These are instructions for if you need to release a new tileserver. If you need to release an update, please see the Release Update section.","title":"First Release"},{"location":"client-facing-applications/tileservers/#set-up-code-and-virtual-environment","text":"Create the venvs folder, if it doesn't exist: sudo mkdir /var/www/venvs sudo chown centos:apache /var/www/venvs Create and activate a new virtual environment for the tileserver: virtualenv /var/www/venvs/tileserver-new-ts source /var/www/venvs/tileserver-new-ts/bin/activate Make sure mapnik is installed, see the project README . Create a new directory for the tileserver project, and checkout the project inside that directory: sudo mkdir /var/www/tileserver-new-ts sudo chown centos:apache /var/www/tileserver-new-ts git clone https://gitlab.com/SatSenseLtd/sat-tileserver.git /var/www/tileserver-new-ts/Tileserver Then install the project into the virtual environment as per the project README . Some of the dependencies in the virtual environment will fall fowl of SELinux once the WSGI is set up. You'll need to update the SELinux context of these dependencies: semanage fcontext -a -t httpd_sys_script_exec_t '/var/www/venvs/tileserver-new-ts/lib/python2.7/site-packages/.*\\.so(\\..*)?' sudo restorecon -R -v /var/www/venvs/tileserver-new-ts/lib/python2.7/site-packages/ Finally, make sure the project configuration is set up correctly (see the project README ). If you want to test the virtual environment and config is set up correctly, you can run the development server by running python /var/www/tileserver-new-ts/Tileserver/Scripts/run_tilestache_dev_server.py with the /var/www/venvs/tileserver-new-ts virtual environment activated. Note you might need to first run export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH Finally, you will be wanting to serve overview geotiffs from a folder. With selinux, that folder needs to have the httpd_sys_content_t context. To give an explicit example of how to set this context up, we assume you are storing tile geotiffs within /data/tile_geotiffs : sudo semanage fcontext -a -t httpd_sys_content_t \"/data/tile_geotiffs(/.*)?\" sudo restorecon -R -v /data/tile_geotiffs","title":"Set Up Code and Virtual Environment"},{"location":"client-facing-applications/tileservers/#wsgi-set-up","text":"We currently run the tileserver using the apache module mod_wsgi . Check the folder /etc/httpd/modules for a file called mod_wsgi.so to see it is installed. If not, this can be installed via: sudo yum install mod_wsgi By default, mapnik installs in /usr/local/lib . We need to update the library path in apache so that it knows to find it. This can be set by adding the variable LD_LIBRARY_PATH=/usr/local/lib/ to /etc/sysconfig/httpd . Then, a virtual host (e.g. /etc/httpd/sites-available/new_portal , full instructions are here ) should be populated with something like: WSGIScriptAlias /tiles /var/www/tileserver-new-ts/Tileserver/tileserver.wsgi WSGIDaemonProcess tileserver_new_ts python-home=/var/www/venvs/tileserver-new-ts processes=4 threads=1 WSGIProcessGroup tileserver_new_ts Then to load in the new configurations, this requires a httpd restart: sudo systemctl restart httpd.service Bear in mind that a httpd restart will mean that the server is unable to respond to requests for a few seconds (therefore best to perform this out of hours).","title":"WSGI set up"},{"location":"client-facing-applications/tileservers/#release-update","text":"These are instructions for if you need to release an update to a tileserver that is already released. You can update the config as needed, see the project README . To update the code, just use git to pull in the latest required changes. After a change in the project, apache needs to be reloaded: sudo systemctl reload httpd.service This is a soft restart and does not interrupt the current request handling i.e. this can be performed at any point.","title":"Release Update"},{"location":"client-facing-applications/tileservers/#troubleshooting","text":"If the tileserver is already set up and it suddenly stops working, see the following table: Problem Actions No tiles render Check httpd errors Test development server Httpd reload or restart Overview geotiff tiles render but point tiles do not Check httpd errors Test development server Httpd reload or restart Point tiles render, but overview geotiff tiles do not Check tileserver config vs overview geotiffs Check httpd errors Test development server Httpd reload or restart Some top tips for when setting up the tileserver and you run into problems. Check the logs and see if the error matches with the following: Problem Actions ImportError: No module named Image Check the virtual environment .so files have the correct selinux context, see above about adding httpd_sys_script_exec_t context NameError: global name 'mapnik' is not defined Check you've added LD_LIBRARY_PATH=/usr/local/lib/ to /etc/sysconfig/httpd . /data/tile_geotiffs/.../path/to/geotiff/tiles_4326_10.tif does not exist in file system Check the geotiff files have the correct selinux context, see above about adding httpd_sys_content_t context","title":"Troubleshooting"},{"location":"client-facing-applications/tileservers/#actions","text":"These are the instructions for the actions list above, we try to provide generic instructions but for illustrate them with examples of commands specific to the satshop tileserver (i.e. the tileserver named \"tileserver-satshop\").","title":"Actions"},{"location":"client-facing-applications/tileservers/#check-httpd-errors","text":"The httpd error logs are in the httpd log directories (locations detailed in the Live Server Locations section).","title":"Check httpd errors"},{"location":"client-facing-applications/tileservers/#test-development-server","text":"This might give you more insights into the errors that are being thrown. Activate the tileserver virtual environment source /var/www/venvs/tileserver-satshop/bin/activate Change directory to the tileserver root cd /var/www/tileserver-satshop/Tileserver And run the development server: python Scripts/run_tilestache_dev_server.py -p <port of your choosing> If the server runs without errors, you may want to check it can receive requests successfully. You can set this up using a proxy in apache, which will forward the requests to this port (similar to what we do with the flask applications). Do not leave the application running in this state - the above command just runs a development server and it should not be used in production.","title":"Test development server"},{"location":"client-facing-applications/tileservers/#check-tileserver-config-vs-overview-geotiffs","text":"Check where the config (locations are in the root of the Project code, see Live Server Locations section) is expecting to find the geotiff overview tiles, make sure they exist/replace with back ups.","title":"Check tileserver config vs overview geotiffs"},{"location":"client-facing-applications/tileservers/#httpd-reload-or-restart","text":"Reloading is a softer version of the \"restarting\" the httpd process. Reloading should not impact the server dealing with requests, but restarting may. The commands are: sudo systemctl reload httpd.service sudo systemctl restart httpd.service","title":"Httpd reload or restart"},{"location":"client-facing-applications/webmisc/","text":"Overview Contents: Apache Httpd Set Up SSL Certificates 'A' Records Application Emails Apache Httpd Set Up We follow the sites-available pattern for setting up our virtual hosts. This involves creating folders: sudo mkdir /etc/httpd/sites-available /etc/httpd/sites-enabled and then populating them with virtual host files. We manually put in these files inside /etc/httpd/sites-available and then we create and destroy symbolic links to those files inside /etc/httpd/sites-enabled . The apache server is only aware of the /etc/httpd/sites-enabled folder. To do this, open the main config file: sudo vi /etc/httpd/conf/httpd.conf and add in IncludeOptional sites-enabled/*.conf somewhere in the file. We can now create a virtual host config file sudo vi /etc/httpd/sites-available/portal-live.conf and populate it. Example virtual host files are contained in the documentation for each application. Now to make the site enabled, create a symbolic link: sudo ln -s /etc/httpd/sites-available/portal-live.conf /etc/httpd/sites-enabled/portal-live.conf The site can be taken offline by removing this symbolic link. After adding or removing a symbolic link, the httpd process will need to be restarted: systemctl restart httpd.service SSL Certificates We use certbot to produce our ssl certificates. There are very good instructions on that website, see here for installation instructions for Centos 7 using apache. Note that centos has EPEL enabled by default, but you can check whether this is the case via: rpm -q epel-release --last Running step five ( certbot --apache ) will ask for: * An email for urgent renewals/security notices. * Ask for you to agree to the terms of service. * Ask if you'd like to share email with EFF. * Ask which domains you'd like to activate https for (you can select domains that already have a certificate if you want to add a domain to an existing certificate). * Ask if you'd like to redirect to https. Note that if certbot runs into a problem, it will attempt to rollback any config to the before it was run. If config installation was unsuccessful, running certbot --apache should recognise if any certificate has been obtained previously, and ask if you'd like to use that. Running echo \"0 0,12 * * * root python -c 'import random; import time; time.sleep(random.random() * 3600)' && certbot renew\" | sudo tee -a /etc/crontab > /dev/null adds a chron job every 12 hours (offset by a random amount) and sets the cert to be renewed. The certificate is only renewed if certificates are short lived. Troubleshooting On first run through, got the error Name duplicates previous WSGI daemon configuration . See this stack overflow post . 'A' Records Our domain is registered with www.namebright.com . To route a new subdomain, for example notaliveexample.satsense.com 1. Log in (credentials are deliberately omitted) and go to DNS Records . 2. Scroll, to the bottom and click Add a New DNS Record . 3. Select A Address Record from the Choose record type drop down. 4. Select Custom Host Name... from the Subdomain drop down. 5. Type in notaliveexample (or similar). 6. Type in the IP Address of the server. 7. Click Add . Application Emails Currently the portal and the admin site send emails for logging and account management purposes. These applications use the flask extension flask-mail . Whilst we assume the reader is setting up email sending with these applications (and in particular flask-mail), these instructions should be transferable to any other framework. To get these applications to send an email, you will need to populate the following settings in config.ini : mail_server = smtp.office365.com mail_port = 587 mail_use_tls = true mail_use_ssl = false mail_username = <username> mail_password = <password> The above settings are correct apart from the username and password. The username is the email address associated with your account, but note that the password is not the password you use to log in online. Instead, you will need to set up an application password . Additionally, config.ini asks for a default_mail_sender . This could be your email address, but you can also specify noreply@satsense.com to send emails from that anonymous user (this is the current live setting). The current live applications uses credentials for michael.west@satsense.com . As a result, if this account is ever removed then the emails will stop working on these applications.","title":"Overview"},{"location":"client-facing-applications/webmisc/#overview","text":"Contents: Apache Httpd Set Up SSL Certificates 'A' Records Application Emails","title":"Overview"},{"location":"client-facing-applications/webmisc/#apache-httpd-set-up","text":"We follow the sites-available pattern for setting up our virtual hosts. This involves creating folders: sudo mkdir /etc/httpd/sites-available /etc/httpd/sites-enabled and then populating them with virtual host files. We manually put in these files inside /etc/httpd/sites-available and then we create and destroy symbolic links to those files inside /etc/httpd/sites-enabled . The apache server is only aware of the /etc/httpd/sites-enabled folder. To do this, open the main config file: sudo vi /etc/httpd/conf/httpd.conf and add in IncludeOptional sites-enabled/*.conf somewhere in the file. We can now create a virtual host config file sudo vi /etc/httpd/sites-available/portal-live.conf and populate it. Example virtual host files are contained in the documentation for each application. Now to make the site enabled, create a symbolic link: sudo ln -s /etc/httpd/sites-available/portal-live.conf /etc/httpd/sites-enabled/portal-live.conf The site can be taken offline by removing this symbolic link. After adding or removing a symbolic link, the httpd process will need to be restarted: systemctl restart httpd.service","title":"Apache Httpd Set Up"},{"location":"client-facing-applications/webmisc/#ssl-certificates","text":"We use certbot to produce our ssl certificates. There are very good instructions on that website, see here for installation instructions for Centos 7 using apache. Note that centos has EPEL enabled by default, but you can check whether this is the case via: rpm -q epel-release --last Running step five ( certbot --apache ) will ask for: * An email for urgent renewals/security notices. * Ask for you to agree to the terms of service. * Ask if you'd like to share email with EFF. * Ask which domains you'd like to activate https for (you can select domains that already have a certificate if you want to add a domain to an existing certificate). * Ask if you'd like to redirect to https. Note that if certbot runs into a problem, it will attempt to rollback any config to the before it was run. If config installation was unsuccessful, running certbot --apache should recognise if any certificate has been obtained previously, and ask if you'd like to use that. Running echo \"0 0,12 * * * root python -c 'import random; import time; time.sleep(random.random() * 3600)' && certbot renew\" | sudo tee -a /etc/crontab > /dev/null adds a chron job every 12 hours (offset by a random amount) and sets the cert to be renewed. The certificate is only renewed if certificates are short lived. Troubleshooting On first run through, got the error Name duplicates previous WSGI daemon configuration . See this stack overflow post .","title":"SSL Certificates"},{"location":"client-facing-applications/webmisc/#a-records","text":"Our domain is registered with www.namebright.com . To route a new subdomain, for example notaliveexample.satsense.com 1. Log in (credentials are deliberately omitted) and go to DNS Records . 2. Scroll, to the bottom and click Add a New DNS Record . 3. Select A Address Record from the Choose record type drop down. 4. Select Custom Host Name... from the Subdomain drop down. 5. Type in notaliveexample (or similar). 6. Type in the IP Address of the server. 7. Click Add .","title":"'A' Records"},{"location":"client-facing-applications/webmisc/#application-emails","text":"Currently the portal and the admin site send emails for logging and account management purposes. These applications use the flask extension flask-mail . Whilst we assume the reader is setting up email sending with these applications (and in particular flask-mail), these instructions should be transferable to any other framework. To get these applications to send an email, you will need to populate the following settings in config.ini : mail_server = smtp.office365.com mail_port = 587 mail_use_tls = true mail_use_ssl = false mail_username = <username> mail_password = <password> The above settings are correct apart from the username and password. The username is the email address associated with your account, but note that the password is not the password you use to log in online. Instead, you will need to set up an application password . Additionally, config.ini asks for a default_mail_sender . This could be your email address, but you can also specify noreply@satsense.com to send emails from that anonymous user (this is the current live setting). The current live applications uses credentials for michael.west@satsense.com . As a result, if this account is ever removed then the emails will stop working on these applications.","title":"Application Emails"},{"location":"client-facing-applications/what-mike-does/","text":"\"What Mike does\" This document contains a list of ad hoc jobs that that need to be taken over. It also contains high level instructions for each job along with links to other relevant documentation, if applicable. Contents Ingest new frame into portal - just refers to ingesting data process and not creating a new portal from scratch. Regenerate countrywide srisks for API Regenerate tiles - tiles aka tile overviews, portal geotiffs Create new portal - just release a new portal, this assumes InSAR data already exists. Add user to staging portal, portal2 or portal3 Generate monthly figures for API Keep an eye on SLA for API Test against API before/after release Insert new dates into live database Keep an eye on SSD storage on API Server Be on hand if server/postgres bounce required Update warm back up insar data Update warm back up user data Ingest new frame into portal Frequency: Every 1-2 months/when prompted Actions: Create new database (for csk data, historically we've called it london_csk_{today's date} , e.g. london_csk_20200803 ). Just do this by logging into psql using postgres user and running create database london_csk_... . Run insar_data_db alembic migrations on this new database. We keep a checked out version of satsense_domain on the api server at /home/centos/Projects/alembic/satsense_domain . There is a virtual environment in this folder too called venv_alembic . Don't forget to check alembic.ini in satsense_db_migrations/insar_data_db . To run the migrations, check current schema is empty using alembic current and then upgrade to most recent schema using alembic upgrade head . Give correct permissions to users for the database you've created. For csk datasets, I've been giving staging_pgi full read, write and delete permissions and satsense_ro read permissions. More info about setting up permissions here: https://satsenseltd.gitlab.io/Documentation/client-facing-applications/database/#2-user-creation-and-permissions Use satpgi to do an initial ingest into the database. Check the config before you run anything. Use satdom scripts to generate the tiles from this database. Again check config. Can use satsense_ro user here. Move tiles to sensible location. Look in /data/tile_geotiffs (specifically for csk look in /data/tile_geotiffs/staging/vels_hr_asc ). Consider doing both rural/high res or ascending/descending. Change satshop (or portal3 for csk data) config to use new database and satshop tileserver (or portal3 tileserver for csk data) to use new database and tiles. Restart portal3 and run httpd reload (reload is a soft restart). Locations of configuration files are the docs for the portal and the tileservers . Check it's rendering something and check it seems reasonable. Regenerate countrywide srisks for api Frequency: Every 1-2 months/when prompted Actions: Use the script generate_srisks_tifs.py from the satdom scripts to regenerate the entire srisks for the api. Once generated, we will alter the config of the staging api (at /var/www/api-staging/app_home/config.in - given for convenience but could have been found in the api docs ). In this staging api config, change the value all_srisk_geotiff_path under the section srisk to the full path of the new srisk file. The current value is probably somewhere on the ssd (i.e. starting with /data ), but it is fine to test the new srisk file from the rust disks - it just might be a little slower. You may be wondering what that option precalculated_directory_path does - this was used when we were just serving \"spatial srisks\" from four different files - we now serve all srisks from one file. Restart the staging api to load the new config. i.e. run sudo systemctl stop apistaging followed by sudo systemctl start apistaging . Run the qa tests against the live api (which uses the old srisk geotiff) and the staging api (which uses the new srisk geotiff due to the previous steps). You might want to keep an eye on response times during pinging the live api, or run outside of hours. Compare the results from the previous step. Would usually do this by comparing the proportions of red/amber/green or look at which polygons have changed status. If there is no big change then you can probably roll out the release without too much hassle. Make groundsure aware (via list of emails I forwarded) that you plan to update some data and offer them the chance to test it against the \"test api\" i.e. api.test.satsense.com . If there is a big change in the results, best to consult Karsten with what to do. May want to highlight change to groundsure, again liaise with Karsten about who best to approach at groundsure regarding this. Once release is scheduled, update the test and live configs and restart each app. The config paths/how to restart each app can be found in the api docs . The restart of each app might need to happen on different days if groundsure want to test against the test api. Regenerate tiles TODO Create new portal TODO Add user to staging portal, portal2 or portal3 TODO Keep an eye on SLA for API TODO Test against API before/after release TODO Insert new dates into live database Frequency: As often as possible Actions: This refers to running the satpgi insert-dates script . Before running this, have a look what other satpgi are happening - check satpgi screens on each vm. Tend to only run two satpgi scripts at the same time (one for each vm). Wait until after 5pm on a weekday or anytime at weekend. Find a suitable frame to update. We manually keep a list of how up-to-date frames are in the database. Find that here . Also sometimes good to check if there is any current processing on the frame in question. To do that, replace <frame id> with a frame id in the following url: https://admin.satsense.com/processing_controller/frame/<frame id> and see if there are any Running Dates on that page. - Can run satpgi insert dates as detailed here . Always check config before running to make sure you're inserting dates into the right place! - For convenience, an example insert-date script: python main.py insert-dates -i 103A_03733_131113 --hr-file /rust2/workspace/frames/103A_03733_131113/RapidSAR/103A_03733_131113-vel.h5 --rural-file /rust2/workspace/frames/103A_03733_131113/RapidSAR/103A_03733_131113-rural-vel.h5 Keep an eye on SSD storage on API Server Frequency: Every so often, more frequently if higher than 85% or so. Actions: Log onto api server and run df -h and look at /data usage. The biggest consumer of data is inserting new dates into the database , but even this doesn't eat too much database too quickly. Really start to worry if less than 150-200GB remaining - then probably worth expanding. Before expanding, delete unnecessary databases/files then if still required talk to Matt (it is expensive) and if he's happy give Seth at unipart an email. The expansion will require a server restart . Be on hand if server restart or database bounce required Frequency: When required Actions: If planned and it affects API, best to let groundsure know, even if maintenance would be out of hours. \"Server restart\" usually goes completely fine and services don't need looking at. \"Database bounce\" can affect some of the application transaction handling and those applications need restarting to rectify. We list a table of services, how you check they are fine and how to restart if they're not. Service Name How to check it's fine How to restart service satshop Log into satshop.satsense.com and retrieve a time series by clicking point systemctl stop satshop systemctl start satshop staging portal Log into portal.staging.satsense.com and retrieve a time series by clicking point systemctl stop portalstaging systemctl start portalstaging portal2 Log into portal2.satsense.com and retrieve a time series by clicking point systemctl stop portal2 systemctl start portal2 portal3 Log into portal3.satsense.com and retrieve a time series by clicking point systemctl stop portal3 systemctl start portal3 admin Log into admin.satsense.com systemctl stop adminlive systemctl start adminlive adminstaging Log into admin.staging.satsense.com systemctl stop adminstaging systemctl start adminstaging admin2 Log into portal2.satsense.com/admin systemctl stop admin2 systemctl start admin2 admin3 Log into portal3.satsense.com/admin systemctl stop admin3 systemctl start admin3 All tile servers Log into relevant portal and check tiles rendered systemctl reload httpd api live Check new relic status/ping api/check logs for errors systemctl stop apilive systemctl start apilive api test Check new relic status/ping api/check logs for errors systemctl stop apitest systemctl start apitest api staging Ping api/check logs for errors systemctl stop apistaging systemctl start apistaging api live celery process Check celery worker logs located at /var/www/api-live/celery/apilivew1-1.log and /var/www/api-live/celery/apilivew1-2.log - make sure there are recent \"succeeded\" messages systemctl stop apilivecelery systemctl start apilivecelery api test celery process Check celery worker logs located at /var/www/api-test/celery/apitestw1-1.log - make sure there are recent \"succeeded\" messages systemctl stop apitestcelery systemctl start apitestcelery api staging celery process Check celery worker logs located at /var/www/api-staging/celery/apistagingw1-1.log - make sure there are recent \"succeeded\" messages systemctl stop apistagingcelery systemctl start apistagingcelery","title":"\"What Mike does\""},{"location":"client-facing-applications/what-mike-does/#what-mike-does","text":"This document contains a list of ad hoc jobs that that need to be taken over. It also contains high level instructions for each job along with links to other relevant documentation, if applicable.","title":"\"What Mike does\""},{"location":"client-facing-applications/what-mike-does/#contents","text":"Ingest new frame into portal - just refers to ingesting data process and not creating a new portal from scratch. Regenerate countrywide srisks for API Regenerate tiles - tiles aka tile overviews, portal geotiffs Create new portal - just release a new portal, this assumes InSAR data already exists. Add user to staging portal, portal2 or portal3 Generate monthly figures for API Keep an eye on SLA for API Test against API before/after release Insert new dates into live database Keep an eye on SSD storage on API Server Be on hand if server/postgres bounce required Update warm back up insar data Update warm back up user data","title":"Contents"},{"location":"client-facing-applications/what-mike-does/#ingest-new-frame-into-portal","text":"Frequency: Every 1-2 months/when prompted Actions: Create new database (for csk data, historically we've called it london_csk_{today's date} , e.g. london_csk_20200803 ). Just do this by logging into psql using postgres user and running create database london_csk_... . Run insar_data_db alembic migrations on this new database. We keep a checked out version of satsense_domain on the api server at /home/centos/Projects/alembic/satsense_domain . There is a virtual environment in this folder too called venv_alembic . Don't forget to check alembic.ini in satsense_db_migrations/insar_data_db . To run the migrations, check current schema is empty using alembic current and then upgrade to most recent schema using alembic upgrade head . Give correct permissions to users for the database you've created. For csk datasets, I've been giving staging_pgi full read, write and delete permissions and satsense_ro read permissions. More info about setting up permissions here: https://satsenseltd.gitlab.io/Documentation/client-facing-applications/database/#2-user-creation-and-permissions Use satpgi to do an initial ingest into the database. Check the config before you run anything. Use satdom scripts to generate the tiles from this database. Again check config. Can use satsense_ro user here. Move tiles to sensible location. Look in /data/tile_geotiffs (specifically for csk look in /data/tile_geotiffs/staging/vels_hr_asc ). Consider doing both rural/high res or ascending/descending. Change satshop (or portal3 for csk data) config to use new database and satshop tileserver (or portal3 tileserver for csk data) to use new database and tiles. Restart portal3 and run httpd reload (reload is a soft restart). Locations of configuration files are the docs for the portal and the tileservers . Check it's rendering something and check it seems reasonable.","title":"Ingest new frame into portal"},{"location":"client-facing-applications/what-mike-does/#regenerate-countrywide-srisks-for-api","text":"Frequency: Every 1-2 months/when prompted Actions: Use the script generate_srisks_tifs.py from the satdom scripts to regenerate the entire srisks for the api. Once generated, we will alter the config of the staging api (at /var/www/api-staging/app_home/config.in - given for convenience but could have been found in the api docs ). In this staging api config, change the value all_srisk_geotiff_path under the section srisk to the full path of the new srisk file. The current value is probably somewhere on the ssd (i.e. starting with /data ), but it is fine to test the new srisk file from the rust disks - it just might be a little slower. You may be wondering what that option precalculated_directory_path does - this was used when we were just serving \"spatial srisks\" from four different files - we now serve all srisks from one file. Restart the staging api to load the new config. i.e. run sudo systemctl stop apistaging followed by sudo systemctl start apistaging . Run the qa tests against the live api (which uses the old srisk geotiff) and the staging api (which uses the new srisk geotiff due to the previous steps). You might want to keep an eye on response times during pinging the live api, or run outside of hours. Compare the results from the previous step. Would usually do this by comparing the proportions of red/amber/green or look at which polygons have changed status. If there is no big change then you can probably roll out the release without too much hassle. Make groundsure aware (via list of emails I forwarded) that you plan to update some data and offer them the chance to test it against the \"test api\" i.e. api.test.satsense.com . If there is a big change in the results, best to consult Karsten with what to do. May want to highlight change to groundsure, again liaise with Karsten about who best to approach at groundsure regarding this. Once release is scheduled, update the test and live configs and restart each app. The config paths/how to restart each app can be found in the api docs . The restart of each app might need to happen on different days if groundsure want to test against the test api.","title":"Regenerate countrywide srisks for api"},{"location":"client-facing-applications/what-mike-does/#regenerate-tiles","text":"TODO","title":"Regenerate tiles"},{"location":"client-facing-applications/what-mike-does/#create-new-portal","text":"TODO","title":"Create new portal"},{"location":"client-facing-applications/what-mike-does/#add-user-to-staging-portal-portal2-or-portal3","text":"TODO","title":"Add user to staging portal, portal2 or portal3"},{"location":"client-facing-applications/what-mike-does/#keep-an-eye-on-sla-for-api","text":"TODO","title":"Keep an eye on SLA for API"},{"location":"client-facing-applications/what-mike-does/#test-against-api-beforeafter-release","text":"TODO","title":"Test against API before/after release"},{"location":"client-facing-applications/what-mike-does/#insert-new-dates-into-live-database","text":"Frequency: As often as possible Actions: This refers to running the satpgi insert-dates script . Before running this, have a look what other satpgi are happening - check satpgi screens on each vm. Tend to only run two satpgi scripts at the same time (one for each vm). Wait until after 5pm on a weekday or anytime at weekend. Find a suitable frame to update. We manually keep a list of how up-to-date frames are in the database. Find that here . Also sometimes good to check if there is any current processing on the frame in question. To do that, replace <frame id> with a frame id in the following url: https://admin.satsense.com/processing_controller/frame/<frame id> and see if there are any Running Dates on that page. - Can run satpgi insert dates as detailed here . Always check config before running to make sure you're inserting dates into the right place! - For convenience, an example insert-date script: python main.py insert-dates -i 103A_03733_131113 --hr-file /rust2/workspace/frames/103A_03733_131113/RapidSAR/103A_03733_131113-vel.h5 --rural-file /rust2/workspace/frames/103A_03733_131113/RapidSAR/103A_03733_131113-rural-vel.h5","title":"Insert new dates into live database"},{"location":"client-facing-applications/what-mike-does/#keep-an-eye-on-ssd-storage-on-api-server","text":"Frequency: Every so often, more frequently if higher than 85% or so. Actions: Log onto api server and run df -h and look at /data usage. The biggest consumer of data is inserting new dates into the database , but even this doesn't eat too much database too quickly. Really start to worry if less than 150-200GB remaining - then probably worth expanding. Before expanding, delete unnecessary databases/files then if still required talk to Matt (it is expensive) and if he's happy give Seth at unipart an email. The expansion will require a server restart .","title":"Keep an eye on SSD storage on API Server"},{"location":"client-facing-applications/what-mike-does/#be-on-hand-if-server-restart-or-database-bounce-required","text":"Frequency: When required Actions: If planned and it affects API, best to let groundsure know, even if maintenance would be out of hours. \"Server restart\" usually goes completely fine and services don't need looking at. \"Database bounce\" can affect some of the application transaction handling and those applications need restarting to rectify. We list a table of services, how you check they are fine and how to restart if they're not. Service Name How to check it's fine How to restart service satshop Log into satshop.satsense.com and retrieve a time series by clicking point systemctl stop satshop systemctl start satshop staging portal Log into portal.staging.satsense.com and retrieve a time series by clicking point systemctl stop portalstaging systemctl start portalstaging portal2 Log into portal2.satsense.com and retrieve a time series by clicking point systemctl stop portal2 systemctl start portal2 portal3 Log into portal3.satsense.com and retrieve a time series by clicking point systemctl stop portal3 systemctl start portal3 admin Log into admin.satsense.com systemctl stop adminlive systemctl start adminlive adminstaging Log into admin.staging.satsense.com systemctl stop adminstaging systemctl start adminstaging admin2 Log into portal2.satsense.com/admin systemctl stop admin2 systemctl start admin2 admin3 Log into portal3.satsense.com/admin systemctl stop admin3 systemctl start admin3 All tile servers Log into relevant portal and check tiles rendered systemctl reload httpd api live Check new relic status/ping api/check logs for errors systemctl stop apilive systemctl start apilive api test Check new relic status/ping api/check logs for errors systemctl stop apitest systemctl start apitest api staging Ping api/check logs for errors systemctl stop apistaging systemctl start apistaging api live celery process Check celery worker logs located at /var/www/api-live/celery/apilivew1-1.log and /var/www/api-live/celery/apilivew1-2.log - make sure there are recent \"succeeded\" messages systemctl stop apilivecelery systemctl start apilivecelery api test celery process Check celery worker logs located at /var/www/api-test/celery/apitestw1-1.log - make sure there are recent \"succeeded\" messages systemctl stop apitestcelery systemctl start apitestcelery api staging celery process Check celery worker logs located at /var/www/api-staging/celery/apistagingw1-1.log - make sure there are recent \"succeeded\" messages systemctl stop apistagingcelery systemctl start apistagingcelery","title":"Be on hand if server restart or database bounce required"},{"location":"client-facing-applications/portal/portal-overview/","text":"Overview The page includes documentation for the portal and admin sites. This includes information about the following applications: * the UK portal flask application (portal.satsense.com); * the admin site flask application (admin.satsense.com); * the tileserver for the full UK portal (portal.satsense.com/tiles); * the demo portal PHP application (demo.satsense.com); * the demo tileserver for the demo portal (demo.satsense.com/tiles). We will refer to each application by the text in bold . Since both the portal and the admin site are written in flask, this documentation starts with detailing information common to both. We then document details for both tileservers and for the demo portal. We finish with troubleshooting hints for all applications, which also cover where the reader can find relevant log files. Contents: General Information for Flask Applications Documentation and Resources Project Design Choices Testing Release Set Up Portal Release Portal Virtual Host for Portal Admin Site Release Admin Site Virtual Host for Admin Site Tileserver and Demo Tileserver Demo Portal Troubleshooting General Information for Flask Applications Documentation and Resources The reader may find the following resources useful: * Flask Documentation - general documentation for flask. * Flask Login Documentation - documentation for the flask plugin we have chosen to handle user sessions. * Flask Mega-Tutorial - an introduction to the world of flask, written in 2017-18. Suitable for absolute beginners to flask, but also useful for seasoned developers. However, bear in mind that Miguel hasn't necessarily chosen the same design choices that we have. * Explore Flask - a book backed on Kickstarter in July 2013. Most of the material is still relevant. Project Design Choices Overall Design From the root of the flask app repository you should find the following directory structure: - <name of project python module> - app - **possibly some other python modules** - src - js - css - **possibly some other directories/files** - requirements - development.txt - production.txt - tests - integrations_tests - **possibly some other tests (e.g. unit tests)** - app.py - config.ini - setup.py - .gitlab-ci.yml - MANIFEST.in - pytest.ini - **some other files** The directory <name of project python module> contains all of the python code relevant to the site. The actual flask app is contained in the subdirectory app , and the <name of project python module> directory may contain other directories - for example, a domain directory to allow the app to connect to a database. The directory src contains javascript and styling code, amongst other files. This directory contains the versions of this code that is checked into source control, that is, it is easy for a developer to work on them. However, before the files are able to be served by a server (development or production), this code needs to be compiled and possibly bundled. See specifics in each projects' readme.md . The directories described above are generally all a developer would have to change to introduce new features. However, here is a brief description of the rest: * The directory requirements contains pip dependencies for the projects. Instructions for how to install dependencies should be found in each projects' readme.md . * The directory tests contains tests for the project. See the testing section for information about testing structure choices for the projects. We use pytest as the project test runner, so setting are contained in pytest.ini . * The file app.py contains bootstrap code that runs the project. Running flask run (after setting up the enviroment etc) runs this file. * The file .gitlab-ci.yml instructs gitlab to automatically run the tests for the project upon pushing a commit * The file setup.py allows the project python module to be installable into a virtual or conda environment. * Upon installing the project into an environment, non-python files (such as html) may not be included in to the installation. The file MANIFEST.in specifies files that should be included into the installation. <name of project python module>/app Design We aim to follow an Model-View-Controller (MVC) design pattern. With that in mind, the <name of project python module>/app directory contains the following structure: - controllers - models - templates - **possibly some other files/directories** The directory templates contains the Views with regards to the MVC pattern - whilst this mismatch of terminology may be confusing at first, it is convention for flask to look for a directory called templates . This directory contains jinja2 and .txt templates. Jinja2 templates are html that allow dynamic values to be injected into them. For example: <p>Hello, {{ model.name }}</p> expects an object to be injected into the page with the attribute name . We call these objects \"models\". These are exactly the objects you can find in the models directory. Because models are extremely simple classes, we aim to use python dataclasses for the models. Whilst Jinja2 templates expect a model to be injected into them, we still need code that will obtain data (perhaps from a database), initialise a model and then actually do the injection of the model into the template. This code is known as a controller and it lives inside the controllers directory. We aim to use the same names across the different directories, so it clear to the developer where to find related models, templates (views) and controllers. For example, the developer may expect to find something like following structure: - controllers - manage_users_controller.py - models - manage_users_models.py - templates - manage_users - view_user.html - search_users.html Testing TODO Release Set Up We host the flask applications on the api server satsense-api.mb1.unipart.io . The following describes how the flask application accepts requests: User makes http request to api server; Apache httpd server accepts request and proxies it to a port (e.g. port 5000) also on api server; Flask application listens on port (e.g. port 5000) and accepts proxied request, it then responds appropriately. To note, systemd runs a gunicorn server allowing the flask application to listen on port. User receives response after it has been proxied back through httpd server. In the following, we describe how to get the flask application up and running as per step 3. See the portal and admin site sections for further information and example virtual host files for apache httpd. For further information about virtual hosts, see the miscellaneous web section , where there is also information about setting up DNS records, and ssl certificates (which will also need to be done for the application). Flask Application Set Up Overview of directory structure All the code for the applications is stored within a subdirectory of /var/www . For example, the live portal website code is contained within: /var/www/flask-portal-live This subdirectory has the following structure: - app_home - log - public - virtual_environments The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the application, namely app.py and config.ini (see Overall Design ). The directory public contains static assets that are not served by the flask application, these assets include (but not limited to): * static html (such as error pages); * javascript; * css; Apache is configured to serve these static assets directly rather than proxy the request to flask. Finally, the log directory contains logs for application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the sub directory log/flask . Commands for setting up directory structure In the following, we assume the location of the live portal. The reader should change the folder paths for the application they are setting up. If this is the first application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the overiew of directory structure section: sudo mkdir /var/www/flask-portal-live/ cd /var/www/flask-portal-live/ sudo mkdir public/ sudo chown flaskuser:apache public/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ Notice that flaskuser is the owner of all of the directories, but that apache needs access to the public and logs directories. The former is so that the the apache server can serve files from this directory without having to give send a proxy request to the flask application. The latter is so the apache server can write logs to this directory. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/flask-portal-live/log(/.*)?\" sudo restorecon -R -v log/ You can now populate the virtual environment, and app_home/public directories. Further details can be found in the Release Portal and Release Admin Site systemd and gunicorn set up The following assumes the setup for the live portal web site and that the application has been set up as per the Release Portal section. Replace names/paths that make sense for the application you would like to run via systemd. Gunicorn is easy to install via pip. First make sure you are logged into the api server as flaskuser (you can run sudo su flaskuser as centos ), and then run: source /var/www/flask-portal-live/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the site is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/flask-portal-live/app_home and replace <port> with a port number. We'd like the above process to be run automatically, which is done by using systemd . To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: touch /etc/systemd/system/portallive.service chmod 664 /etc/systemd/system/portallive.service Then populate the file, the following is the current systemd config for the live portal process: [Unit] Description = PortalLive After = network.target [Service] User=flaskuser WorkingDirectory=/var/www/flask-portal-live/app_home ExecStart=/var/www/flask-portal-live/virtual_environments/venv/bin/gunicorn -b localhost:7000 -w 4 app:app Restart=always [Install] WantedBy = multi-user.target For systemd to recognise the new file, you will need to run systemctl daemon-reload and you can check it has been found using systemctl list-unit-files The service can be started via: systemctl start portallive or stopped via: systemctl stop portallive To allow the service to start on server reboot, it needs to be enabled: systemctl enable portallive Portal First Release of Portal At time of writing, the user \"flaskuser\" on the api server runs all of the flask apps. The following instructions assume that the portal has already been released on the server. If this is the first release of the portal on the server The reader can follow the instructions following this note, but omit uninstalling satdom/satportal and removing static files (just copy them over). In addition to the instructions following this note, the will reader will need to: Create a virtual environment for the application Populate the app_home directory Create a 503 document in public/error the reader will also need to copy the app.py and config.ini files (and populate the config.ini correctly): cp app.py /var/www/flask-portal-live/app_home cp config.ini /var/www/flask-portal-live/app_home # populate config.ini correctly Finally, gdal is a fiddly dependency and needs to be installed in a particular way. Instead of just running pip install -r requirements/production.txt check the project readme.md. Subsequent Releases of Portal To release the portal, follow the steps: Log onto api server as flaskuser (can run sudo su flaskuser as centos). Checkout latest versions of the master branches of satsense-domain, and satsense-portal. Projects are already cloned in ~/projects . Change dir to satsense-portal root directory (i.e. cd ~/projects/satsense-portal ). Make sure the ./static folder doesn't exist or is empty; that src/js/config.js is correct and that the rest of the working directory is clean. Backups can be found at ~/config_backups . From satsense-portal root directory, run npm run gulp . The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps. This can be done via sudo systemctl stop portalstaging.service or sudo systemctl stop portallive.service for the live version. Apply any db changes using alembic. (This step is a stub, more details is a TODO) Check if the config needs updating. On gitlab, compare the master branch of satsense-portal to the most recent release tag - if config.ini has been updated, you'll need to apply changes to the current version. Current site config can be found at /var/www/flask-portal-live/app_home/config.ini . Make a back up if you wish. Uninstall satdom/satportal in the venv: source /var/www/flask-portal-live/virtual_environments/venv/bin/activate pip uninstall satdom satportal Check dependencies, on the same gitlab comparison as config update, check if requirements/production.txt has been updated. If so, run (within venv): pip install -r requirements/production.txt Reinstall satdom/satsense-portal into the venv. From within venv, run: cd ~/projects/satsense-domain pip install --no-dependencies . cd ~/projects/satsense-portal pip install --no-dependencies . Replace static files cd /var/www/flask-portal-live/public/static rm -rv * cp -rv ~/projects/satsense-portal/static/* /var/www/flask-portal-live/public/static Run sudo systemctl start portallive.service and check the site works as expected. Virtual Host for Portal For further information about virtual hosts, see the apache httpd set up . Here is the current virtual host for the live portal: <VirtualHost *:80> ServerName portal.satsense.com ServerAlias portal.satsense.com DocumentRoot /var/www/flask-portal-live/public # rewrite to https RewriteEngine on RewriteCond %{SERVER_NAME} =portal.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName portal.satsense.com ServerAlias portal.satsense.com DocumentRoot /var/www/flask-portal-live/public # flask proxy ProxyPass /static ! ProxyPass /error ! ProxyPass /tiles ! ProxyPass / http://localhost:5001/ ProxyPassReverse / http://localhost:5001/ # logs ErrorLog /var/www/flask-portal-live/log/error.log CustomLog /var/www/flask-portal-live/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=31536000; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html # wsgi WSGIScriptAlias /tiles /var/www/tileserver-live/Tileserver/tileserver.wsgi WSGIDaemonProcess tileserver_live python-home=/var/www/venvs/tileserver-live processes=4 threads=1 WSGIProcessGroup tileserver_live # ssl SSLCertificateFile /etc/letsencrypt/live/portal.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/portal.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/portal.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to portal.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to portal.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://portal.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5001 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /static ! ) mean that requests following this pattern should not be proxied (e.g. https://portal.satsense.com/static/resource.js ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The wsgi section sets up the tileserver. Requests to https://portal.satsense.com/tiles are forwarded to the tileserver. See the section about installing the tileserver . The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release . Admin Site Release Admin Site At time of writing, the user \"flaskuser\" on the api server runs all of the flask apps. The following instructions assume that the admin site has already been released on the server. If this is the first release of the admin site on the server The reader can follow the following instructions, but omit uninstalling satdom/satadmin. The reader will also need to copy the app.py and config.ini files (and populate the config.ini correctly): cp app.py /var/www/admin-live/app_home cp config.ini /var/www/admin-live/app_home # populate config.ini correctly The reader will also need to prepare the 503 error files. (more details is a TODO) To release the admin site, follow the steps: Log onto api server as flaskuser (can run sudo su flaskuser as centos). Checkout latest versions of the master branches of satsense-domain, and satsense-admin. Projects are already cloned in ~/projects . Make sure both projects are clean checkouts. From satsense-admin root directory, run npm run-script build . The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps. This can be done via sudo systemctl stop adminstaging.service or sudo systemctl stop adminlive.service for the live version. Apply any db changes using alembic. (This step is a stub, more details is a TODO) Check if the config needs updating. On gitlab, compare the master branch of satsense-admin to the most recent release tag - if config.ini has been updated, you'll need to apply changes to the current version. Current site config can be found at /var/www/admin-live/app_home/config.ini . Make a back up if you wish. Uninstall satdom/satadmin in the venv: source /var/www/admin-live/virtual_environments/venv/bin/activate pip uninstall satdom satadmin Check dependencies, on the same gitlab comparison as config update, check if requirements/production.txt has been updated. If so, run (within venv): pip install -r requirements/production.txt Reinstall satdom/satadmin into the venv. From within venv, run: cd ~/projects/satsense-domain pip install --no-dependencies . cd ~/projects/satsense-admin pip install --no-dependencies . Run sudo systemctl start adminlive.service and check the site works as expected. Virtual Host for Admin Site For further information about virtual hosts, see the apache httpd set up . Here is the current virtual host for the live admin site: <VirtualHost *:80> ServerName admin.satsense.com ServerAlias admin.satsense.com DocumentRoot /var/www/admin-live/public RewriteEngine on RewriteCond %{SERVER_NAME} =admin.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName admin.satsense.com ServerAlias admin.satsense.com DocumentRoot /var/www/admin-live/public # flask proxy ProxyPass /error ! ProxyPass / http://localhost:6001/ ProxyPassReverse / http://localhost:6001/ # logs ErrorLog /var/www/admin-live/log/error.log CustomLog /var/www/admin-live/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=300; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html SSLCertificateFile /etc/letsencrypt/live/admin.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/admin.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/admin.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to admin.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to admin.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://admin.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 6001 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /error ! ) mean that requests following this pattern should not be proxied (e.g. https://admin.satsense.com/static/resource.js ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release . Demo Portal TODO Troubleshooting Use the following tables to look up the actions you should do. Actions are listed in the order you should consider them. Instructions for each action are listed below the tables. Troubleshooting for Flask Applications (Portal and Admin Site) Problem Actions Web site isn't responding. For example https://portal.satsense.com or https://admin.satsense.com don't respond. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check flask errors Web site reports \"Server Unavailable\" Check gunicorn systemd process is running Web site responds, but logging in does not work Check flask errors Restart flask application Troubleshooting for Demo Portal Problem Actions Web site isn't responding. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check httpd errors Httpd restart Actions Check Api server is running. Log into api server using ssh -p 2222 centos@satsense-api.mb1.unipart.io If no response, contact unipart sysadmins. Check httpd errors. Log files for httpd are kept: ``` Portal + Tileserver: /var/www/flask-portal-live/log/error.log /var/www/flask-portal-live/log/requests.log Admin site: /var/www/admin-live/log/error.log /var/www/admin-live/log/requests.log Demo Portal + Demo Tileserver: /var/www/demo-portal-live/log/error.log /var/www/demo-portal-live/log/requests.log * **Httpd restart.** Restart the httpd process via: sudo systemctl restart httpd.service * **Check flask errors.** Log files for flask errors are kept in the following directories: Portal: /var/www/flask-portal-live/log/flask/ Admin site: /var/www/admin-live/log/flask * **Check gunicorn systemd process is running.** Log into api server, and run one of: systemctl status portallive systemctl status adminlive If process is reported as stopped. Then run sudo systemctl start portallive sudo systemctl start adminlive ``` Check flask errors for anything untoward, especially if starting the process doesn't work. Restart flask application. Stop and start the application process. For the portal: sudo systemctl stop portallive sudo systemctl start portallive and similarly for the admin site. Check a record. This is very unlikely to be the problem. Only do this step if the api server is not receiving requests. For example, there should be logs in /var/www/flask-portal-live/log/requests.log . Log in www.namebright.com and go to DNS Records . Check details are correct next to problematic subdomain. Check tileserver config vs overview geotiffs. Open tileserver config: # for tileserver vi -R /var/www/tileserver-live/Tileserver/config.ini # for demo tileserver vi -R /var/www/tileserver-demo/Tileserver/config.ini You should see a json object for the value for config under the section [tilestache] . Inside this object, there should be one or more layers , each of which have values for geotiff_directory and geotiff_name_stem . Check: The geotiff_directory exists; Files with names <geotiff_name_stem>_<resolution>.geotiff exist for each resolution in resolutions under the section [geotiff] . None of these files are corrupt.","title":"Overview"},{"location":"client-facing-applications/portal/portal-overview/#overview","text":"The page includes documentation for the portal and admin sites. This includes information about the following applications: * the UK portal flask application (portal.satsense.com); * the admin site flask application (admin.satsense.com); * the tileserver for the full UK portal (portal.satsense.com/tiles); * the demo portal PHP application (demo.satsense.com); * the demo tileserver for the demo portal (demo.satsense.com/tiles). We will refer to each application by the text in bold . Since both the portal and the admin site are written in flask, this documentation starts with detailing information common to both. We then document details for both tileservers and for the demo portal. We finish with troubleshooting hints for all applications, which also cover where the reader can find relevant log files. Contents: General Information for Flask Applications Documentation and Resources Project Design Choices Testing Release Set Up Portal Release Portal Virtual Host for Portal Admin Site Release Admin Site Virtual Host for Admin Site Tileserver and Demo Tileserver Demo Portal Troubleshooting","title":"Overview"},{"location":"client-facing-applications/portal/portal-overview/#general-information-for-flask-applications","text":"","title":"General Information for Flask Applications"},{"location":"client-facing-applications/portal/portal-overview/#documentation-and-resources","text":"The reader may find the following resources useful: * Flask Documentation - general documentation for flask. * Flask Login Documentation - documentation for the flask plugin we have chosen to handle user sessions. * Flask Mega-Tutorial - an introduction to the world of flask, written in 2017-18. Suitable for absolute beginners to flask, but also useful for seasoned developers. However, bear in mind that Miguel hasn't necessarily chosen the same design choices that we have. * Explore Flask - a book backed on Kickstarter in July 2013. Most of the material is still relevant.","title":"Documentation and Resources"},{"location":"client-facing-applications/portal/portal-overview/#project-design-choices","text":"","title":"Project Design Choices"},{"location":"client-facing-applications/portal/portal-overview/#overall-design","text":"From the root of the flask app repository you should find the following directory structure: - <name of project python module> - app - **possibly some other python modules** - src - js - css - **possibly some other directories/files** - requirements - development.txt - production.txt - tests - integrations_tests - **possibly some other tests (e.g. unit tests)** - app.py - config.ini - setup.py - .gitlab-ci.yml - MANIFEST.in - pytest.ini - **some other files** The directory <name of project python module> contains all of the python code relevant to the site. The actual flask app is contained in the subdirectory app , and the <name of project python module> directory may contain other directories - for example, a domain directory to allow the app to connect to a database. The directory src contains javascript and styling code, amongst other files. This directory contains the versions of this code that is checked into source control, that is, it is easy for a developer to work on them. However, before the files are able to be served by a server (development or production), this code needs to be compiled and possibly bundled. See specifics in each projects' readme.md . The directories described above are generally all a developer would have to change to introduce new features. However, here is a brief description of the rest: * The directory requirements contains pip dependencies for the projects. Instructions for how to install dependencies should be found in each projects' readme.md . * The directory tests contains tests for the project. See the testing section for information about testing structure choices for the projects. We use pytest as the project test runner, so setting are contained in pytest.ini . * The file app.py contains bootstrap code that runs the project. Running flask run (after setting up the enviroment etc) runs this file. * The file .gitlab-ci.yml instructs gitlab to automatically run the tests for the project upon pushing a commit * The file setup.py allows the project python module to be installable into a virtual or conda environment. * Upon installing the project into an environment, non-python files (such as html) may not be included in to the installation. The file MANIFEST.in specifies files that should be included into the installation.","title":"Overall Design"},{"location":"client-facing-applications/portal/portal-overview/#name-of-project-python-moduleapp-design","text":"We aim to follow an Model-View-Controller (MVC) design pattern. With that in mind, the <name of project python module>/app directory contains the following structure: - controllers - models - templates - **possibly some other files/directories** The directory templates contains the Views with regards to the MVC pattern - whilst this mismatch of terminology may be confusing at first, it is convention for flask to look for a directory called templates . This directory contains jinja2 and .txt templates. Jinja2 templates are html that allow dynamic values to be injected into them. For example: <p>Hello, {{ model.name }}</p> expects an object to be injected into the page with the attribute name . We call these objects \"models\". These are exactly the objects you can find in the models directory. Because models are extremely simple classes, we aim to use python dataclasses for the models. Whilst Jinja2 templates expect a model to be injected into them, we still need code that will obtain data (perhaps from a database), initialise a model and then actually do the injection of the model into the template. This code is known as a controller and it lives inside the controllers directory. We aim to use the same names across the different directories, so it clear to the developer where to find related models, templates (views) and controllers. For example, the developer may expect to find something like following structure: - controllers - manage_users_controller.py - models - manage_users_models.py - templates - manage_users - view_user.html - search_users.html","title":"&lt;name of project python module&gt;/app Design"},{"location":"client-facing-applications/portal/portal-overview/#testing","text":"TODO","title":"Testing"},{"location":"client-facing-applications/portal/portal-overview/#release-set-up","text":"We host the flask applications on the api server satsense-api.mb1.unipart.io . The following describes how the flask application accepts requests: User makes http request to api server; Apache httpd server accepts request and proxies it to a port (e.g. port 5000) also on api server; Flask application listens on port (e.g. port 5000) and accepts proxied request, it then responds appropriately. To note, systemd runs a gunicorn server allowing the flask application to listen on port. User receives response after it has been proxied back through httpd server. In the following, we describe how to get the flask application up and running as per step 3. See the portal and admin site sections for further information and example virtual host files for apache httpd. For further information about virtual hosts, see the miscellaneous web section , where there is also information about setting up DNS records, and ssl certificates (which will also need to be done for the application).","title":"Release Set Up"},{"location":"client-facing-applications/portal/portal-overview/#flask-application-set-up","text":"","title":"Flask Application Set Up"},{"location":"client-facing-applications/portal/portal-overview/#overview-of-directory-structure","text":"All the code for the applications is stored within a subdirectory of /var/www . For example, the live portal website code is contained within: /var/www/flask-portal-live This subdirectory has the following structure: - app_home - log - public - virtual_environments The app is installed into a virtual environment inside virtual_environments . The directory app_home contains bootstrap code needed for the application, namely app.py and config.ini (see Overall Design ). The directory public contains static assets that are not served by the flask application, these assets include (but not limited to): * static html (such as error pages); * javascript; * css; Apache is configured to serve these static assets directly rather than proxy the request to flask. Finally, the log directory contains logs for application. Any errors/requests that the apache server runs into can be found in this directory. The flask application itself is also configured to report any errors, these can be found in the sub directory log/flask .","title":"Overview of directory structure"},{"location":"client-facing-applications/portal/portal-overview/#commands-for-setting-up-directory-structure","text":"In the following, we assume the location of the live portal. The reader should change the folder paths for the application they are setting up. If this is the first application on the server, it is best to add a user to handle the flask applications: useradd flaskuser Now we make the directories as per the overiew of directory structure section: sudo mkdir /var/www/flask-portal-live/ cd /var/www/flask-portal-live/ sudo mkdir public/ sudo chown flaskuser:apache public/ sudo mkdir log/ sudo chown flaskuser:apache log/ sudo mkdir log/flask sudo chown flaskuser:flaskuser log/flask/ sudo mkdir app_home/ sudo chown flaskuser:flaskuser app_home/ sudo mkdir virtual_environments/ sudo chown flaskuser:flaskuser virtual_environments/ Notice that flaskuser is the owner of all of the directories, but that apache needs access to the public and logs directories. The former is so that the the apache server can serve files from this directory without having to give send a proxy request to the flask application. The latter is so the apache server can write logs to this directory. To write logs, we have to also give that folder SELinux permissions to do that: sudo semanage fcontext -a -t httpd_log_t \"/var/www/flask-portal-live/log(/.*)?\" sudo restorecon -R -v log/ You can now populate the virtual environment, and app_home/public directories. Further details can be found in the Release Portal and Release Admin Site","title":"Commands for setting up directory structure"},{"location":"client-facing-applications/portal/portal-overview/#systemd-and-gunicorn-set-up","text":"The following assumes the setup for the live portal web site and that the application has been set up as per the Release Portal section. Replace names/paths that make sense for the application you would like to run via systemd. Gunicorn is easy to install via pip. First make sure you are logged into the api server as flaskuser (you can run sudo su flaskuser as centos ), and then run: source /var/www/flask-portal-live/virtual_environments/venv/bin/activate pip install gunicorn If you wish, you can check that the site is set up correctly (i.e. that the application will run) by running: gunicorn -b localhost:<port> -w 1 app:app from /var/www/flask-portal-live/app_home and replace <port> with a port number. We'd like the above process to be run automatically, which is done by using systemd . To set up systemd , you'll need sudo privileges (which flaskuser does not have). First, create a file: touch /etc/systemd/system/portallive.service chmod 664 /etc/systemd/system/portallive.service Then populate the file, the following is the current systemd config for the live portal process: [Unit] Description = PortalLive After = network.target [Service] User=flaskuser WorkingDirectory=/var/www/flask-portal-live/app_home ExecStart=/var/www/flask-portal-live/virtual_environments/venv/bin/gunicorn -b localhost:7000 -w 4 app:app Restart=always [Install] WantedBy = multi-user.target For systemd to recognise the new file, you will need to run systemctl daemon-reload and you can check it has been found using systemctl list-unit-files The service can be started via: systemctl start portallive or stopped via: systemctl stop portallive To allow the service to start on server reboot, it needs to be enabled: systemctl enable portallive","title":"systemd and gunicorn set up"},{"location":"client-facing-applications/portal/portal-overview/#portal","text":"","title":"Portal"},{"location":"client-facing-applications/portal/portal-overview/#first-release-of-portal","text":"At time of writing, the user \"flaskuser\" on the api server runs all of the flask apps. The following instructions assume that the portal has already been released on the server. If this is the first release of the portal on the server The reader can follow the instructions following this note, but omit uninstalling satdom/satportal and removing static files (just copy them over). In addition to the instructions following this note, the will reader will need to: Create a virtual environment for the application Populate the app_home directory Create a 503 document in public/error the reader will also need to copy the app.py and config.ini files (and populate the config.ini correctly): cp app.py /var/www/flask-portal-live/app_home cp config.ini /var/www/flask-portal-live/app_home # populate config.ini correctly Finally, gdal is a fiddly dependency and needs to be installed in a particular way. Instead of just running pip install -r requirements/production.txt check the project readme.md.","title":"First Release of Portal"},{"location":"client-facing-applications/portal/portal-overview/#subsequent-releases-of-portal","text":"To release the portal, follow the steps: Log onto api server as flaskuser (can run sudo su flaskuser as centos). Checkout latest versions of the master branches of satsense-domain, and satsense-portal. Projects are already cloned in ~/projects . Change dir to satsense-portal root directory (i.e. cd ~/projects/satsense-portal ). Make sure the ./static folder doesn't exist or is empty; that src/js/config.js is correct and that the rest of the working directory is clean. Backups can be found at ~/config_backups . From satsense-portal root directory, run npm run gulp . The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps. This can be done via sudo systemctl stop portalstaging.service or sudo systemctl stop portallive.service for the live version. Apply any db changes using alembic. (This step is a stub, more details is a TODO) Check if the config needs updating. On gitlab, compare the master branch of satsense-portal to the most recent release tag - if config.ini has been updated, you'll need to apply changes to the current version. Current site config can be found at /var/www/flask-portal-live/app_home/config.ini . Make a back up if you wish. Uninstall satdom/satportal in the venv: source /var/www/flask-portal-live/virtual_environments/venv/bin/activate pip uninstall satdom satportal Check dependencies, on the same gitlab comparison as config update, check if requirements/production.txt has been updated. If so, run (within venv): pip install -r requirements/production.txt Reinstall satdom/satsense-portal into the venv. From within venv, run: cd ~/projects/satsense-domain pip install --no-dependencies . cd ~/projects/satsense-portal pip install --no-dependencies . Replace static files cd /var/www/flask-portal-live/public/static rm -rv * cp -rv ~/projects/satsense-portal/static/* /var/www/flask-portal-live/public/static Run sudo systemctl start portallive.service and check the site works as expected.","title":"Subsequent Releases of Portal"},{"location":"client-facing-applications/portal/portal-overview/#virtual-host-for-portal","text":"For further information about virtual hosts, see the apache httpd set up . Here is the current virtual host for the live portal: <VirtualHost *:80> ServerName portal.satsense.com ServerAlias portal.satsense.com DocumentRoot /var/www/flask-portal-live/public # rewrite to https RewriteEngine on RewriteCond %{SERVER_NAME} =portal.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName portal.satsense.com ServerAlias portal.satsense.com DocumentRoot /var/www/flask-portal-live/public # flask proxy ProxyPass /static ! ProxyPass /error ! ProxyPass /tiles ! ProxyPass / http://localhost:5001/ ProxyPassReverse / http://localhost:5001/ # logs ErrorLog /var/www/flask-portal-live/log/error.log CustomLog /var/www/flask-portal-live/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=31536000; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html # wsgi WSGIScriptAlias /tiles /var/www/tileserver-live/Tileserver/tileserver.wsgi WSGIDaemonProcess tileserver_live python-home=/var/www/venvs/tileserver-live processes=4 threads=1 WSGIProcessGroup tileserver_live # ssl SSLCertificateFile /etc/letsencrypt/live/portal.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/portal.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/portal.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to portal.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to portal.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://portal.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 5001 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /static ! ) mean that requests following this pattern should not be proxied (e.g. https://portal.satsense.com/static/resource.js ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The wsgi section sets up the tileserver. Requests to https://portal.satsense.com/tiles are forwarded to the tileserver. See the section about installing the tileserver . The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release .","title":"Virtual Host for Portal"},{"location":"client-facing-applications/portal/portal-overview/#admin-site","text":"","title":"Admin Site"},{"location":"client-facing-applications/portal/portal-overview/#release-admin-site","text":"At time of writing, the user \"flaskuser\" on the api server runs all of the flask apps. The following instructions assume that the admin site has already been released on the server. If this is the first release of the admin site on the server The reader can follow the following instructions, but omit uninstalling satdom/satadmin. The reader will also need to copy the app.py and config.ini files (and populate the config.ini correctly): cp app.py /var/www/admin-live/app_home cp config.ini /var/www/admin-live/app_home # populate config.ini correctly The reader will also need to prepare the 503 error files. (more details is a TODO) To release the admin site, follow the steps: Log onto api server as flaskuser (can run sudo su flaskuser as centos). Checkout latest versions of the master branches of satsense-domain, and satsense-admin. Projects are already cloned in ~/projects . Make sure both projects are clean checkouts. From satsense-admin root directory, run npm run-script build . The following will actually interact with the current running site. It is advisable to bring the site down whilst doing these steps. This can be done via sudo systemctl stop adminstaging.service or sudo systemctl stop adminlive.service for the live version. Apply any db changes using alembic. (This step is a stub, more details is a TODO) Check if the config needs updating. On gitlab, compare the master branch of satsense-admin to the most recent release tag - if config.ini has been updated, you'll need to apply changes to the current version. Current site config can be found at /var/www/admin-live/app_home/config.ini . Make a back up if you wish. Uninstall satdom/satadmin in the venv: source /var/www/admin-live/virtual_environments/venv/bin/activate pip uninstall satdom satadmin Check dependencies, on the same gitlab comparison as config update, check if requirements/production.txt has been updated. If so, run (within venv): pip install -r requirements/production.txt Reinstall satdom/satadmin into the venv. From within venv, run: cd ~/projects/satsense-domain pip install --no-dependencies . cd ~/projects/satsense-admin pip install --no-dependencies . Run sudo systemctl start adminlive.service and check the site works as expected.","title":"Release Admin Site"},{"location":"client-facing-applications/portal/portal-overview/#virtual-host-for-admin-site","text":"For further information about virtual hosts, see the apache httpd set up . Here is the current virtual host for the live admin site: <VirtualHost *:80> ServerName admin.satsense.com ServerAlias admin.satsense.com DocumentRoot /var/www/admin-live/public RewriteEngine on RewriteCond %{SERVER_NAME} =admin.satsense.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] </VirtualHost> <VirtualHost *:443> ServerName admin.satsense.com ServerAlias admin.satsense.com DocumentRoot /var/www/admin-live/public # flask proxy ProxyPass /error ! ProxyPass / http://localhost:6001/ ProxyPassReverse / http://localhost:6001/ # logs ErrorLog /var/www/admin-live/log/error.log CustomLog /var/www/admin-live/log/requests.log combined # headers: Header always set Strict-Transport-Security \"max-age=300; includeSubdomains\" Header always set X-Frame-Options \"deny\" Header always set X-Xss-Protection \"1; mode=block\" Header always set X-Content-Type-Options \"nosniff\" Header always set Referrer-Policy \"no-referrer\" Header always edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure;SameSite=Strict # Error Documents ErrorDocument 503 /error/503.html SSLCertificateFile /etc/letsencrypt/live/admin.satsense.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/admin.satsense.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/admin.satsense.com/chain.pem </VirtualHost> In the above: The httpd server listens to http requests on port 80 ; the configuration inside <VirtualHost *:80> is used upon a http request to admin.satsense.com . The only instruction is to rewrite the request to a https request. The httpd server listens to https requests on port 443 ; the configuration inside <VirtualHost *:443> is used upon a https request to admin.satsense.com . DocumentRoot specifies the directory where the server should look for files. Without any other configuration, a request to https://admin.satsense.com/index.html would server the file index.html inside the DocumentRoot directory. The flask proxy session allows the httpd server to forward requests to port 6001 (where the flask application is listening). Values with an exclamation mark (e.g. ProxyPass /error ! ) mean that requests following this pattern should not be proxied (e.g. https://admin.satsense.com/static/resource.js ) The logs section specifies where the httpd logs should be made. The headers section sets headers on each response, these values are recommended to improve the security between the server and the client The Error Documents are documents that are served upon a particular error thrown by the server. A 503 corresponds to a Service Unavailable and is thrown if the flask server is not running - therefore any website users see a branded error page and not the default httpd error page. The ssl section tells the httpd server which ssl certificate to use. This section is automatically populated by certbot and should not be populated manually upon a new release .","title":"Virtual Host for Admin Site"},{"location":"client-facing-applications/portal/portal-overview/#demo-portal","text":"TODO","title":"Demo Portal"},{"location":"client-facing-applications/portal/portal-overview/#troubleshooting","text":"Use the following tables to look up the actions you should do. Actions are listed in the order you should consider them. Instructions for each action are listed below the tables.","title":"Troubleshooting"},{"location":"client-facing-applications/portal/portal-overview/#troubleshooting-for-flask-applications-portal-and-admin-site","text":"Problem Actions Web site isn't responding. For example https://portal.satsense.com or https://admin.satsense.com don't respond. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check flask errors Web site reports \"Server Unavailable\" Check gunicorn systemd process is running Web site responds, but logging in does not work Check flask errors Restart flask application","title":"Troubleshooting for Flask Applications (Portal and Admin Site)"},{"location":"client-facing-applications/portal/portal-overview/#troubleshooting-for-demo-portal","text":"Problem Actions Web site isn't responding. Check Api server is running Check httpd errors Check a record Web site reports \"Unexpected error occurred\" Check httpd errors Httpd restart","title":"Troubleshooting for Demo Portal"},{"location":"client-facing-applications/portal/portal-overview/#actions","text":"Check Api server is running. Log into api server using ssh -p 2222 centos@satsense-api.mb1.unipart.io If no response, contact unipart sysadmins. Check httpd errors. Log files for httpd are kept: ``` Portal + Tileserver: /var/www/flask-portal-live/log/error.log /var/www/flask-portal-live/log/requests.log Admin site: /var/www/admin-live/log/error.log /var/www/admin-live/log/requests.log Demo Portal + Demo Tileserver: /var/www/demo-portal-live/log/error.log /var/www/demo-portal-live/log/requests.log * **Httpd restart.** Restart the httpd process via: sudo systemctl restart httpd.service * **Check flask errors.** Log files for flask errors are kept in the following directories: Portal: /var/www/flask-portal-live/log/flask/ Admin site: /var/www/admin-live/log/flask * **Check gunicorn systemd process is running.** Log into api server, and run one of: systemctl status portallive systemctl status adminlive If process is reported as stopped. Then run sudo systemctl start portallive sudo systemctl start adminlive ``` Check flask errors for anything untoward, especially if starting the process doesn't work. Restart flask application. Stop and start the application process. For the portal: sudo systemctl stop portallive sudo systemctl start portallive and similarly for the admin site. Check a record. This is very unlikely to be the problem. Only do this step if the api server is not receiving requests. For example, there should be logs in /var/www/flask-portal-live/log/requests.log . Log in www.namebright.com and go to DNS Records . Check details are correct next to problematic subdomain. Check tileserver config vs overview geotiffs. Open tileserver config: # for tileserver vi -R /var/www/tileserver-live/Tileserver/config.ini # for demo tileserver vi -R /var/www/tileserver-demo/Tileserver/config.ini You should see a json object for the value for config under the section [tilestache] . Inside this object, there should be one or more layers , each of which have values for geotiff_directory and geotiff_name_stem . Check: The geotiff_directory exists; Files with names <geotiff_name_stem>_<resolution>.geotiff exist for each resolution in resolutions under the section [geotiff] . None of these files are corrupt.","title":"Actions"}]}